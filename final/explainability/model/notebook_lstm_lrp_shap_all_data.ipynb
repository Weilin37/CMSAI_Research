{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge LSTM LRP and SHAP of All Test/Val Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for merging the results of LRP and SHAP scores for all test and validation data. You need to first run [LSTM LRP](lstm_lrp_all_data.py) and [LSTM SHAP](lstm_shap_all_data.py) to compute the LRP and SHAP scores respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "import imp_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_SYNTHETIC = True #Whether data is synthetic\n",
    "\n",
    "BEST_EPOCH = 2\n",
    "DATA_SPLIT = 'val' #val/test\n",
    "\n",
    "RESULTS_DIR = f'./output/synthetic/{DATA_TYPE}/{SEQ_LEN}/{MODEL_NAME}/importances/'\n",
    "\n",
    "SHAP_RESULTS_PATH = os.path.join(RESULTS_DIR, f\"{DATA_SPLIT}_all_shap_{BEST_EPOCH}.pkl\")\n",
    "LRP_RESULTS_PATH = os.path.join(RESULTS_DIR, f\"{DATA_SPLIT}_all_lrp_{BEST_EPOCH}.pkl\")\n",
    "OUTPUT_PATH = os.path.join(RESULTS_DIR, f\"{DATA_SPLIT}_all_lrp_shap_{BEST_EPOCH}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SHAP_RESULTS_PATH, 'rb') as fp:\n",
    "    shap_results = pickle.load(fp)\n",
    "    \n",
    "with open(LRP_RESULTS_PATH, 'rb') as fp:\n",
    "    lrp_results = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LRP: 7000\n",
      "SHAP: 7000\n"
     ]
    }
   ],
   "source": [
    "print(f\"LRP: {len(lrp_results[BEST_EPOCH])}\")\n",
    "print(f\"SHAP: {len(shap_results[BEST_EPOCH])}\")\n",
    "assert len(lrp_results[BEST_EPOCH]) == len(shap_results[BEST_EPOCH])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge LRP and SHAP scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pid in lrp_results[BEST_EPOCH].keys():\n",
    "    orig_len = lrp_results[BEST_EPOCH][pid][\"imp\"].shape[0]\n",
    "    lrp_results[BEST_EPOCH][pid][\"imp\"] = lrp_results[BEST_EPOCH][pid][\"imp\"].merge(\n",
    "        shap_results[BEST_EPOCH][pid][\"imp\"], on=[\"seq_idx\", \"token\"]\n",
    "    )\n",
    "    assert orig_len == lrp_results[BEST_EPOCH][pid][\"imp\"].shape[0]\n",
    "    lrp_results[BEST_EPOCH][pid][\"imp\"] = lrp_results[BEST_EPOCH][pid][\"imp\"][\n",
    "        [\"idx\", \"seq_idx\", \"token\", \"att_weights\", \"lrp_scores\", \"shap_scores\"]\n",
    "    ]\n",
    "results = lrp_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate similarity indexes\n",
    "epoch_lrp_shap_t_corr = []\n",
    "epoch_lrp_sim = []\n",
    "epoch_shap_sim = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pid in results[BEST_EPOCH].keys():\n",
    "    imp_df = results[BEST_EPOCH][pid][\"imp\"]\n",
    "    imp_df[\"u_token\"] = [\n",
    "        str(seq) + \"_\" + str(token)\n",
    "        for seq, token in zip(imp_df[\"seq_idx\"], imp_df[\"token\"])\n",
    "    ]\n",
    "    results[BEST_EPOCH][pid][\"lrp_shap_t_corr\"] = get_wtau(\n",
    "        imp_df[\"lrp_scores\"], imp_df[\"shap_scores\"]\n",
    "    )\n",
    "\n",
    "    # gt similarity\n",
    "    lrp_sim = imp_utils.get_intersection_similarity(\n",
    "        imp_df.lrp_scores, imp_df.token, freedom=0, is_synthetic=IS_SYNTHETIC\n",
    "    )\n",
    "    shap_sim = imp_utils.get_intersection_similarity(\n",
    "        imp_df.shap_scores, imp_df.token, freedom=0, is_synthetic=IS_SYNTHETIC\n",
    "    )\n",
    "    att_sim = imp_utils.get_intersection_similarity(\n",
    "        imp_df.att_weights, imp_df.token, freedom=0, is_synthetic=IS_SYNTHETIC\n",
    "    )\n",
    "    results[BEST_EPOCH][pid][\"lrp_sim\"] = lrp_sim\n",
    "    results[BEST_EPOCH][pid][\"shap_sim\"] = shap_sim\n",
    "    results[BEST_EPOCH][pid][\"att_sim\"] = att_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>seq_idx</th>\n",
       "      <th>token</th>\n",
       "      <th>att_weights</th>\n",
       "      <th>lrp_scores</th>\n",
       "      <th>shap_scores</th>\n",
       "      <th>u_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>dental_exam_N</td>\n",
       "      <td>0.039415</td>\n",
       "      <td>-0.020867</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>0_dental_exam_N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>dental_exam_N</td>\n",
       "      <td>0.043597</td>\n",
       "      <td>-0.022586</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>1_dental_exam_N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>cut_finger_N</td>\n",
       "      <td>0.042979</td>\n",
       "      <td>-0.018259</td>\n",
       "      <td>0.002387</td>\n",
       "      <td>2_cut_finger_N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>0.046472</td>\n",
       "      <td>-0.024119</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>3_ingrown_nail_N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>quad_injury_N</td>\n",
       "      <td>0.045419</td>\n",
       "      <td>-0.018696</td>\n",
       "      <td>-0.001051</td>\n",
       "      <td>4_quad_injury_N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx  seq_idx           token  att_weights  lrp_scores  shap_scores  \\\n",
       "0   11        0   dental_exam_N     0.039415   -0.020867     0.002821   \n",
       "1   11        1   dental_exam_N     0.043597   -0.022586     0.000379   \n",
       "2   17        2    cut_finger_N     0.042979   -0.018259     0.002387   \n",
       "3   18        3  ingrown_nail_N     0.046472   -0.024119     0.000659   \n",
       "4    6        4   quad_injury_N     0.045419   -0.018696    -0.001051   \n",
       "\n",
       "            u_token  \n",
       "0   0_dental_exam_N  \n",
       "1   1_dental_exam_N  \n",
       "2    2_cut_finger_N  \n",
       "3  3_ingrown_nail_N  \n",
       "4   4_quad_injury_N  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[BEST_EPOCH][pid]['imp'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save all combined results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importance Scores Successfully Merged and Saved to ./output/synthetic/event/30/lstm/importances/val_all_lrp_shap_2.pkl!\n"
     ]
    }
   ],
   "source": [
    "with open(OUTPUT_PATH, 'wb') as fpath:\n",
    "    pickle.dump(results, fpath)\n",
    "print(f'Importance Scores Successfully Merged and Saved to {OUTPUT_PATH}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
