{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run LRP on all test and validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install nb_black\n",
    "#! pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from urllib.parse import urlparse\n",
    "import tarfile\n",
    "import pickle\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "import deep_id_pytorch\n",
    "\n",
    "from lstm_models import *\n",
    "from lstm_lrp_models import *\n",
    "from lstm_att_models import *\n",
    "from lstm_self_att_models import *\n",
    "from lstm_utils import *\n",
    "from imp_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_SYNTHETIC = True  # If dataset is synthetic/real\n",
    "# MODEL_NAME = 'lstm'\n",
    "MODEL_NAME = \"lstm\"\n",
    "USE_SELF_ATTENTION = True\n",
    "\n",
    "NROWS = 1e9\n",
    "\n",
    "TRAIN_MODEL = True\n",
    "SEQ_LEN = 30\n",
    "DATA_TYPE = \"event\"  # event/sequence\n",
    "\n",
    "TRAIN_DATA_PATH = f\"../data/sample_dataset/{DATA_TYPE}/{SEQ_LEN}/train.csv\"\n",
    "VALID_DATA_PATH = f\"../data/sample_dataset/{DATA_TYPE}/{SEQ_LEN}/val.csv\"\n",
    "TEST_DATA_PATH = f\"../data/sample_dataset/{DATA_TYPE}/{SEQ_LEN}/test.csv\"\n",
    "VOCAB_PATH = f\"../data/sample_dataset/{DATA_TYPE}/{SEQ_LEN}/vocab.pkl\"\n",
    "\n",
    "MODEL_SAVE_PATH_PATTERN = (\n",
    "    f\"./output/{DATA_TYPE}/{SEQ_LEN}/{MODEL_NAME}/model_weights/model_{'{}'}.pkl\"\n",
    ")\n",
    "IMP_SAVE_DIR_PATTERN = f\"./output/{DATA_TYPE}/{SEQ_LEN}/{MODEL_NAME}/importances/{'{}'}_imp_{'{}'}.pkl\"  # Feature importance values path for a given dataset split\n",
    "\n",
    "OUTPUT_RESULTS_PATH = (\n",
    "    f\"./output/{DATA_TYPE}/{SEQ_LEN}/{MODEL_NAME}/train_results/results.csv\"\n",
    ")\n",
    "PARAMS_PATH = (\n",
    "    f\"./output/{DATA_TYPE}/{SEQ_LEN}/{MODEL_NAME}/train_results/model_params.json\"\n",
    ")\n",
    "\n",
    "\n",
    "# Test Patients for Visualization (from Test Set)\n",
    "SELECTED_PATIENTS = [\"VHCSIEPRI8\", \"MIP0F9ZOUM\", \"79A4PHXNE6\", \"CW780GL0AX\"]\n",
    "\n",
    "BEST_EPOCH = 2\n",
    "EARLY_STOPPING_NUM = 1  # For early stopping\n",
    "\n",
    "TARGET_COLNAME = \"label\"\n",
    "UID_COLNAME = \"patient_id\"\n",
    "TARGET_VALUE = \"1\"\n",
    "\n",
    "# Results path for val & test data\n",
    "output_dir = os.path.dirname(IMP_SAVE_DIR_PATTERN)\n",
    "VAL_RESULTS_PATH = os.path.join(output_dir, f\"val_all_lrp_{BEST_EPOCH:02}.pkl\")\n",
    "TEST_RESULTS_PATH = os.path.join(output_dir, f\"test_all_lrp_{BEST_EPOCH:02}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Vocab and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_freq': 1,\n",
       " 'batch_size': 16,\n",
       " 'embedding_dim': 8,\n",
       " 'hidden_dim': 16,\n",
       " 'nlayers': 2,\n",
       " 'bidirectional': True,\n",
       " 'dropout': 0.3,\n",
       " 'linear_bias': False,\n",
       " 'init_type': 'zero',\n",
       " 'learning_rate': 0.01,\n",
       " 'scheduler_step': 3,\n",
       " 'clip': False,\n",
       " 'rev': False,\n",
       " 'n_background': 300,\n",
       " 'background_negative_only': True,\n",
       " 'background_positive_only': False,\n",
       " 'num_eval_val': 64,\n",
       " 'num_eval_test': 64,\n",
       " 'test_positive_only': False,\n",
       " 'is_test_random': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model params\n",
    "MODEL_PARAMS = None\n",
    "with open(PARAMS_PATH, \"r\") as fp:\n",
    "    MODEL_PARAMS = json.load(fp)\n",
    "MODEL_PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab len: 47\n",
      "Building dataset from ../data/sample_dataset/event/30/val.csv..\n",
      "Success!\n",
      "Building dataset from ../data/sample_dataset/event/30/test.csv..\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(VOCAB_PATH):\n",
    "    with open(VOCAB_PATH, \"rb\") as fp:\n",
    "        vocab = pickle.load(fp)\n",
    "    print(f\"vocab len: {len(vocab)}\")  # vocab + padding + unknown\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"Vocab path does not exist! Please create vocab from training data and save it first.\"\n",
    "    )\n",
    "\n",
    "valid_dataset, vocab = build_lstm_dataset(\n",
    "    VALID_DATA_PATH,\n",
    "    min_freq=MODEL_PARAMS[\"min_freq\"],\n",
    "    uid_colname=UID_COLNAME,\n",
    "    target_colname=TARGET_COLNAME,\n",
    "    max_len=SEQ_LEN,\n",
    "    target_value=TARGET_VALUE,\n",
    "    vocab=vocab,\n",
    "    nrows=NROWS,\n",
    "    rev=MODEL_PARAMS[\"rev\"],\n",
    ")\n",
    "\n",
    "test_dataset, _ = build_lstm_dataset(\n",
    "    TEST_DATA_PATH,\n",
    "    min_freq=MODEL_PARAMS[\"min_freq\"],\n",
    "    uid_colname=UID_COLNAME,\n",
    "    target_colname=TARGET_COLNAME,\n",
    "    max_len=SEQ_LEN,\n",
    "    target_value=TARGET_VALUE,\n",
    "    vocab=vocab,\n",
    "    nrows=NROWS,\n",
    "    rev=MODEL_PARAMS[\"rev\"],\n",
    ")\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset, batch_size=MODEL_PARAMS[\"batch_size\"], shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=MODEL_PARAMS[\"batch_size\"], shuffle=False, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./output/event/30/lstm/model_weights/model_02.pkl'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = MODEL_SAVE_PATH_PATTERN.format(f\"{BEST_EPOCH:02}\")\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n"
     ]
    }
   ],
   "source": [
    "# Check if cuda is available\n",
    "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
    "model_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model_best = AttNoHtLSTM(\n",
    "    MODEL_PARAMS[\"embedding_dim\"],\n",
    "    MODEL_PARAMS[\"hidden_dim\"],\n",
    "    vocab,\n",
    "    model_device,\n",
    "    bidi=MODEL_PARAMS[\"bidirectional\"],\n",
    "    nlayers=MODEL_PARAMS[\"nlayers\"],\n",
    "    dropout=MODEL_PARAMS[\"dropout\"],\n",
    "    init_type=MODEL_PARAMS[\"init_type\"],\n",
    "    linear_bias=MODEL_PARAMS[\"linear_bias\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model_best.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_eval_data(dataloader, num):\n",
    "#     \"\"\"Get more than one iteration of data\"\"\"\n",
    "#     col_pid, col_lab, col_txt = None, None, None\n",
    "#     col_num = 0\n",
    "#     for pid, lab, txt in dataloader:\n",
    "#         if col_pid is None:\n",
    "#             col_pid, col_lab, col_txt = pid, lab, txt\n",
    "#         else:\n",
    "#             col_pid = tuple(list(col_pid) + list(pid))\n",
    "#             col_lab = torch.cat((col_lab, lab), dim=0)\n",
    "#             col_txt = torch.cat((col_txt, txt), dim=0)\n",
    "#         col_num = len(col_pid)\n",
    "#         if col_num > num:\n",
    "#             break\n",
    "\n",
    "#     return col_pid[:num], col_lab[:num], col_txt[:num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_results_best = {}\n",
    "valid_results_best[BEST_EPOCH] = {}\n",
    "\n",
    "test_results_best = {}\n",
    "test_results_best[BEST_EPOCH] = {}\n",
    "# calculate relevancy and SHAP\n",
    "lstm_model_best.eval()\n",
    "lrp_model = LSTM_LRP_MultiLayer(lstm_model_best.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test/val data\n",
    "val_patient_ids, val_labels, val_idxed_text = get_eval_data(\n",
    "    valid_dataloader, 7000\n",
    ")  # Change the number if your dataset size is different\n",
    "\n",
    "test_patient_ids, test_labels, test_idxed_text = get_eval_data(test_dataloader, 7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "2min: 49sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for sel_idx in range(len(val_labels)):\n",
    "    one_text = [\n",
    "        int(token.numpy())\n",
    "        for token in val_idxed_text[sel_idx]\n",
    "        if int(token.numpy()) != 0\n",
    "    ]\n",
    "    lrp_model.set_input(one_text)\n",
    "    lrp_model.forward_lrp()\n",
    "\n",
    "    Rx, Rx_rev, _ = lrp_model.lrp(one_text, 0, eps=1e-6, bias_factor=0)\n",
    "    R_words = np.sum(Rx + Rx_rev, axis=1)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df[\"lrp_scores\"] = R_words\n",
    "    df[\"idx\"] = one_text\n",
    "    df[\"seq_idx\"] = [x for x in range(len(one_text))]\n",
    "    df[\"token\"] = [lrp_model.vocab.itos(x) for x in one_text]\n",
    "    df[\"att_weights\"] = lrp_model.get_attn_values()\n",
    "\n",
    "    if val_patient_ids[sel_idx] not in valid_results_best[BEST_EPOCH]:\n",
    "        valid_results_best[BEST_EPOCH][val_patient_ids[sel_idx]] = {}\n",
    "    valid_results_best[BEST_EPOCH][val_patient_ids[sel_idx]] = {}\n",
    "    valid_results_best[BEST_EPOCH][val_patient_ids[sel_idx]][\"label\"] = val_labels[\n",
    "        sel_idx\n",
    "    ]\n",
    "    valid_results_best[BEST_EPOCH][val_patient_ids[sel_idx]][\"pred\"] = lrp_model.s[0]\n",
    "    valid_results_best[BEST_EPOCH][val_patient_ids[sel_idx]][\"imp\"] = df.copy()\n",
    "\n",
    "    if sel_idx % 500 == 0:\n",
    "        print(sel_idx)\n",
    "\n",
    "end = time.time()\n",
    "mins, secs = epoch_time(start, end)\n",
    "print(f\"{mins}min: {secs}sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor([1]),\n",
       " 'pred': -0.9606567216006672,\n",
       " 'imp':     lrp_scores  idx  seq_idx              token  att_weights\n",
       " 0    -0.020867   11        0      dental_exam_N     0.039415\n",
       " 1    -0.022586   11        1      dental_exam_N     0.043597\n",
       " 2    -0.018259   17        2       cut_finger_N     0.042979\n",
       " 3    -0.024119   18        3     ingrown_nail_N     0.046472\n",
       " 4    -0.018696    6        4      quad_injury_N     0.045419\n",
       " 5    -0.004450    9        5         backache_N     0.047086\n",
       " 6    -0.020040   18        6     ingrown_nail_N     0.046999\n",
       " 7    -0.014780   19        7         headache_N     0.047027\n",
       " 8    -0.012223    8        8        hay_fever_N     0.047272\n",
       " 9    -0.019245   19        9         headache_N     0.047400\n",
       " 10   -0.016507   12       10        cold_sore_N     0.047696\n",
       " 11    0.547189   31       11      sleep_apnea_H     0.024369\n",
       " 12   -0.031667    3       12     ankle_sprain_N     0.028616\n",
       " 13   -0.015872   18       13     ingrown_nail_N     0.029725\n",
       " 14   -0.009968    6       14      quad_injury_N     0.031593\n",
       " 15   -0.012595    3       15     ankle_sprain_N     0.034048\n",
       " 16   -0.014069    2       16  annual_physical_N     0.036734\n",
       " 17   -0.017619   19       17         headache_N     0.039867\n",
       " 18    0.007497    9       18         backache_N     0.043949\n",
       " 19   -0.008849   18       19     ingrown_nail_N     0.048581\n",
       " 20   -1.001148   28       20    beta_blockers_U     0.060062\n",
       " 21   -0.032492   17       21       cut_finger_N     0.061044\n",
       " 22   -0.015325    6       22      quad_injury_N     0.060052}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_results_best[BEST_EPOCH][val_patient_ids[sel_idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(VAL_RESULTS_PATH, \"wb\") as fp:\n",
    "    pickle.dump(valid_results_best, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0min: 0sec\n",
      "Total 2min: 54sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for sel_idx in range(len(test_labels)):\n",
    "    one_text = [\n",
    "        int(token.numpy())\n",
    "        for token in test_idxed_text[sel_idx]\n",
    "        if int(token.numpy()) != 0\n",
    "    ]\n",
    "    lrp_model.set_input(one_text)\n",
    "    lrp_model.forward_lrp()\n",
    "\n",
    "    Rx, Rx_rev, _ = lrp_model.lrp(one_text, 0, eps=1e-6, bias_factor=0)\n",
    "    R_words = np.sum(Rx + Rx_rev, axis=1)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df[\"lrp_scores\"] = R_words\n",
    "    df[\"idx\"] = one_text\n",
    "    df[\"seq_idx\"] = [x for x in range(len(one_text))]\n",
    "    df[\"token\"] = [lstm_model_best.vocab.itos(x) for x in one_text]\n",
    "    df[\"att_weights\"] = lrp_model.get_attn_values()\n",
    "\n",
    "    if test_patient_ids[sel_idx] not in test_results_best[BEST_EPOCH]:\n",
    "        test_results_best[BEST_EPOCH][test_patient_ids[sel_idx]] = {}\n",
    "    test_results_best[BEST_EPOCH][test_patient_ids[sel_idx]] = {}\n",
    "    test_results_best[BEST_EPOCH][test_patient_ids[sel_idx]][\"label\"] = test_labels[\n",
    "        sel_idx\n",
    "    ]\n",
    "    test_results_best[BEST_EPOCH][test_patient_ids[sel_idx]][\"pred\"] = lrp_model.s[0]\n",
    "    test_results_best[BEST_EPOCH][test_patient_ids[sel_idx]][\"imp\"] = df.copy()\n",
    "\n",
    "    if sel_idx / 50 == 0:\n",
    "        print(sel_idx)\n",
    "        end = time.time()\n",
    "        mins, secs = epoch_time(start, end)\n",
    "        print(f\"{mins}min: {secs}sec\")\n",
    "\n",
    "end = time.time()\n",
    "mins, secs = epoch_time(start, end)\n",
    "print(f\"Total {mins}min: {secs}sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_results_best[BEST_EPOCH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TEST_RESULTS_PATH, \"wb\") as fp:\n",
    "    pickle.dump(test_results_best, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
