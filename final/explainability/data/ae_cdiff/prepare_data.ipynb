{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "- Total Downsampled Data:\n",
    "    - (22990, 1002)\n",
    "- Total Combined Data:\n",
    "    - (11183529, 1002) *[Month 1 - Month 6]*\n",
    "    - (8867418, 1002) *[Month 7 - Month 11]*\n",
    "    - (20050947, 1002) *[Total]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "**Author: Tesfagabir Meharizghi *(Adopted from Lin Lee Notebook)*<br>\n",
    "Last Updated: 02/12/2021**\n",
    "\n",
    "Notebook for prepares and splits the AE data with only one target variable:\n",
    "- Target: d_00845 for C.Diff Infection (ICD-9 code C.Diff is  008.45)\n",
    "- C.Diff is selected because main events/causes are relatively well known so that the features importances predicted from different algorithms and models could be compared with the ground truth\n",
    "- Actions:\n",
    "    - Read 365 data\n",
    "    - Flattens into 1000 events\n",
    "    - Downsamples the data to make it balanced\n",
    "    - Combine all months data\n",
    "    - Splits data into train/val/test\n",
    "    - Finally saves them to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_codes_path = './cdiff_risk_factors_codes.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Code_System</th>\n",
       "      <th>Internal_Code</th>\n",
       "      <th>Group</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>555.0</td>\n",
       "      <td>ICD-9 Diagnosis</td>\n",
       "      <td>d_5550</td>\n",
       "      <td>Inflammatory Bowel Disease</td>\n",
       "      <td>Crohn’s disease of small intestine, including ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>555.1</td>\n",
       "      <td>ICD-9 Diagnosis</td>\n",
       "      <td>d_5551</td>\n",
       "      <td>Inflammatory Bowel Disease</td>\n",
       "      <td>Crohn’s disease of large intestine (regional c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>555.2</td>\n",
       "      <td>ICD-9 Diagnosis</td>\n",
       "      <td>d_5552</td>\n",
       "      <td>Inflammatory Bowel Disease</td>\n",
       "      <td>Crohn’s disease of small intestine with large ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>555.9</td>\n",
       "      <td>ICD-9 Diagnosis</td>\n",
       "      <td>d_5559</td>\n",
       "      <td>Inflammatory Bowel Disease</td>\n",
       "      <td>Crohn’s disease of unspecified site (regional ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>713.1</td>\n",
       "      <td>ICD-9 Diagnosis</td>\n",
       "      <td>d_7131</td>\n",
       "      <td>Inflammatory Bowel Disease</td>\n",
       "      <td>Arthropathy associated with gastrointestinal c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Code      Code_System Internal_Code                       Group  \\\n",
       "0  555.0  ICD-9 Diagnosis        d_5550  Inflammatory Bowel Disease   \n",
       "1  555.1  ICD-9 Diagnosis        d_5551  Inflammatory Bowel Disease   \n",
       "2  555.2  ICD-9 Diagnosis        d_5552  Inflammatory Bowel Disease   \n",
       "3  555.9  ICD-9 Diagnosis        d_5559  Inflammatory Bowel Disease   \n",
       "4  713.1  ICD-9 Diagnosis        d_7131  Inflammatory Bowel Disease   \n",
       "\n",
       "                                         Description  \n",
       "0  Crohn’s disease of small intestine, including ...  \n",
       "1  Crohn’s disease of large intestine (regional c...  \n",
       "2  Crohn’s disease of small intestine with large ...  \n",
       "3  Crohn’s disease of unspecified site (regional ...  \n",
       "4  Arthropathy associated with gastrointestinal c...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gt_codes = pd.read_csv(gt_codes_path)\n",
    "print(df_gt_codes.shape)\n",
    "df_gt_codes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_codes = df_gt_codes.Internal_Code.tolist()\n",
    "#gt_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages - First time only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install nb-black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from more_itertools import unique_everseen\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x, n_events=1000):\n",
    "    \"\"\"Flatten the 365 dataset into N long events\"\"\"\n",
    "\n",
    "    def get_days(x):\n",
    "        \"\"\"Calculate number of days between events\"\"\"\n",
    "        new_lst = []\n",
    "        counter = 1\n",
    "        counting = False\n",
    "        for event in x:\n",
    "            if event is np.nan or (type(event) == float and math.isnan(event)):\n",
    "                if not counting:\n",
    "                    counting = True\n",
    "                counter += 1\n",
    "            else:\n",
    "\n",
    "                if counting:\n",
    "                    counting = False\n",
    "                    try:\n",
    "                        event = f\"{counter + 1}_days,\" + event\n",
    "                    except:\n",
    "                        print(type(counter), counter)\n",
    "                        print(event, type(event))\n",
    "                    new_lst.append(event)\n",
    "                    counter = 0\n",
    "                else:\n",
    "                    event = \"1_days,\" + event\n",
    "                    new_lst.append(event)\n",
    "\n",
    "        return new_lst\n",
    "\n",
    "    # count days with no events, move admission/discharge to the end of the day, dedupe events per day\n",
    "    x = np.array(get_days(x))\n",
    "    lst = [move_ad_dis(str(day).replace(\" \", \"\").split(\",\")) for day in x.ravel(\"K\")]\n",
    "\n",
    "    # flatten, clean up corner cases\n",
    "    lst = [event for day in lst for event in day]\n",
    "    if not lst:\n",
    "        return [\"<pad>\"] * (n_events - len(lst)) + lst\n",
    "\n",
    "    if \"_days\" in lst[0]:\n",
    "        lst = lst[1:]\n",
    "\n",
    "    if len(lst) >= n_events:\n",
    "        return lst[-n_events:]\n",
    "\n",
    "    return [\"<pad>\"] * (n_events - len(lst)) + lst\n",
    "\n",
    "\n",
    "def move_ad_dis(events_in_day):\n",
    "    \"\"\"Move target_event and patient_id to the end of the list, dedupe events\"\"\"\n",
    "    if not isinstance(events_in_day, list):\n",
    "        return events_in_day\n",
    "\n",
    "    events_in_day = list(unique_everseen(events_in_day))\n",
    "    has_admission = False\n",
    "    has_discharge = False\n",
    "\n",
    "    if \"admission\" in events_in_day:\n",
    "        has_admission = True\n",
    "        events_in_day.remove(\"admission\")\n",
    "\n",
    "    if \"discharge\" in events_in_day:\n",
    "        has_discharge = True\n",
    "        events_in_day.remove(\"discharge\")\n",
    "\n",
    "    #     if has_admission:\n",
    "    #         events_in_day.append(\"admission\")\n",
    "\n",
    "    #     if has_discharge:\n",
    "    #         events_in_day.append(\"discharge\")\n",
    "\n",
    "    return events_in_day\n",
    "\n",
    "\n",
    "def get_flat_df(raw_df, x_lst, copy_lst, n_events):\n",
    "    \"\"\"\n",
    "    Function to flatten dataframe into 1000 long sequence.\n",
    "\n",
    "    Calls function flatten, which in turn calls move_ad_dis\n",
    "    \"\"\"\n",
    "    columns = [str(x) for x in range(n_events - 1, -1, -1)]\n",
    "    flat_df = pd.DataFrame(\n",
    "        raw_df[x_lst]\n",
    "        .apply(\n",
    "            flatten,\n",
    "            args=(n_events,),\n",
    "            axis=1,\n",
    "        )\n",
    "        .tolist(),\n",
    "        columns=columns,\n",
    "    )\n",
    "\n",
    "    for colname in copy_lst:\n",
    "        flat_df[colname] = raw_df[colname].tolist()\n",
    "\n",
    "    return flat_df\n",
    "\n",
    "\n",
    "# Downsample Data to make it balanced\n",
    "# Class count\n",
    "def downsample(df0, label):\n",
    "    \"\"\"Downsample dataset to make classes balanced.\"\"\"\n",
    "    df = df0.copy()\n",
    "    count_class_0, count_class_1 = df[label].value_counts()\n",
    "\n",
    "    # Divide by class\n",
    "    df_class_0 = df[df[label] == 0]\n",
    "    df_class_1 = df[df[label] == 1]\n",
    "\n",
    "    df_class_0_under = df_class_0.sample(count_class_1)\n",
    "\n",
    "    df = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
    "    df = df.sample(frac=1)  # shuffle\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_data(df, test_size, label, output_dir, n_events=1000):\n",
    "    \"\"\"Split data into train/val/test sets. test_size is the fraction of val/test sets\"\"\"\n",
    "    feature_names = [str(x) for x in range(n_events - 1, -1, -1)]\n",
    "    x_train, x_val_test, y_train, y_val_test = train_test_split(\n",
    "        df[feature_names],\n",
    "        df[label],\n",
    "        test_size=2 * test_size,\n",
    "        stratify=df[label],\n",
    "    )\n",
    "    x_val, x_test, y_val, y_test = train_test_split(\n",
    "        x_val_test, y_val_test, test_size=0.5\n",
    "    )\n",
    "    df_train = pd.concat([x_train, y_train], axis=1)\n",
    "    df_val = pd.concat([x_val, y_val], axis=1)\n",
    "    df_test = pd.concat([x_test, y_test], axis=1)\n",
    "\n",
    "    df_train.to_csv(os.path.join(output_dir, \"train.csv\"), index=False)\n",
    "    df_val.to_csv(os.path.join(output_dir, \"val.csv\"), index=False)\n",
    "    df_test.to_csv(os.path.join(output_dir, \"test.csv\"), index=False)\n",
    "    return df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for Month: 20110101....\n",
      "Flat Shape = (1903423, 1002), Downsampled Shape = (2160, 1002)\n"
     ]
    }
   ],
   "source": [
    "NROWS = None\n",
    "\n",
    "N_DAYS = 365  # Number of input days\n",
    "N_EVENTS = 1000  # Output number of events\n",
    "\n",
    "X_INPUT_LST = [\n",
    "    str(x) for x in range(N_DAYS, -1, -1)\n",
    "]  # total days in datasets, usually 365.\n",
    "LABEL = \"d_00845\"\n",
    "UID_COLUMN = \"patient_id\"\n",
    "COPY_LIST = [LABEL, UID_COLUMN]\n",
    "\n",
    "SPLIT_TEST_SIZE = 0.15  # 70/15/15 splits\n",
    "\n",
    "RAW_DATA_DIR = \"/home/ec2-user/SageMaker/CMSAI/modeling/tes/data/anonymize/AE/Data/Anonymized/365NoDeath/\"\n",
    "OUTPUT_ORIGINAL_DIR = \"./output/data/1000/original/\"\n",
    "\n",
    "OUTPUT_DOWNSAMPLED_DIR = \"./output/data/1000/downsampled/\"\n",
    "\n",
    "os.makedirs(OUTPUT_ORIGINAL_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DOWNSAMPLED_DIR, exist_ok=True)\n",
    "\n",
    "df_all = None\n",
    "df_down_all = None\n",
    "for i in range(1, 12):\n",
    "    MONTH = f\"2011{i:02}01\"\n",
    "    print(f\"Processing data for Month: {MONTH}....\")\n",
    "\n",
    "    IN_FNAME = f\"ae_patients_365_{MONTH}.csv\"\n",
    "    OUT_FNAME = f\"{MONTH}.csv\"\n",
    "\n",
    "    raw_data_path = os.path.join(RAW_DATA_DIR, IN_FNAME)\n",
    "    flat_data_path = os.path.join(OUTPUT_ORIGINAL_DIR, OUT_FNAME)\n",
    "    flat_downsampled_path = os.path.join(OUTPUT_DOWNSAMPLED_DIR, OUT_FNAME)\n",
    "\n",
    "    df_raw = pd.read_csv(raw_data_path, low_memory=False, nrows=NROWS)\n",
    "\n",
    "    df_flat = get_flat_df(df_raw, X_INPUT_LST, COPY_LIST, N_EVENTS)\n",
    "\n",
    "    df_down = downsample(df_flat, LABEL)\n",
    "    print(f\"Flat Shape = {df_flat.shape}, Downsampled Shape = {df_down.shape}\")\n",
    "\n",
    "    # Save the data\n",
    "    df_flat.to_csv(flat_data_path, index=False)\n",
    "    df_down.to_csv(flat_downsampled_path, index=False)\n",
    "\n",
    "    # Split data\n",
    "    output_dir = os.path.join(OUTPUT_ORIGINAL_DIR, f\"splits/{MONTH}/\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    _ = split_data(df_flat, SPLIT_TEST_SIZE, LABEL, output_dir, n_events=N_EVENTS)\n",
    "\n",
    "    output_dir = os.path.join(OUTPUT_DOWNSAMPLED_DIR, f\"splits/{MONTH}/\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    _ = split_data(df_down, SPLIT_TEST_SIZE, LABEL, output_dir, n_events=N_EVENTS)\n",
    "\n",
    "    # Combine data\n",
    "    df_flat[UID_COLUMN] = df_flat[UID_COLUMN] + f\"_{MONTH}\"\n",
    "    df_down[UID_COLUMN] = df_down[UID_COLUMN] + f\"_{MONTH}\"\n",
    "    if df_all is None:\n",
    "        df_all = df_flat.copy()\n",
    "        df_down_all = df_down.copy()\n",
    "    else:\n",
    "        df_all = pd.concat([df_all, df_flat], axis=0)\n",
    "        df_down_all = pd.concat([df_down_all, df_down], axis=0)\n",
    "    del df_raw, df_flat, df_down\n",
    "    print(\"*\" * 50)\n",
    "\n",
    "# Shuffle dataset\n",
    "df_all = df_all.sample(frac=1)\n",
    "df_down_all = df_down_all.sample(frac=1)\n",
    "print(\"all_flat_data shape: \", df_all.shape)\n",
    "print(\"all_down_data shape: \", df_down_all.shape)\n",
    "\n",
    "# Split data\n",
    "output_dir = os.path.join(OUTPUT_ORIGINAL_DIR, \"splits/all\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "_ = split_data(df_all, SPLIT_TEST_SIZE, LABEL, output_dir, n_events=N_EVENTS)\n",
    "\n",
    "output_dir = os.path.join(OUTPUT_DOWNSAMPLED_DIR, \"splits/all\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "_ = split_data(df_down_all, SPLIT_TEST_SIZE, LABEL, output_dir, n_events=N_EVENTS)\n",
    "\n",
    "# Save data\n",
    "all_fname = \"all.csv\"\n",
    "all_data_path = os.path.join(OUTPUT_ORIGINAL_DIR, all_fname)\n",
    "all_down_data_path = os.path.join(OUTPUT_DOWNSAMPLED_DIR, all_fname)\n",
    "df_all.to_csv(all_data_path, index=False)\n",
    "df_down_all.to_csv(all_down_data_path, index=False)\n",
    "print(\"SUCCESS!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
