{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Case: PPP and NNN cases only\n",
    "Author: Lin Lee Cheong <br>\n",
    "Date: 12/21/2020 <br> <br>\n",
    "\n",
    "PPP event is defined as one adverse token and one adverse helper token. \n",
    "- adverse_tokens:\n",
    "    - AMI\n",
    "    - PH\n",
    "    - ARR\n",
    "    - CHF\n",
    "\n",
    "- adverse_helper_tokens:\n",
    "    - apnea\n",
    "    - furosemide\n",
    "    - pneumonia\n",
    "    - high_creatinine\n",
    "    - tachycardia\n",
    "    - resistent_hyp\n",
    "    \n",
    "Findings:\n",
    "1. Main source of variations between SHAP values originals from model overtraining. Models with large feature space ends up with strange attributions of features. The sweet spot seems to be around 1:10 param:obs, slower learning rate, aggressive stopping. <If the feature attributes don't make sense, it means you've overtrained>.\n",
    "2. For SHAP: use negative background to backfill missingness that calculates the effects of the given feature. About 500 is sufficient. \n",
    "\n",
    "TODO:\n",
    "1. First event still has plenty of high attributes. Need to look into trainable init hidden states.\n",
    "2. Start reducing probabilities (performance drop) and see how the 'latching on' of important features change\n",
    "3. Look into how to do feature comparisons\n",
    "4. Define attention models and see how they help in such cases.\n",
    "5. Retry this on the original toy dataset\n",
    "6. Multiprocessing explainer otherwise it will take forever!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install pathos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pathos.multiprocessing as multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import deep_id_pytorch_debug2 as deep_id_pytorch_debug\n",
    "\n",
    "from lstm_models import *\n",
    "from lstm_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 1e9\n",
    "min_freq = 1\n",
    "\n",
    "seq_len = 30\n",
    "\n",
    "train_data_path = \"../../data/toy_dataset/data/30_ppp_nnn_only/train_30000.csv\"\n",
    "valid_data_path = \"../../data/toy_dataset/data/30_ppp_nnn_only/val_3000.csv\"\n",
    "test_data_path = \"../../data/toy_dataset/data/30/test_pos3.csv\"\n",
    "\n",
    "test_data_path2 = \"../../data/toy_dataset/data/30/test.csv\"\n",
    "\n",
    "model_save_path = './models/lstm/lstm_seq_ppp_nnn_only_{}'.format(seq_len)\n",
    "results_save_path = \"./model_results/lstm/lstm_seq_ppp_nnn_only_{}\".format(seq_len)\n",
    "batch_size = 64\n",
    "\n",
    "n_epochs = 1\n",
    "stop_num = 2\n",
    "\n",
    "embedding_dim = 5\n",
    "hidden_dim = 8\n",
    "bidirectional = True\n",
    "dropout = 0.4\n",
    "n_layers = 3\n",
    "\n",
    "target_colname = 'label'\n",
    "uid_colname = 'patient_id'\n",
    "x_inputs = [str(x) for x in range(29, -1, -1)]\n",
    "target_value = '1'\n",
    "\n",
    "rev = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n"
     ]
    }
   ],
   "source": [
    "for fp in [model_save_path, results_save_path]:\n",
    "    if not os.path.isdir(os.path.split(fp)[0]):\n",
    "        print(f'New directory created: {fp}')\n",
    "        os.makedirs(os.path.split(fp)[0])\n",
    "\n",
    "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
    "model_device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "#model_device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vocab and Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataset from ../../data/toy_dataset/data/30_ppp_nnn_only/train_30000.csv..\n",
      "Success!\n",
      "Building dataset from ../../data/toy_dataset/data/30_ppp_nnn_only/val_3000.csv..\n",
      "Success!\n",
      "Building dataset from ../../data/toy_dataset/data/30/test_pos3.csv..\n",
      "Success!\n",
      "Building dataset from ../../data/toy_dataset/data/30/test.csv..\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "train_dataset, vocab = build_lstm_dataset(\n",
    "                                train_data_path,\n",
    "                                min_freq=min_freq,\n",
    "                                uid_colname=\"patient_id\",\n",
    "                                target_colname=\"label\",\n",
    "                                max_len=seq_len,\n",
    "                                target_value=target_value,\n",
    "                                vocab=None,\n",
    "                                nrows=nrows,\n",
    "                                rev=rev\n",
    "                            )\n",
    "valid_dataset, _ = build_lstm_dataset(\n",
    "                                valid_data_path,\n",
    "                                min_freq=min_freq,\n",
    "                                uid_colname=\"patient_id\",\n",
    "                                target_colname=\"label\",\n",
    "                                max_len=seq_len,\n",
    "                                target_value=target_value,\n",
    "                                vocab=vocab,\n",
    "                                nrows=nrows,\n",
    "                                rev=rev\n",
    "                            )\n",
    "\n",
    "test_dataset, _ = build_lstm_dataset(\n",
    "                                test_data_path,\n",
    "                                min_freq=min_freq,\n",
    "                                uid_colname=\"patient_id\",\n",
    "                                target_colname=\"label\",\n",
    "                                max_len=seq_len,\n",
    "                                target_value=target_value,\n",
    "                                vocab=vocab,\n",
    "                                nrows=nrows,\n",
    "                                rev=rev\n",
    "                            )\n",
    "\n",
    "test_dataset2, _ = build_lstm_dataset(\n",
    "                                test_data_path2,\n",
    "                                min_freq=min_freq,\n",
    "                                uid_colname=\"patient_id\",\n",
    "                                target_colname=\"label\",\n",
    "                                max_len=seq_len,\n",
    "                                target_value=target_value,\n",
    "                                vocab=vocab,\n",
    "                                nrows=nrows,\n",
    "                                rev=rev\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "test_dataloader2 = DataLoader(\n",
    "    test_dataset2,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def count_tokens(dataloader, del_pad=True):\n",
    "    counter = None\n",
    "    for _, _, idxes in dataloader:\n",
    "        idxes = idxes.flatten().tolist()\n",
    "        if counter is None:\n",
    "            counter = Counter(idxes)\n",
    "        else:\n",
    "            counter.update(idxes)\n",
    "    counter = dict(counter)\n",
    "    if del_pad:\n",
    "        del counter[0]\n",
    "    return counter\n",
    "\n",
    "\n",
    "def plot_data(counter, title):\n",
    "    plt.bar(counter.keys(), counter.values(), width=1.0, color='g')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Token IDs')\n",
    "    plt.ylabel('Freqs')\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_counter = count_tokens(train_dataloader, del_pad=True)\n",
    "# plot_data(train_counter, 'Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_counter = count_tokens(valid_dataloader, del_pad=True)\n",
    "# plot_data(val_counter, 'Val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_counter2 = count_tokens(test_dataloader2, del_pad=True)\n",
    "# plot_data(test_counter2, 'Test All')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_counter = count_tokens(test_dataloader, del_pad=True)\n",
    "# plot_data(test_counter, 'Test PPP Only')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1,2,3,4,5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,1,2,3,4,5\n"
     ]
    }
   ],
   "source": [
    "! echo ${CUDA_VISIBLE_DEVICES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleLSTM(embedding_dim, hidden_dim, vocab, model_device, nlayers=n_layers, dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleLSTM(embedding_dim, hidden_dim, vocab, model_device, nlayers=n_layers, dropout=dropout)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4465"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_function = nn.CrossEntropyLoss()\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_EXECUTION_FAILED",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-ed35965fa498>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     train_loss, train_auc = epoch_train_lstm(\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     )\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/CMSAI_Research/model/toy_simple/lstm_utils.py\u001b[0m in \u001b[0;36mepoch_train_lstm\u001b[0;34m(model, dataloader, optimizer, criterion, test)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0midxed_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midxed_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxed_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0;31m# predictions = model(text, text_lengths).squeeze(1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/CMSAI_Research/model/toy_simple/lstm_models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    109\u001b[0m         )\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mpacked_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_embedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n\u001b[0;32m--> 562\u001b[0;31m                               self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED"
     ]
    }
   ],
   "source": [
    "best_valid_loss = float(\"inf\")\n",
    "valid_worse_loss = 0  # enable early stopping\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_auc = epoch_train_lstm(\n",
    "        model, train_dataloader, optimizer, loss_function\n",
    "    )\n",
    "\n",
    "    valid_loss, valid_auc = epoch_val_lstm(\n",
    "        model, valid_dataloader, loss_function\n",
    "    )  # , return_preds=False\n",
    "    # )\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(\"Saved Model, epoch {}\".format(epoch))\n",
    "        valid_worse_loss = 0\n",
    "\n",
    "    else:\n",
    "        valid_worse_loss += 1\n",
    "        if valid_worse_loss == stop_num:\n",
    "            print(\"EARLY STOP ------\")\n",
    "            break\n",
    "\n",
    "    scheduler.step()\n",
    "    print(\n",
    "        f\"Train Loss: {train_loss:.3f} | Train AUC: {train_auc:.2f} \\t Val. Loss: {valid_loss:.3f} |  Val. AUC: {valid_auc:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load best model for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for SimpleLSTM:\n\tUnexpected key(s) in state_dict: \"attn_layer.weight\", \"attn_layer.bias\", \"context_layer.weight\", \"context_layer.bias\". \n\tsize mismatch for pred_layer.weight: copying a param with shape torch.Size([1, 32]) from checkpoint, the shape in current model is torch.Size([1, 16]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-78b9fbaa84f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_save_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 830\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    831\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SimpleLSTM:\n\tUnexpected key(s) in state_dict: \"attn_layer.weight\", \"attn_layer.bias\", \"context_layer.weight\", \"context_layer.bias\". \n\tsize mismatch for pred_layer.weight: copying a param with shape torch.Size([1, 32]) from checkpoint, the shape in current model is torch.Size([1, 16])."
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_auc, val_labs, val_pred_scores = epoch_val_lstm(\n",
    "    model, valid_dataloader, loss_function, return_preds=True\n",
    ")\n",
    "print(f\"Val Loss: {val_loss:.3f} | Val AUC: {val_auc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss2, test_auc2 = epoch_val_lstm(\n",
    "   model, test_dataloader2, loss_function)#, return_preds=False\n",
    "print(f\"Test Loss (All): {test_loss2:.3f} | Test AUC (All): {test_auc2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_auc = epoch_val_lstm(\n",
    "   model, test_dataloader, loss_function)#, return_preds=False\n",
    "print(f\"Test Loss (PPP only): {test_loss:.3f} | Test AUC (PPP only): {test_auc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([1 if x > 0.5 else 0 for x in val_pred_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.distplot(val_pred_scores, kde=False, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_auc, labs, pred_scores = epoch_val_lstm(\n",
    "    model, test_dataloader, loss_function, return_preds=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([1 if x > 0.5 else 0 for x in pred_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.distplot(pred_scores, kde=False, bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get SHAP values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the negative cases as background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select non-AE cases only as background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_background = 500\n",
    "sel_set = []\n",
    "for batch in valid_dataloader:\n",
    "    sel_set.extend(\n",
    "        [\n",
    "            (uid, lab, idxes)\n",
    "            for (uid, lab, idxes) in zip(batch[0], batch[1], batch[2])\n",
    "            if lab == 0\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    if len(sel_set) > n_background:\n",
    "        break\n",
    "        \n",
    "sel_set = sel_set[:n_background]\n",
    "    \n",
    "background_ids = [x[0] for x in sel_set]\n",
    "background_labels = [x[1] for x in sel_set]\n",
    "background_idxes = [x[2] for x in sel_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_idxes = torch.stack(background_idxes)\n",
    "background_idxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_data, bg_masks = model.get_all_ids_masks(background_idxes, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = deep_id_pytorch_debug.CustomPyTorchDeepIDExplainer(\n",
    "    model, bg_data, bg_masks, gpu_memory_efficient=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train() # in case that shap complains that autograd cannot be called\n",
    "lstm_values = []\n",
    "features = []\n",
    "start = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get AE events to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 100\n",
    "sel_set = []\n",
    "for batch in test_dataloader:\n",
    "    sel_set.extend(\n",
    "        [\n",
    "            (uid, lab, idxes)\n",
    "            for (uid, lab, idxes) in zip(batch[0], batch[1], batch[2])\n",
    "            if lab == 1\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    if len(sel_set) > n_test:\n",
    "        break\n",
    "        \n",
    "sel_set = sel_set[:n_test]\n",
    "    \n",
    "test_ids = [x[0] for x in sel_set]\n",
    "test_labels = [x[1] for x in sel_set]\n",
    "test_idxes = [x[2] for x in sel_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idxes = torch.stack(test_idxes)\n",
    "test_idxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_masks = model.get_all_ids_masks(test_idxes, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(test_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "lstm_shap_values_p = explainer.shap_values_parallel(test_data, test_masks)\n",
    "print('Total time: {:.2f}mins'.format((time.time()-start)/60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "lstm_shap_values = explainer.shap_values(test_data, test_masks)\n",
    "print('Total time: {:.2f}mins'.format((time.time()-start)/60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_values, features = [], []\n",
    "for idx, label in zip(range(test_idxes.shape[0]), test_labels):\n",
    "    features.append([model.vocab.itos(x) for x in test_idxes[idx].numpy()])\n",
    "    w = []\n",
    "    for seq_idx, tok_idx in enumerate(test_idxes[idx].numpy()):\n",
    "        w.append(lstm_shap_values[idx, seq_idx, tok_idx])\n",
    "    lstm_values.append(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mix background + dropout in LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WITH NEG AS BACKGROUND + EMBEDDING DROPOUT + 30000 observation in training + \n",
    "# reduced dim space, 3 layers, bidirectional\n",
    "# raise dropout, single epoch training, drop training rate\n",
    "\n",
    "#for idx in range(n_test):\n",
    "for idx in range(10):\n",
    "    df = pd.DataFrame()\n",
    "    df['events'] = features[idx]\n",
    "    df['shap_vals'] = lstm_values[idx]\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    ax = sns.barplot(x=df.index, y=df.shap_vals, orient='v')\n",
    "    z = ax.set_xticklabels(df.events, rotation=90)\n",
    "    plt.title(f\"idx: {idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find overall contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for idx in range(n_test):\n",
    "    for token, value in zip(features[idx], lstm_values[idx]):\n",
    "        if token not in results:\n",
    "            results[token] = {}\n",
    "            results[token]['val'] = 0\n",
    "            results[token]['count'] = 0\n",
    "        results[token]['val'] += value\n",
    "        results[token]['count'] += 1\n",
    "        \n",
    "for token in results.keys():\n",
    "    results[token]['ave'] = results[token]['val'] / results[token]['count']\n",
    "\n",
    "results_df = pd.DataFrame()\n",
    "res = [(k, results[k]['ave'], results[k]['val']) for k in results.keys()]\n",
    "results_df['token'] = [i[0] for i in res]\n",
    "results_df['ave'] = [i[1] for i in res]\n",
    "results_df['tot'] = [i[2] for i in res]\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.sort_values('ave', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['ave_abs'] = results_df.ave.abs()\n",
    "results_df.sort_values('ave_abs', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
