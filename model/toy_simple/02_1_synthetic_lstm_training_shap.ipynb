{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple LSTM Model Training and SHAP computation using the Synthetic-events Dataset\n",
    "\n",
    "**Author: Tesfagabir Meharizghi<br>Last Updated: 01/07/2021**\n",
    "\n",
    "This notebook does the following actions:\n",
    "- Model training using the given parameters\n",
    "- Model selection using Intersection Similarity Score between ground truth helping features and predicted ones\n",
    "    * Early stopping using Intersection similarity score criteria\n",
    "- Computes SHAP values and visualizes for a few examples\n",
    "- Visualizes the train/val/test probability scores from each trained model\n",
    "- Visualizes the Intersection Similarity Scores for val/test splits\n",
    "- Finally, after tweaking the parameters, it gets the best model for the given model architecture and dataset\n",
    "\n",
    "Outputs:\n",
    "- The following artifacts are saved:\n",
    "    * Model artifacts\n",
    "    * SHAP values and their corresponding scores for the specified number of val/test examples\n",
    "\n",
    "Model Architecture Used:\n",
    "- SimpleLSTM\n",
    "\n",
    "Dataset:\n",
    "- Synthetic-events (Toy Dataset)\n",
    "\n",
    "Requirements:\n",
    "- Make sure that you have already generated the synthetic toy dataset (train/val/test splits) using [Create_toy_dataset.ipynb](../../data/toy_dataset/Create_toy_dataset.ipynb).\n",
    "\n",
    "Next Steps:\n",
    "- Once you train different models, save the best one you found\n",
    "- Do also the same for other models architectures (SimpleLSTM, XGB, etc.) using the separate notebooks\n",
    "- Finally, go to [this ipynb]() to compare to compare the models' performances and shap values usig Jaccard Similarity Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install nb-black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install botocore==1.12.201\n",
    "\n",
    "#! pip install shap\n",
    "#! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from urllib.parse import urlparse\n",
    "import tarfile\n",
    "import pickle\n",
    "import shutil\n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "import deep_id_pytorch\n",
    "\n",
    "import lstm_utils as l_utils\n",
    "import lstm_models as lstm\n",
    "import shap_jacc_utils as sj_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleLSTM Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 1e9\n",
    "min_freq = 1\n",
    "\n",
    "seq_len = 30\n",
    "\n",
    "batch_size = 64  # For model training\n",
    "\n",
    "n_epochs = 10\n",
    "stop_num = 2\n",
    "\n",
    "embedding_dim = 8\n",
    "hidden_dim = 16\n",
    "nlayers = 1\n",
    "bidirectional = True\n",
    "dropout = 0.2\n",
    "init_type='zero' #Possible values: zero/learned\n",
    "\n",
    "target_colname = \"label\"\n",
    "uid_colname = \"patient_id\"\n",
    "target_value = \"1\"\n",
    "\n",
    "rev = False\n",
    "\n",
    "# For model early stopping criteria\n",
    "EARLY_STOPPING = \"intersection_similarity\"  # Values are any of these: ['intersection_similarity', 'loss']\n",
    "\n",
    "# SHAP related constants\n",
    "N_BACKGROUND = 500  # Number of background examples\n",
    "BACKGROUND_NEGATIVE_ONLY = True  # If negative examples are used as background\n",
    "N_VALID_EXAMPLES = 32  # Number of validation examples to be used during model training\n",
    "N_TEST_EXAMPLES = 64  # Number of test examples\n",
    "TEST_POSITIVE_ONLY = True  # If only positive examples are selected\n",
    "IS_TEST_RANDOM = (\n",
    "    True  # If random test/val examples are selected for shap value computation\n",
    ")\n",
    "SORT_SHAP_VALUES = False  # Whether to sort per-patient shap values for visualization\n",
    "\n",
    "train_data_path = \"../../data/toy_dataset/data/{}/train.csv\".format(seq_len)\n",
    "valid_data_path = \"../../data/toy_dataset/data/{}/val.csv\".format(seq_len)\n",
    "test_data_path = \"../../data/toy_dataset/data/{}/test.csv\".format(seq_len)\n",
    "\n",
    "model_name = \"lstm\"\n",
    "model_save_path = \"./output/{}/{}/models/model_{}.pkl\".format(seq_len, model_name, \"{}\")\n",
    "shap_save_path = \"./output/{}/{}/shap/{}_shap_{}.pkl\".format(\n",
    "    seq_len, model_name, \"{}\", \"{}\"\n",
    ")  # SHAP values path for a given dataset split (train/val/test) (data format (features, scores, patient_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New directory created: ./output/30/lstm-att/models\n",
      "New directory created: ./output/30/lstm-att/shap\n",
      "Cuda available: True\n",
      "Total GPUs: 4\n"
     ]
    }
   ],
   "source": [
    "# SimpleLSTM Model Output Directory\n",
    "model_save_dir = os.path.dirname(model_save_path)\n",
    "shap_save_dir = os.path.dirname(shap_save_path)\n",
    "if os.path.exists(model_save_dir):\n",
    "    # Remove model save directory if exists\n",
    "    shutil.rmtree(model_save_dir)\n",
    "if os.path.exists(shap_save_dir):\n",
    "    # Remove model save directory if exists\n",
    "    shutil.rmtree(shap_save_dir)\n",
    "os.makedirs(model_save_dir)\n",
    "os.makedirs(shap_save_dir)\n",
    "print(f\"New directory created: {model_save_dir}\")\n",
    "print(f\"New directory created: {shap_save_dir}\")\n",
    "\n",
    "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
    "print(\"Total GPUs:\", torch.cuda.device_count())\n",
    "model_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Vocab and Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataset from ../../data/toy_dataset/data/30/train.csv..\n",
      "Success!\n",
      "Building dataset from ../../data/toy_dataset/data/30/val.csv..\n",
      "Success!\n",
      "Building dataset from ../../data/toy_dataset/data/30/test.csv..\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "train_dataset, vocab = l_utils.build_lstm_dataset(\n",
    "    train_data_path,\n",
    "    min_freq=min_freq,\n",
    "    uid_colname=\"patient_id\",\n",
    "    target_colname=\"label\",\n",
    "    max_len=seq_len,\n",
    "    target_value=target_value,\n",
    "    vocab=None,\n",
    "    nrows=nrows,\n",
    "    rev=rev,\n",
    ")\n",
    "valid_dataset, _ = l_utils.build_lstm_dataset(\n",
    "    valid_data_path,\n",
    "    min_freq=min_freq,\n",
    "    uid_colname=\"patient_id\",\n",
    "    target_colname=\"label\",\n",
    "    max_len=seq_len,\n",
    "    target_value=target_value,\n",
    "    vocab=vocab,\n",
    "    nrows=nrows,\n",
    "    rev=rev,\n",
    ")\n",
    "\n",
    "test_dataset, _ = l_utils.build_lstm_dataset(\n",
    "    test_data_path,\n",
    "    min_freq=min_freq,\n",
    "    uid_colname=\"patient_id\",\n",
    "    target_colname=\"label\",\n",
    "    max_len=seq_len,\n",
    "    target_value=target_value,\n",
    "    vocab=vocab,\n",
    "    nrows=nrows,\n",
    "    rev=rev,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset, batch_size=batch_size, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm.SimpleLSTM(\n",
    "    embedding_dim, hidden_dim, vocab, model_device, nlayers=nlayers, dropout=dropout, init_type=init_type,\n",
    ")\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleLSTM(\n",
       "  (emb_layer): Embedding(32, 8, padding_idx=0)\n",
       "  (lstm): LSTM(8, 16, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (pred_layer): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (dpt): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the # of models params and check the accepted ratio of #params/#examples (accepted<=0.1)...\n",
      "Total Model Params=3715, Total Examples=16000, Ratio=0.2321875, Test Passed=False\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Computing the # of models params and check the accepted ratio of #params/#examples (accepted<=0.1)...\"\n",
    ")\n",
    "# Get the number of trainable parameters\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total_examples = 16000\n",
    "ratio = float(total_params) / total_examples\n",
    "passed = ratio <= 0.1\n",
    "print(\n",
    "    f\"Total Model Params={total_params}, Total Examples={total_examples}, Ratio={ratio}, Test Passed={passed}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_function = nn.CrossEntropyLoss()\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 4, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing SHAP Intersection Similarity for epoch=0...\n",
      "Epoch: 01 | Epoch Time: 2m 8s\n",
      "saved ./output/30/lstm-att/shap/val_shap_00.pkl pickle..\n",
      "Saved Model and SHAP values, epoch 0\n",
      "Train Loss: 0.370 | Train AUC: 0.89 \t Val. Loss: 0.323 |  Val. AUC: 0.9006 | Val Int. Similarity: 0.2448\n",
      "Computing SHAP Intersection Similarity for epoch=1...\n",
      "Epoch: 02 | Epoch Time: 2m 8s\n",
      "Train Loss: 0.350 | Train AUC: 0.90 \t Val. Loss: 0.321 |  Val. AUC: 0.9029 | Val Int. Similarity: 0.1354\n",
      "Computing SHAP Intersection Similarity for epoch=2...\n"
     ]
    }
   ],
   "source": [
    "if EARLY_STOPPING == \"intersection_similarity\":\n",
    "    best_valid = float(\"-inf\")\n",
    "else:\n",
    "    best_valid = float(\"inf\")\n",
    "worse_valid = 0  # enable early stopping\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_auc = l_utils.epoch_train_lstm(\n",
    "        model, train_dataloader, optimizer, loss_function\n",
    "    )\n",
    "\n",
    "    valid_loss, valid_auc = l_utils.epoch_val_lstm(\n",
    "        model, valid_dataloader, loss_function\n",
    "    )  # , return_preds=False\n",
    "\n",
    "    val_shap_path = shap_save_path.format(\"val\", f\"{epoch:02}\")\n",
    "    if EARLY_STOPPING == \"intersection_similarity\":\n",
    "        print(f\"Computing SHAP Intersection Similarity for epoch={epoch}...\")\n",
    "        (features, scores, patients,) = sj_utils.get_lstm_features_and_shap_scores(\n",
    "            model,\n",
    "            train_dataloader,\n",
    "            valid_dataloader,\n",
    "            seq_len,\n",
    "            val_shap_path,\n",
    "            save_output=False,\n",
    "            n_background=N_BACKGROUND,\n",
    "            background_negative_only=BACKGROUND_NEGATIVE_ONLY,\n",
    "            n_test=N_VALID_EXAMPLES,\n",
    "            test_positive_only=TEST_POSITIVE_ONLY,\n",
    "            is_test_random=IS_TEST_RANDOM,\n",
    "        )\n",
    "\n",
    "        valid_sim, _ = sj_utils.get_model_intersection_similarity((features, scores))\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = l_utils.epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n",
    "\n",
    "    if EARLY_STOPPING == \"intersection_similarity\":\n",
    "        if valid_sim > best_valid:\n",
    "            best_valid = valid_sim\n",
    "            save_path = model_save_path.format(str(epoch).zfill(2))\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            sj_utils.save_pickle((features, scores, patients), val_shap_path)\n",
    "            print(\"Saved Model and SHAP values, epoch {}\".format(epoch))\n",
    "            worse_valid = 0\n",
    "        else:\n",
    "            worse_valid += 1\n",
    "            if worse_valid == stop_num:\n",
    "                print(\"EARLY STOP ------\")\n",
    "                break\n",
    "    else:\n",
    "        if valid_loss < best_valid:\n",
    "            best_valid = valid_loss\n",
    "            save_path = model_save_path.format(str(epoch).zfill(2))\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(\"Saved Model, epoch {}\".format(epoch))\n",
    "            worse_valid = 0\n",
    "        else:\n",
    "            worse_valid += 1\n",
    "            if worse_valid == stop_num:\n",
    "                print(\"EARLY STOP ------\")\n",
    "                break\n",
    "\n",
    "    scheduler.step()\n",
    "    sim_message = \"\"\n",
    "    if EARLY_STOPPING == \"intersection_similarity\":\n",
    "        sim_message = f\"| Val Int. Similarity: {valid_sim:.4f}\"\n",
    "    print(\n",
    "        f\"Train Loss: {train_loss:.3f} | Train AUC: {train_auc:.2f} \\t Val. Loss: {valid_loss:.3f} |  Val. AUC: {valid_auc:.4f} {sim_message}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get paths of each saved model\n",
    "models_paths = sj_utils.get_model_paths(model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_models = len(models_paths)\n",
    "for i, model_path in enumerate(models_paths):\n",
    "    print(f\"Processing for model {os.path.basename(model_path)} ...\")\n",
    "    # Load trained weights\n",
    "    print(\"Loading the trained weights...\")\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    ##Get Train/Val/Test Scores\n",
    "    print(\"Computing the models performances for train/val/test splits...\")\n",
    "    train_loss, train_auc, train_labels, train_scores = l_utils.epoch_val_lstm(\n",
    "        model, train_dataloader, loss_function, return_preds=True\n",
    "    )\n",
    "    val_loss, val_auc, val_labels, val_scores = l_utils.epoch_val_lstm(\n",
    "        model, valid_dataloader, loss_function, return_preds=True\n",
    "    )\n",
    "    test_loss, test_auc, test_labels, test_scores = l_utils.epoch_val_lstm(\n",
    "        model, test_dataloader, loss_function, return_preds=True\n",
    "    )\n",
    "    print(\"Ploting Histograms of Train/Val/Test Predicted Scores...\")\n",
    "    _, axes = plt.subplots(1, 3, sharex=False, figsize=(15, 5))\n",
    "    # Train\n",
    "    scores = train_scores.flatten().tolist()\n",
    "    axes = sj_utils.plot_histogram(\n",
    "        scores,\n",
    "        title=f\"Train Scores (Loss={train_loss:.4f}, AUC={train_auc:.4f})\",\n",
    "        xlabel=\"Prediction Scores\",\n",
    "        ylabel=\"Frequencies\",\n",
    "        axes=axes,\n",
    "        axes_idx=0,\n",
    "    )\n",
    "    # Val\n",
    "    scores = val_scores.flatten().tolist()\n",
    "    axes = sj_utils.plot_histogram(\n",
    "        scores,\n",
    "        title=f\"Val Scores (Loss={val_loss:.4f}, AUC={val_auc:.4f})\",\n",
    "        xlabel=\"Prediction Scores\",\n",
    "        ylabel=\"\",\n",
    "        axes=axes,\n",
    "        axes_idx=1,\n",
    "    )\n",
    "    # Test\n",
    "    scores = test_scores.flatten().tolist()\n",
    "    axes = sj_utils.plot_histogram(\n",
    "        scores,\n",
    "        title=f\"Test Scores (Loss={test_loss:.4f}, AUC={test_auc:.4f})\",\n",
    "        xlabel=\"Prediction Scores\",\n",
    "        ylabel=\"\",\n",
    "        axes=axes,\n",
    "        axes_idx=2,\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Computing SHAP for {N_VALID_EXAMPLES} positive val examples...\")\n",
    "    epoch = sj_utils.get_epoch_number_from_path(model_path)\n",
    "    val_shap_path = shap_save_path.format(\"val\", f\"{epoch:02}\")\n",
    "    (\n",
    "        features,\n",
    "        scores,\n",
    "        patients,\n",
    "    ) = sj_utils.load_pickle(val_shap_path)\n",
    "\n",
    "    for idx in range(N_VALID_EXAMPLES):\n",
    "        if idx > 2:\n",
    "            break\n",
    "        features1 = features[idx]\n",
    "        scores1 = scores[idx]\n",
    "        patient_id = patients[idx]\n",
    "\n",
    "        df_shap = pd.DataFrame(\n",
    "            np.array([features1, scores1]).T, columns=[\"events\", \"shap_vals\"]\n",
    "        )\n",
    "        df_shap[\"shap_vals\"] = pd.to_numeric(df_shap[\"shap_vals\"])\n",
    "\n",
    "        sj_utils.plot_shap_values(\n",
    "            df_shap, patient_id, sort=SORT_SHAP_VALUES, figsize=(10, 5)\n",
    "        )\n",
    "\n",
    "    print(\"Computing Intersection Similarity...\")\n",
    "    avg_sim, sim = sj_utils.get_model_intersection_similarity((features, scores))\n",
    "    sj_utils.plot_histogram(\n",
    "        sim,\n",
    "        title=f\"Average Intersection Simi={avg_sim:.4f}\",\n",
    "        xlabel=\"Intersection Similarity\",\n",
    "        ylabel=\"Frequencies\",\n",
    "        axes=None,\n",
    "    )\n",
    "\n",
    "    # For the best model, get the final performance (test set) (intersection similarity)\n",
    "    if i == (total_models - 1):\n",
    "        print(\n",
    "            f\"Computing SHAP for {N_TEST_EXAMPLES} positive TEST examples for the final model...\"\n",
    "        )\n",
    "        test_shap_path = shap_save_path.format(\"test\", f\"{epoch:02}\")\n",
    "        (features, scores, patients,) = sj_utils.get_lstm_features_and_shap_scores(\n",
    "            model,\n",
    "            train_dataloader,\n",
    "            test_dataloader,\n",
    "            seq_len,\n",
    "            test_shap_path,\n",
    "            save_output=True,\n",
    "            n_background=N_BACKGROUND,\n",
    "            background_negative_only=BACKGROUND_NEGATIVE_ONLY,\n",
    "            n_test=N_TEST_EXAMPLES,\n",
    "            test_positive_only=TEST_POSITIVE_ONLY,\n",
    "            is_test_random=IS_TEST_RANDOM,\n",
    "        )\n",
    "\n",
    "        for idx in range(N_TEST_EXAMPLES):\n",
    "            if idx > 2:\n",
    "                break\n",
    "            features1 = features[idx]\n",
    "            scores1 = scores[idx]\n",
    "            patient_id = patients[idx]\n",
    "\n",
    "            df_shap = pd.DataFrame(\n",
    "                np.array([features1, scores1]).T,\n",
    "                columns=[\"events\", \"shap_vals\"],\n",
    "            )\n",
    "            df_shap[\"shap_vals\"] = pd.to_numeric(df_shap[\"shap_vals\"])\n",
    "\n",
    "            sj_utils.plot_shap_values(\n",
    "                df_shap, patient_id, sort=SORT_SHAP_VALUES, figsize=(10, 5)\n",
    "            )\n",
    "\n",
    "        print(\"Computing Intersection Similarity...\")\n",
    "        avg_sim, sim = sj_utils.get_model_intersection_similarity((features, scores))\n",
    "        sj_utils.plot_histogram(\n",
    "            sim,\n",
    "            title=f\"Average Intersection Simi={avg_sim:.4f}\",\n",
    "            xlabel=\"Intersection Similarity\",\n",
    "            ylabel=\"Frequencies\",\n",
    "            axes=None,\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            \"Finally computing and visualizing the global feature importance of the best model....\"\n",
    "        )\n",
    "        feat_importance = sj_utils.get_global_feature_importance(features, scores)\n",
    "        sj_utils.plot_global_feature_importance(feat_importance)\n",
    "        print(\"All tasks SUCCESSFULLY completed!\")\n",
    "\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
