{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple LSTM+Attention Model Training and SHAP computation using the Synthetic-events Dataset\n",
    "\n",
    "**Author: Tesfagabir Meharizghi<br>Last Updated: 01/11/2021**\n",
    "\n",
    "This notebook does the following actions:\n",
    "- Model training using the given parameters\n",
    "- Model selection using Intersection Similarity Score between ground truth helping features and predicted ones\n",
    "    * Early stopping using Intersection similarity score criteria\n",
    "- Computes SHAP values and visualizes for a few examples\n",
    "- Visualizes the train/val/test probability scores from each trained model\n",
    "- Visualizes the Intersection Similarity Scores for val/test splits\n",
    "- Finally, after tweaking the parameters, it gets the best model for the given model architecture and dataset\n",
    "\n",
    "Outputs:\n",
    "- The following artifacts are saved:\n",
    "    * Model artifacts\n",
    "    * SHAP values and their corresponding scores for the specified number of val/test examples\n",
    "\n",
    "Model Architecture Used:\n",
    "- LSTM+Attention\n",
    "\n",
    "Dataset:\n",
    "- Synthetic-events (Toy Dataset)\n",
    "- Sequence Length = 300\n",
    "\n",
    "Requirements:\n",
    "- Make sure that you have already generated the synthetic toy dataset (train/val/test splits) using [Create_toy_dataset.ipynb](../../data/toy_dataset/Create_toy_dataset.ipynb).\n",
    "\n",
    "Next Steps:\n",
    "- Once you train different models, save the best one you found\n",
    "- Do also the same for other models architectures (SimpleLSTM, XGB, etc.) using the separate notebooks\n",
    "- Finally, go to [02_4_synthetic_shap_jacc.ipynb](02_4_synthetic_shap_jacc.ipynb) to compare to compare the models' performances and shap values usig Jaccard Similarity Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install nb-black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install botocore==1.12.201\n",
    "\n",
    "#! pip install shap\n",
    "#! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lab_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext lab_black\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext lab_black\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from urllib.parse import urlparse\n",
    "import tarfile\n",
    "import pickle\n",
    "import shutil\n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "import deep_id_pytorch\n",
    "\n",
    "import lstm_utils as l_utils\n",
    "import lstm_models as lstm\n",
    "import att_lstm_models as lstm_att\n",
    "import shap_jacc_utils as sj_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM+Attn Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"lstm-att\"\n",
    "\n",
    "nrows = 1e9\n",
    "min_freq = 1\n",
    "\n",
    "seq_len = 300\n",
    "\n",
    "batch_size = 64  # For model training\n",
    "\n",
    "n_epochs = 10\n",
    "stop_num = 2\n",
    "\n",
    "embedding_dim = 8\n",
    "hidden_dim = 16\n",
    "nlayers = 1\n",
    "bidirectional = True\n",
    "dropout = 0.3\n",
    "init_type = \"zero\"  # Possible values: zero/learned\n",
    "\n",
    "target_colname = \"label\"\n",
    "uid_colname = \"patient_id\"\n",
    "target_value = \"1\"\n",
    "\n",
    "rev = False\n",
    "\n",
    "# For model early stopping criteria\n",
    "EARLY_STOPPING = \"intersection_similarity\"  # Values are any of these: ['intersection_similarity', 'loss']\n",
    "\n",
    "# SHAP related constants\n",
    "N_BACKGROUND = 500  # Number of background examples\n",
    "BACKGROUND_NEGATIVE_ONLY = True  # If negative examples are used as background\n",
    "N_VALID_EXAMPLES = 32  # Number of validation examples to be used during model training\n",
    "N_TEST_EXAMPLES = 128  # Number of test examples #TODO: update here\n",
    "TEST_POSITIVE_ONLY = True  # If only positive examples are selected\n",
    "IS_TEST_RANDOM = (\n",
    "    False  # If random test/val examples are selected for shap value computation\n",
    ")\n",
    "SORT_SHAP_VALUES = False  # Whether to sort per-patient shap values for visualization\n",
    "\n",
    "SHAP_SCORE_ABSOLUTE = False  # Whether to consider the absolute value of a shap score #TODO: Check this before running.\n",
    "\n",
    "train_data_path = \"../../data/toy_dataset/data/{}/train.csv\".format(seq_len)\n",
    "valid_data_path = \"../../data/toy_dataset/data/{}/val.csv\".format(seq_len)\n",
    "test_data_path = \"../../data/toy_dataset/data/{}/test.csv\".format(seq_len)\n",
    "\n",
    "model_save_path = \"./output/{}/{}/models/model_{}.pkl\".format(seq_len, model_name, \"{}\")\n",
    "shap_save_path = \"./output/{}/{}/shap/{}_shap_{}.pkl\".format(\n",
    "    seq_len, model_name, \"{}\", \"{}\"\n",
    ")  # SHAP values path for a given dataset split (train/val/test) (data format (features, scores, patient_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New directory created: ./output/300/lstm-att/models\n",
      "New directory created: ./output/300/lstm-att/shap\n",
      "Cuda available: True\n",
      "Total GPUs: 4\n"
     ]
    }
   ],
   "source": [
    "# LSTM+Attn Model Output Directory\n",
    "model_save_dir = os.path.dirname(model_save_path)\n",
    "shap_save_dir = os.path.dirname(shap_save_path)\n",
    "if os.path.exists(model_save_dir):\n",
    "    # Remove model save directory if exists\n",
    "    shutil.rmtree(model_save_dir)\n",
    "if os.path.exists(shap_save_dir):\n",
    "    # Remove model save directory if exists\n",
    "    shutil.rmtree(shap_save_dir)\n",
    "os.makedirs(model_save_dir)\n",
    "os.makedirs(shap_save_dir)\n",
    "print(f\"New directory created: {model_save_dir}\")\n",
    "print(f\"New directory created: {shap_save_dir}\")\n",
    "\n",
    "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
    "print(\"Total GPUs:\", torch.cuda.device_count())\n",
    "model_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Vocab and Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataset from ../../data/toy_dataset/data/300/train.csv..\n",
      "Success!\n",
      "Building dataset from ../../data/toy_dataset/data/300/val.csv..\n",
      "Success!\n",
      "Building dataset from ../../data/toy_dataset/data/300/test.csv..\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "train_dataset, vocab = l_utils.build_lstm_dataset(\n",
    "    train_data_path,\n",
    "    min_freq=min_freq,\n",
    "    uid_colname=\"patient_id\",\n",
    "    target_colname=\"label\",\n",
    "    max_len=seq_len,\n",
    "    target_value=target_value,\n",
    "    vocab=None,\n",
    "    nrows=nrows,\n",
    "    rev=rev,\n",
    ")\n",
    "valid_dataset, _ = l_utils.build_lstm_dataset(\n",
    "    valid_data_path,\n",
    "    min_freq=min_freq,\n",
    "    uid_colname=\"patient_id\",\n",
    "    target_colname=\"label\",\n",
    "    max_len=seq_len,\n",
    "    target_value=target_value,\n",
    "    vocab=vocab,\n",
    "    nrows=nrows,\n",
    "    rev=rev,\n",
    ")\n",
    "\n",
    "test_dataset, _ = l_utils.build_lstm_dataset(\n",
    "    test_data_path,\n",
    "    min_freq=min_freq,\n",
    "    uid_colname=\"patient_id\",\n",
    "    target_colname=\"label\",\n",
    "    max_len=seq_len,\n",
    "    target_value=target_value,\n",
    "    vocab=vocab,\n",
    "    nrows=nrows,\n",
    "    rev=rev,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset, batch_size=batch_size, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == \"lstm\":\n",
    "    model = lstm.SimpleLSTM(\n",
    "        embedding_dim,\n",
    "        hidden_dim,\n",
    "        vocab,\n",
    "        model_device,\n",
    "        nlayers=nlayers,\n",
    "        dropout=dropout,\n",
    "        init_type=init_type,\n",
    "    )\n",
    "else:\n",
    "    model = lstm_att.AttLSTM(\n",
    "        embedding_dim,\n",
    "        hidden_dim,\n",
    "        vocab,\n",
    "        model_device,\n",
    "        nlayers=nlayers,\n",
    "        dropout=dropout,\n",
    "        init_type=init_type,\n",
    "    )\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttLSTM(\n",
       "  (emb_layer): Embedding(32, 8, padding_idx=0)\n",
       "  (lstm): LSTM(8, 16, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "  (pred_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (dpt): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\n",
    "#     \"Computing the # of models params and check the accepted ratio of #params/#examples (accepted<=0.1)...\"\n",
    "# )\n",
    "# # Get the number of trainable parameters\n",
    "# total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "# total_examples = 16000\n",
    "# ratio = float(total_params) / total_examples\n",
    "# passed = ratio <= 0.1\n",
    "# print(\n",
    "#     f\"Total Model Params={total_params}, Total Examples={total_examples}, Ratio={ratio}, Test Passed={passed}\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_function = nn.CrossEntropyLoss()\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 4, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing SHAP Intersection Similarity for epoch=0...\n",
      "Epoch: 01 | Epoch Time: 5m 48s\n",
      "saved ./output/300/lstm-att/shap/val_shap_00.pkl pickle..\n",
      "Saved Model and SHAP values, epoch 0\n",
      "Train Loss: 0.466 | Train AUC: 0.87 \t Val. Loss: 0.404 |  Val. AUC: 0.8955 | Val Int. Similarity: 0.0625\n",
      "Computing SHAP Intersection Similarity for epoch=1...\n",
      "Epoch: 02 | Epoch Time: 5m 36s\n",
      "saved ./output/300/lstm-att/shap/val_shap_01.pkl pickle..\n",
      "Saved Model and SHAP values, epoch 1\n",
      "Train Loss: 0.392 | Train AUC: 0.90 \t Val. Loss: 0.379 |  Val. AUC: 0.8964 | Val Int. Similarity: 0.1875\n",
      "Computing SHAP Intersection Similarity for epoch=2...\n",
      "Epoch: 03 | Epoch Time: 5m 52s\n",
      "Train Loss: 0.372 | Train AUC: 0.90 \t Val. Loss: 0.348 |  Val. AUC: 0.8955 | Val Int. Similarity: 0.1146\n",
      "Computing SHAP Intersection Similarity for epoch=3...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 15.78 GiB total capacity; 7.88 GiB already allocated; 3.00 MiB free; 7.98 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-281c5d9820b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mn_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_VALID_EXAMPLES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mtest_positive_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTEST_POSITIVE_ONLY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mis_test_random\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIS_TEST_RANDOM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         )\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/CMSAI_Research/model/toy_simple/shap_jacc_utils.py\u001b[0m in \u001b[0;36mget_lstm_features_and_shap_scores\u001b[0;34m(model, tr_dataloader, te_dataloader, seq_len, shap_path, save_output, n_test, n_background, background_negative_only, test_positive_only, is_test_random)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_ids_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_idxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mlstm_shap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/CMSAI_Research/model/toy_simple/deep_id_pytorch.py\u001b[0m in \u001b[0;36mshap_values\u001b[0;34m(self, X, masks, ranked_outputs, output_rank_order)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# run attribution computation graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0mfeature_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_output_ranks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0msample_phis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoint_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoint_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# assign the attributions to the right part of the output arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/CMSAI_Research/model/toy_simple/deep_id_pytorch.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, idx, inputs, masks)\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mx_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0mx_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_shap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_id_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m                 \u001b[0mselected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/CMSAI_Research/model/toy_simple/att_lstm_models.py\u001b[0m in \u001b[0;36mforward_shap\u001b[0;34m(self, token_ids, mask, full_id_matrix)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;31m#output = output.permute(1, 0, 2)  # [batch, text_length, hidden_dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 559\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 15.78 GiB total capacity; 7.88 GiB already allocated; 3.00 MiB free; 7.98 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "if EARLY_STOPPING == \"intersection_similarity\":\n",
    "    best_valid = float(\"-inf\")\n",
    "else:\n",
    "    best_valid = float(\"inf\")\n",
    "worse_valid = 0  # enable early stopping\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_auc = l_utils.epoch_train_lstm(\n",
    "        model, train_dataloader, optimizer, loss_function\n",
    "    )\n",
    "\n",
    "    valid_loss, valid_auc = l_utils.epoch_val_lstm(\n",
    "        model, valid_dataloader, loss_function\n",
    "    )  # , return_preds=False\n",
    "\n",
    "    val_shap_path = shap_save_path.format(\"val\", f\"{epoch:02}\")\n",
    "    if EARLY_STOPPING == \"intersection_similarity\":\n",
    "        print(f\"Computing SHAP Intersection Similarity for epoch={epoch}...\")\n",
    "        (features, scores, patients,) = sj_utils.get_lstm_features_and_shap_scores(\n",
    "            model,\n",
    "            train_dataloader,\n",
    "            valid_dataloader,\n",
    "            seq_len,\n",
    "            val_shap_path,\n",
    "            save_output=False,\n",
    "            n_background=N_BACKGROUND,\n",
    "            background_negative_only=BACKGROUND_NEGATIVE_ONLY,\n",
    "            n_test=N_VALID_EXAMPLES,\n",
    "            test_positive_only=TEST_POSITIVE_ONLY,\n",
    "            is_test_random=IS_TEST_RANDOM,\n",
    "        )\n",
    "\n",
    "        valid_sim, _ = sj_utils.get_model_intersection_similarity(\n",
    "            (features, scores), absolute=SHAP_SCORE_ABSOLUTE\n",
    "        )\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = l_utils.epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n",
    "\n",
    "    if EARLY_STOPPING == \"intersection_similarity\":\n",
    "        if valid_sim > best_valid:\n",
    "            best_valid = valid_sim\n",
    "            save_path = model_save_path.format(str(epoch).zfill(2))\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            sj_utils.save_pickle((features, scores, patients), val_shap_path)\n",
    "            print(\"Saved Model and SHAP values, epoch {}\".format(epoch))\n",
    "            worse_valid = 0\n",
    "        else:\n",
    "            worse_valid += 1\n",
    "            if worse_valid == stop_num:\n",
    "                print(\"EARLY STOP ------\")\n",
    "                break\n",
    "    else:\n",
    "        if valid_loss < best_valid:\n",
    "            best_valid = valid_loss\n",
    "            save_path = model_save_path.format(str(epoch).zfill(2))\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(\"Saved Model, epoch {}\".format(epoch))\n",
    "            worse_valid = 0\n",
    "        else:\n",
    "            worse_valid += 1\n",
    "            if worse_valid == stop_num:\n",
    "                print(\"EARLY STOP ------\")\n",
    "                break\n",
    "\n",
    "    scheduler.step()\n",
    "    sim_message = \"\"\n",
    "    if EARLY_STOPPING == \"intersection_similarity\":\n",
    "        sim_message = f\"| Val Int. Similarity: {valid_sim:.4f}\"\n",
    "    print(\n",
    "        f\"Train Loss: {train_loss:.3f} | Train AUC: {train_auc:.2f} \\t Val. Loss: {valid_loss:.3f} |  Val. AUC: {valid_auc:.4f} {sim_message}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get paths of each saved model\n",
    "models_paths = sj_utils.get_model_paths(model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positive_scores(labels, scores):\n",
    "    \"\"\"Get scores of only positive examples\"\"\"\n",
    "    labels2 = np.array(labels).flatten()\n",
    "    pos_rows = labels2 == 1\n",
    "    return scores.flatten()[pos_rows].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_models = len(models_paths)\n",
    "for i, model_path in enumerate(models_paths):\n",
    "    print(f\"Processing for model {os.path.basename(model_path)} ...\")\n",
    "    # Load trained weights\n",
    "    print(\"Loading the trained weights...\")\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    ##Get Train/Val/Test Scores\n",
    "    print(\"Computing the models performances for train/val/test splits...\")\n",
    "    train_loss, train_auc, train_labels, train_scores = l_utils.epoch_val_lstm(\n",
    "        model, train_dataloader, loss_function, return_preds=True\n",
    "    )\n",
    "    val_loss, val_auc, val_labels, val_scores = l_utils.epoch_val_lstm(\n",
    "        model, valid_dataloader, loss_function, return_preds=True\n",
    "    )\n",
    "    test_loss, test_auc, test_labels, test_scores = l_utils.epoch_val_lstm(\n",
    "        model, test_dataloader, loss_function, return_preds=True\n",
    "    )\n",
    "    print(\"Ploting Histograms of Train/Val/Test Predicted Scores...\")\n",
    "    _, axes = plt.subplots(1, 3, sharex=False, figsize=(15, 5))\n",
    "    # Train\n",
    "    scores = train_scores.flatten().tolist()\n",
    "    axes = sj_utils.plot_histogram(\n",
    "        scores,\n",
    "        title=f\"Train Scores (Loss={train_loss:.4f}, AUC={train_auc:.4f})\",\n",
    "        xlabel=\"Prediction Scores\",\n",
    "        ylabel=\"Frequencies\",\n",
    "        axes=axes,\n",
    "        axes_idx=0,\n",
    "    )\n",
    "    # Val\n",
    "    scores = val_scores.flatten().tolist()\n",
    "    axes = sj_utils.plot_histogram(\n",
    "        scores,\n",
    "        title=f\"Val Scores (Loss={val_loss:.4f}, AUC={val_auc:.4f})\",\n",
    "        xlabel=\"Prediction Scores\",\n",
    "        ylabel=\"\",\n",
    "        axes=axes,\n",
    "        axes_idx=1,\n",
    "    )\n",
    "    # Test\n",
    "    scores = test_scores.flatten().tolist()\n",
    "    axes = sj_utils.plot_histogram(\n",
    "        scores,\n",
    "        title=f\"Test Scores (Loss={test_loss:.4f}, AUC={test_auc:.4f})\",\n",
    "        xlabel=\"Prediction Scores\",\n",
    "        ylabel=\"\",\n",
    "        axes=axes,\n",
    "        axes_idx=2,\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Computing SHAP for {N_VALID_EXAMPLES} positive val examples...\")\n",
    "    epoch = sj_utils.get_epoch_number_from_path(model_path)\n",
    "    val_shap_path = shap_save_path.format(\"val\", f\"{epoch:02}\")\n",
    "    (\n",
    "        features,\n",
    "        scores,\n",
    "        patients,\n",
    "    ) = sj_utils.load_pickle(val_shap_path)\n",
    "\n",
    "    val_prob_scores = get_positive_scores(val_labels, val_scores)\n",
    "    if N_VALID_EXAMPLES is not None:\n",
    "        num_val = N_VALID_EXAMPLES\n",
    "    else:\n",
    "        num_val = len(val_prob_scores)\n",
    "    n_vis_examples = 0\n",
    "    for idx in range(num_val):\n",
    "        if n_vis_examples > 2:\n",
    "            break\n",
    "        prob_scores1 = val_prob_scores[idx]\n",
    "        features1 = features[idx]\n",
    "        scores1 = scores[idx]\n",
    "        patient_id = patients[idx]\n",
    "        patient_id = f\"{patient_id}, Probability={prob_scores1:.4f}\"\n",
    "\n",
    "        if prob_scores1 >= 0.8:\n",
    "            import pdb; pdb.set_trace()\n",
    "            df_shap = pd.DataFrame(\n",
    "                np.array([features1, scores1]).T, columns=[\"events\", \"shap_vals\"]\n",
    "            )\n",
    "            df_shap[\"shap_vals\"] = pd.to_numeric(df_shap[\"shap_vals\"])\n",
    "\n",
    "            sj_utils.plot_shap_values(\n",
    "                df_shap, patient_id, sort=SORT_SHAP_VALUES, figsize=(10, 5)\n",
    "            )\n",
    "            n_vis_examples += 1\n",
    "\n",
    "    print(\"Computing Intersection Similarity...\")\n",
    "    avg_sim, sim = sj_utils.get_model_intersection_similarity(\n",
    "        (features, scores), absolute=SHAP_SCORE_ABSOLUTE\n",
    "    )\n",
    "    sj_utils.plot_histogram(\n",
    "        sim,\n",
    "        title=f\"Average VAL Intersection Simi={avg_sim:.4f}\",\n",
    "        xlabel=\"Intersection Similarity\",\n",
    "        ylabel=\"Frequencies\",\n",
    "        axes=None,\n",
    "    )\n",
    "\n",
    "    # For the best model, get the final performance (test set) (intersection similarity)\n",
    "    if i == (total_models - 1):\n",
    "        message = \"\"\n",
    "        if N_TEST_EXAMPLES is None:\n",
    "            message = (\n",
    "                f\"Computing SHAP for ALL positive TEST examples for the final model...\"\n",
    "            )\n",
    "        else:\n",
    "            message = f\"Computing SHAP for {N_TEST_EXAMPLES} positive TEST examples for the final model...\"\n",
    "        print(message)\n",
    "        test_shap_path = shap_save_path.format(\"test\", f\"{epoch:02}\")\n",
    "        (features, scores, patients,) = sj_utils.get_lstm_features_and_shap_scores(\n",
    "            model,\n",
    "            train_dataloader,\n",
    "            test_dataloader,\n",
    "            seq_len,\n",
    "            test_shap_path,\n",
    "            save_output=True,\n",
    "            n_background=N_BACKGROUND,\n",
    "            background_negative_only=BACKGROUND_NEGATIVE_ONLY,\n",
    "            n_test=N_TEST_EXAMPLES,\n",
    "            test_positive_only=TEST_POSITIVE_ONLY,\n",
    "            is_test_random=IS_TEST_RANDOM,\n",
    "        )\n",
    "        test_prob_scores = get_positive_scores(test_labels, test_scores)\n",
    "        if N_TEST_EXAMPLES is not None:\n",
    "            num_test = N_TEST_EXAMPLES\n",
    "        else:\n",
    "            num_test = len(test_prob_scores)\n",
    "        n_vis_examples = 0\n",
    "        for idx in range(num_test):\n",
    "            if n_vis_examples > 2:\n",
    "                break\n",
    "            prob_scores1 = test_prob_scores[idx]\n",
    "            features1 = features[idx]\n",
    "            scores1 = scores[idx]\n",
    "            patient_id = patients[idx]\n",
    "            patient_id = f\"{patient_id}, Probability={prob_scores1:.4f}\"\n",
    "\n",
    "            if prob_scores1 >= 0.8:\n",
    "                df_shap = pd.DataFrame(\n",
    "                    np.array([features1, scores1]).T,\n",
    "                    columns=[\"events\", \"shap_vals\"],\n",
    "                )\n",
    "                df_shap[\"shap_vals\"] = pd.to_numeric(df_shap[\"shap_vals\"])\n",
    "\n",
    "                sj_utils.plot_shap_values(\n",
    "                    df_shap, patient_id, sort=SORT_SHAP_VALUES, figsize=(10, 5)\n",
    "                )\n",
    "                n_vis_examples += 1\n",
    "\n",
    "        print(\"Computing Intersection Similarity...\")\n",
    "        avg_sim, sim = sj_utils.get_model_intersection_similarity(\n",
    "            (features, scores), absolute=SHAP_SCORE_ABSOLUTE\n",
    "        )\n",
    "        sj_utils.plot_histogram(\n",
    "            sim,\n",
    "            title=f\"Average TEST Intersection Simi={avg_sim:.4f}\",\n",
    "            xlabel=\"Intersection Similarity\",\n",
    "            ylabel=\"Frequencies\",\n",
    "            axes=None,\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            \"Finally computing and visualizing the global feature importance of the best model....\"\n",
    "        )\n",
    "        feat_importance = sj_utils.get_global_feature_importance(\n",
    "            features, scores, absolute=SHAP_SCORE_ABSOLUTE\n",
    "        )\n",
    "        sj_utils.plot_global_feature_importance(feat_importance)\n",
    "        print(\"All tasks SUCCESSFULLY completed!\")\n",
    "\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
