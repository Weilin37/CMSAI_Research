{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Training using Toy Dataset\n",
    "\n",
    "<font color='purple'>\n",
    "\n",
    "- Add author, date\n",
    "- Describe purpose: train which models, before the other notebook\n",
    "- Outputs and requirements (other files etc)\n",
    "- Steps\n",
    "- Data used for this notebook\n",
    "    \n",
    "You need to black the notebook for readibility\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! jupyter nbextension enable jupyter-black-master/jupyter-black\n",
    "\n",
    "#! pip install botocore==1.12.201\n",
    "\n",
    "#! pip install shap\n",
    "#! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from urllib.parse import urlparse\n",
    "import tarfile\n",
    "import pickle\n",
    "import shutil\n",
    "\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "import deep_id_pytorch\n",
    "\n",
    "from lstm_models import *\n",
    "from att_lstm_models import *\n",
    "from lstm_utils import *\n",
    "from xgboost_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LSTM Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 1e9\n",
    "min_freq = 1\n",
    "\n",
    "seq_len = 30\n",
    "\n",
    "train_data_path = \"../../data/toy_dataset/data/{}/train.csv\".format(seq_len)\n",
    "valid_data_path = \"../../data/toy_dataset/data/{}/val.csv\".format(seq_len)\n",
    "test_data_path = \"../../data/toy_dataset/data/{}/test.csv\".format(seq_len)\n",
    "\n",
    "lstm_model_save_path = './output/{}/lstm/models/model'.format(seq_len)\n",
    "lstm_results_save_path = \"./output/{}/lstm/results/\".format(seq_len)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "n_epochs = 2\n",
    "stop_num = 2\n",
    "\n",
    "embedding_dim = 8\n",
    "hidden_dim = 16\n",
    "nlayers = 1\n",
    "bidirectional = True\n",
    "dropout = 0.3\n",
    "\n",
    "target_colname = 'label'\n",
    "uid_colname = 'patient_id'\n",
    "x_inputs = [str(x) for x in range(29, -1, -1)]\n",
    "target_value = '1'\n",
    "\n",
    "rev = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n"
     ]
    }
   ],
   "source": [
    "#LSTM Output Directory\n",
    "for fp in [lstm_model_save_path, lstm_results_save_path]:\n",
    "    if not os.path.isdir(os.path.split(fp)[0]):\n",
    "        print(f'New directory created: {fp}')\n",
    "        os.makedirs(os.path.split(fp)[0])\n",
    "\n",
    "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
    "model_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Vocab and Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataset from ../../data/toy_dataset/data/30/train.csv..\n",
      "Success!\n",
      "Building dataset from ../../data/toy_dataset/data/30/val.csv..\n",
      "Success!\n",
      "Building dataset from ../../data/toy_dataset/data/30/test.csv..\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "train_dataset, vocab = build_lstm_dataset(\n",
    "                                train_data_path,\n",
    "                                min_freq=min_freq,\n",
    "                                uid_colname=\"patient_id\",\n",
    "                                target_colname=\"label\",\n",
    "                                max_len=seq_len,\n",
    "                                target_value=target_value,\n",
    "                                vocab=None,\n",
    "                                nrows=nrows,\n",
    "                                rev=rev\n",
    "                            )\n",
    "valid_dataset, _ = build_lstm_dataset(\n",
    "                                valid_data_path,\n",
    "                                min_freq=min_freq,\n",
    "                                uid_colname=\"patient_id\",\n",
    "                                target_colname=\"label\",\n",
    "                                max_len=seq_len,\n",
    "                                target_value=target_value,\n",
    "                                vocab=vocab,\n",
    "                                nrows=nrows,\n",
    "                                rev=rev\n",
    "                            )\n",
    "\n",
    "test_dataset, _ = build_lstm_dataset(\n",
    "                                test_data_path,\n",
    "                                min_freq=min_freq,\n",
    "                                uid_colname=\"patient_id\",\n",
    "                                target_colname=\"label\",\n",
    "                                max_len=seq_len,\n",
    "                                target_value=target_value,\n",
    "                                vocab=vocab,\n",
    "                                nrows=nrows,\n",
    "                                rev=rev\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SimpleLSTM Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = SimpleLSTM(embedding_dim, hidden_dim, vocab, model_device, nlayers=nlayers, dropout=dropout)\n",
    "lstm_model = lstm_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleLSTM(\n",
       "  (emb_layer): Embedding(32, 8, padding_idx=0)\n",
       "  (lstm): LSTM(8, 16, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "  (pred_layer): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (dpt): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_function = nn.CrossEntropyLoss()\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=0.05)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 4, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 6s\n",
      "Saved Model, epoch 0\n",
      "Train Loss: 0.407 | Train AUC: 0.89 \t Val. Loss: 0.313 |  Val. AUC: 0.9113\n",
      "Epoch: 02 | Epoch Time: 0m 5s\n",
      "Saved Model, epoch 1\n",
      "Train Loss: 0.345 | Train AUC: 0.90 \t Val. Loss: 0.300 |  Val. AUC: 0.9173\n"
     ]
    }
   ],
   "source": [
    "best_valid_loss = float(\"inf\")\n",
    "valid_worse_loss = 0  # enable early stopping\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_auc = epoch_train_lstm(\n",
    "        lstm_model, train_dataloader, optimizer, loss_function\n",
    "    )\n",
    "\n",
    "    valid_loss, valid_auc = epoch_val_lstm(\n",
    "       lstm_model, valid_dataloader, loss_function)#, return_preds=False\n",
    "    #)\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(lstm_model.state_dict(), lstm_model_save_path)\n",
    "        print(\"Saved Model, epoch {}\".format(epoch))\n",
    "        valid_worse_loss = 0\n",
    "\n",
    "    else:\n",
    "        valid_worse_loss += 1\n",
    "        if valid_worse_loss == stop_num:\n",
    "            print(\"EARLY STOP ------\")\n",
    "            break\n",
    "\n",
    "    scheduler.step()\n",
    "    print(\n",
    "        f\"Train Loss: {train_loss:.3f} | Train AUC: {train_auc:.2f} \\t Val. Loss: {valid_loss:.3f} |  Val. AUC: {valid_auc:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='purple'>\n",
    "Missing Sanity Check Steps on model building <br>\n",
    "You need to add plots on the histograms of the train, val and test scores to verify that you did not overtrain the models    \n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.325 | Test AUC: 0.91\n"
     ]
    }
   ],
   "source": [
    "lstm_model.load_state_dict(torch.load(lstm_model_save_path))\n",
    "test_loss, test_auc = epoch_val_lstm(\n",
    "   lstm_model, test_dataloader, loss_function)#, return_preds=False\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.3f} | Test AUC: {test_auc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='purple'>\n",
    "\n",
    "Sanity check a few shap values to confirm model is behaving as expected\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM with Attention Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_att_model_save_path = './output/{}/lstm-att/models/model'.format(seq_len)\n",
    "lstm_att_results_save_path = \"./output/{}/lstm-att/results/\".format(seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM with Attention Output Directory\n",
    "for fp in [lstm_att_model_save_path, lstm_att_results_save_path]:\n",
    "    if not os.path.exists(os.path.split(fp)[0]):\n",
    "        print(f'New directory created: {fp}')\n",
    "        os.makedirs(os.path.split(fp)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_att_model = AttLSTM(embedding_dim, hidden_dim, vocab, model_device, nlayers=nlayers, dropout=dropout)\n",
    "lstm_att_model = lstm_att_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttLSTM(\n",
       "  (emb_layer): Embedding(32, 8, padding_idx=0)\n",
       "  (lstm): LSTM(8, 16, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "  (pred_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (attn_layer): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (dpt): Dropout(p=0.3, inplace=False)\n",
       "  (context_layer): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_att_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_function = nn.CrossEntropyLoss()\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(lstm_att_model.parameters(), lr=0.05)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 4, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 5s\n",
      "Saved Model, epoch 0\n",
      "Train Loss: 0.370 | Train AUC: 0.90 \t Val. Loss: 0.296 |  Val. AUC: 0.9131\n",
      "Epoch: 02 | Epoch Time: 0m 5s\n",
      "Train Loss: 0.341 | Train AUC: 0.90 \t Val. Loss: 0.299 |  Val. AUC: 0.9113\n"
     ]
    }
   ],
   "source": [
    "best_valid_loss = float(\"inf\")\n",
    "valid_worse_loss = 0  # enable early stopping\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_auc = epoch_train_lstm(\n",
    "        lstm_att_model, train_dataloader, optimizer, loss_function\n",
    "    )\n",
    "\n",
    "    valid_loss, valid_auc = epoch_val_lstm(\n",
    "       lstm_att_model, valid_dataloader, loss_function)#, return_preds=False\n",
    "    #)\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(lstm_att_model.state_dict(), lstm_att_model_save_path)\n",
    "        print(\"Saved Model, epoch {}\".format(epoch))\n",
    "        valid_worse_loss = 0\n",
    "\n",
    "    else:\n",
    "        valid_worse_loss += 1\n",
    "        if valid_worse_loss == stop_num:\n",
    "            print(\"EARLY STOP ------\")\n",
    "            break\n",
    "\n",
    "    scheduler.step()\n",
    "    print(\n",
    "        f\"Train Loss: {train_loss:.3f} | Train AUC: {train_auc:.2f} \\t Val. Loss: {valid_loss:.3f} |  Val. AUC: {valid_auc:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='purple'>\n",
    "\n",
    "Same thing as before\n",
    "I think you need to add plots on the histograms of the train and \n",
    "test scores to verify that you did not overtrain the models    \n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.321 | Test AUC: 0.91\n"
     ]
    }
   ],
   "source": [
    "lstm_att_model.load_state_dict(torch.load(lstm_att_model_save_path))\n",
    "test_loss, test_auc = epoch_val_lstm(\n",
    "   lstm_att_model, test_dataloader, loss_function)#, return_preds=False\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.3f} | Test AUC: {test_auc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='purple'>\n",
    "\n",
    "Sanity check a few shap values to confirm model is behaving as expected\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. XGBoost Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_one_hot_path = 'output/{}/xgboost/data/train_one_hot.csv'.format(seq_len)\n",
    "x_valid_one_hot_path = 'output/{}/xgboost/data/val_one_hot.csv'.format(seq_len)\n",
    "x_test_one_hot_path = 'output/{}/xgboost/data/test_one_hot.csv'.format(seq_len)\n",
    "\n",
    "x_train_data_path = 'output/{}/xgboost/data/train.csv'.format(seq_len)\n",
    "x_valid_data_path = 'output/{}/xgboost/data/val.csv'.format(seq_len)\n",
    "x_test_data_path = 'output/{}/xgboost/data/test.csv'.format(seq_len)\n",
    "\n",
    "s3_output_data_dir = 's3://merck-paper-bucket/{}/data'.format(seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 33)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>29</th>\n",
       "      <th>28</th>\n",
       "      <th>27</th>\n",
       "      <th>26</th>\n",
       "      <th>25</th>\n",
       "      <th>24</th>\n",
       "      <th>23</th>\n",
       "      <th>22</th>\n",
       "      <th>21</th>\n",
       "      <th>...</th>\n",
       "      <th>7</th>\n",
       "      <th>6</th>\n",
       "      <th>5</th>\n",
       "      <th>4</th>\n",
       "      <th>3</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>label</th>\n",
       "      <th>patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1279</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>cold_sore</td>\n",
       "      <td>cut_finger</td>\n",
       "      <td>hay_fever</td>\n",
       "      <td>PH</td>\n",
       "      <td>apnea</td>\n",
       "      <td>1</td>\n",
       "      <td>T8MY5WMELF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2634</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>hay_fever</td>\n",
       "      <td>ingrown_nail</td>\n",
       "      <td>cut_finger</td>\n",
       "      <td>low_salt_diet</td>\n",
       "      <td>ingrown_nail</td>\n",
       "      <td>cold_sore</td>\n",
       "      <td>headache</td>\n",
       "      <td>...</td>\n",
       "      <td>quad_injury</td>\n",
       "      <td>backache</td>\n",
       "      <td>backache</td>\n",
       "      <td>cold_sore</td>\n",
       "      <td>cut_finger</td>\n",
       "      <td>myopia</td>\n",
       "      <td>myopia</td>\n",
       "      <td>eye_exam</td>\n",
       "      <td>0</td>\n",
       "      <td>NTE5E431A7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1653</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>headache</td>\n",
       "      <td>cut_finger</td>\n",
       "      <td>peanut_allergy</td>\n",
       "      <td>ingrown_nail</td>\n",
       "      <td>myopia</td>\n",
       "      <td>pneumonia</td>\n",
       "      <td>quad_injury</td>\n",
       "      <td>...</td>\n",
       "      <td>foot_pain</td>\n",
       "      <td>eye_exam</td>\n",
       "      <td>ankle_sprain</td>\n",
       "      <td>dental_exam</td>\n",
       "      <td>apnea</td>\n",
       "      <td>foot_pain</td>\n",
       "      <td>cold_sore</td>\n",
       "      <td>ACL_tear</td>\n",
       "      <td>1</td>\n",
       "      <td>VWT8TZSHU8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1135</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>cold_sore</td>\n",
       "      <td>dental_exam</td>\n",
       "      <td>eye_exam</td>\n",
       "      <td>myopia</td>\n",
       "      <td>peanut_allergy</td>\n",
       "      <td>backache</td>\n",
       "      <td>cold_sore</td>\n",
       "      <td>dental_exam</td>\n",
       "      <td>1</td>\n",
       "      <td>FUWNH10AHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2886</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>ankle_sprain</td>\n",
       "      <td>eye_exam</td>\n",
       "      <td>ankle_sprain</td>\n",
       "      <td>eye_exam</td>\n",
       "      <td>annual_physical</td>\n",
       "      <td>foot_pain</td>\n",
       "      <td>cold_sore</td>\n",
       "      <td>backache</td>\n",
       "      <td>1</td>\n",
       "      <td>YRWCVEYKWW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     29     28         27            26              25  \\\n",
       "0   1279  <pad>  <pad>      <pad>         <pad>           <pad>   \n",
       "1   2634  <pad>  <pad>  hay_fever  ingrown_nail      cut_finger   \n",
       "2   1653  <pad>  <pad>   headache    cut_finger  peanut_allergy   \n",
       "3   1135  <pad>  <pad>      <pad>         <pad>           <pad>   \n",
       "4   2886  <pad>  <pad>      <pad>         <pad>           <pad>   \n",
       "\n",
       "              24            23         22           21  ...             7  \\\n",
       "0          <pad>         <pad>      <pad>        <pad>  ...         <pad>   \n",
       "1  low_salt_diet  ingrown_nail  cold_sore     headache  ...   quad_injury   \n",
       "2   ingrown_nail        myopia  pneumonia  quad_injury  ...     foot_pain   \n",
       "3          <pad>         <pad>      <pad>        <pad>  ...     cold_sore   \n",
       "4          <pad>         <pad>      <pad>        <pad>  ...  ankle_sprain   \n",
       "\n",
       "             6             5            4                3          2  \\\n",
       "0        <pad>         <pad>    cold_sore       cut_finger  hay_fever   \n",
       "1     backache      backache    cold_sore       cut_finger     myopia   \n",
       "2     eye_exam  ankle_sprain  dental_exam            apnea  foot_pain   \n",
       "3  dental_exam      eye_exam       myopia   peanut_allergy   backache   \n",
       "4     eye_exam  ankle_sprain     eye_exam  annual_physical  foot_pain   \n",
       "\n",
       "           1            0 label  patient_id  \n",
       "0         PH        apnea     1  T8MY5WMELF  \n",
       "1     myopia     eye_exam     0  NTE5E431A7  \n",
       "2  cold_sore     ACL_tear     1  VWT8TZSHU8  \n",
       "3  cold_sore  dental_exam     1  FUWNH10AHI  \n",
       "4  cold_sore     backache     1  YRWCVEYKWW  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(train_data_path)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_valid_tokens(tokens):\n",
    "#     \"\"\"Get all tokens except <pad> and <unk>\"\"\"\n",
    "#     my_tokens = []\n",
    "#     for key, val in tokens.items():\n",
    "#         if val>=2:\n",
    "#             my_tokens.append(key)\n",
    "#     my_tokens\n",
    "#     return my_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = lstm_model.vocab._vocab\n",
    "my_tokens = get_valid_tokens(tokens)\n",
    "#my_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>29</th>\n",
       "      <th>28</th>\n",
       "      <th>27</th>\n",
       "      <th>26</th>\n",
       "      <th>25</th>\n",
       "      <th>24</th>\n",
       "      <th>23</th>\n",
       "      <th>22</th>\n",
       "      <th>21</th>\n",
       "      <th>...</th>\n",
       "      <th>7</th>\n",
       "      <th>6</th>\n",
       "      <th>5</th>\n",
       "      <th>4</th>\n",
       "      <th>3</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>label</th>\n",
       "      <th>patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1279</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>cold_sore</td>\n",
       "      <td>cut_finger</td>\n",
       "      <td>hay_fever</td>\n",
       "      <td>PH</td>\n",
       "      <td>apnea</td>\n",
       "      <td>1</td>\n",
       "      <td>T8MY5WMELF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2634</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>hay_fever</td>\n",
       "      <td>ingrown_nail</td>\n",
       "      <td>cut_finger</td>\n",
       "      <td>low_salt_diet</td>\n",
       "      <td>ingrown_nail</td>\n",
       "      <td>cold_sore</td>\n",
       "      <td>headache</td>\n",
       "      <td>...</td>\n",
       "      <td>quad_injury</td>\n",
       "      <td>backache</td>\n",
       "      <td>backache</td>\n",
       "      <td>cold_sore</td>\n",
       "      <td>cut_finger</td>\n",
       "      <td>myopia</td>\n",
       "      <td>myopia</td>\n",
       "      <td>eye_exam</td>\n",
       "      <td>0</td>\n",
       "      <td>NTE5E431A7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1653</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>headache</td>\n",
       "      <td>cut_finger</td>\n",
       "      <td>peanut_allergy</td>\n",
       "      <td>ingrown_nail</td>\n",
       "      <td>myopia</td>\n",
       "      <td>pneumonia</td>\n",
       "      <td>quad_injury</td>\n",
       "      <td>...</td>\n",
       "      <td>foot_pain</td>\n",
       "      <td>eye_exam</td>\n",
       "      <td>ankle_sprain</td>\n",
       "      <td>dental_exam</td>\n",
       "      <td>apnea</td>\n",
       "      <td>foot_pain</td>\n",
       "      <td>cold_sore</td>\n",
       "      <td>ACL_tear</td>\n",
       "      <td>1</td>\n",
       "      <td>VWT8TZSHU8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1135</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>cold_sore</td>\n",
       "      <td>dental_exam</td>\n",
       "      <td>eye_exam</td>\n",
       "      <td>myopia</td>\n",
       "      <td>peanut_allergy</td>\n",
       "      <td>backache</td>\n",
       "      <td>cold_sore</td>\n",
       "      <td>dental_exam</td>\n",
       "      <td>1</td>\n",
       "      <td>FUWNH10AHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2886</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>ankle_sprain</td>\n",
       "      <td>eye_exam</td>\n",
       "      <td>ankle_sprain</td>\n",
       "      <td>eye_exam</td>\n",
       "      <td>annual_physical</td>\n",
       "      <td>foot_pain</td>\n",
       "      <td>cold_sore</td>\n",
       "      <td>backache</td>\n",
       "      <td>1</td>\n",
       "      <td>YRWCVEYKWW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     29     28         27            26              25  \\\n",
       "0   1279  <pad>  <pad>      <pad>         <pad>           <pad>   \n",
       "1   2634  <pad>  <pad>  hay_fever  ingrown_nail      cut_finger   \n",
       "2   1653  <pad>  <pad>   headache    cut_finger  peanut_allergy   \n",
       "3   1135  <pad>  <pad>      <pad>         <pad>           <pad>   \n",
       "4   2886  <pad>  <pad>      <pad>         <pad>           <pad>   \n",
       "\n",
       "              24            23         22           21  ...             7  \\\n",
       "0          <pad>         <pad>      <pad>        <pad>  ...         <pad>   \n",
       "1  low_salt_diet  ingrown_nail  cold_sore     headache  ...   quad_injury   \n",
       "2   ingrown_nail        myopia  pneumonia  quad_injury  ...     foot_pain   \n",
       "3          <pad>         <pad>      <pad>        <pad>  ...     cold_sore   \n",
       "4          <pad>         <pad>      <pad>        <pad>  ...  ankle_sprain   \n",
       "\n",
       "             6             5            4                3          2  \\\n",
       "0        <pad>         <pad>    cold_sore       cut_finger  hay_fever   \n",
       "1     backache      backache    cold_sore       cut_finger     myopia   \n",
       "2     eye_exam  ankle_sprain  dental_exam            apnea  foot_pain   \n",
       "3  dental_exam      eye_exam       myopia   peanut_allergy   backache   \n",
       "4     eye_exam  ankle_sprain     eye_exam  annual_physical  foot_pain   \n",
       "\n",
       "           1            0 label  patient_id  \n",
       "0         PH        apnea     1  T8MY5WMELF  \n",
       "1     myopia     eye_exam     0  NTE5E431A7  \n",
       "2  cold_sore     ACL_tear     1  VWT8TZSHU8  \n",
       "3  cold_sore  dental_exam     1  FUWNH10AHI  \n",
       "4  cold_sore     backache     1  YRWCVEYKWW  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucess!\n",
      "Sucess!\n",
      "Sucess!\n"
     ]
    }
   ],
   "source": [
    "prepare_data(train_data_path, x_train_one_hot_path, x_train_data_path, seq_len, target_colname, my_tokens, s3_output_data_dir)\n",
    "prepare_data(valid_data_path, x_valid_one_hot_path, x_valid_data_path, seq_len, target_colname, my_tokens, s3_output_data_dir)\n",
    "prepare_data(test_data_path, x_test_one_hot_path, x_test_data_path, seq_len, target_colname, my_tokens, s3_output_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = 'merck-paper-bucket'\n",
    "DATA_PREFIX = '{}/data'.format(seq_len)\n",
    "MODEL_PREFIX = '{}/xgboost/model'.format(seq_len)\n",
    "label = 'label'\n",
    "\n",
    "output_results_path = 'output/{}/xgboost/train/train_results.csv'.format(seq_len)\n",
    "local_model_dir = 'output/{}/xgboost/models/'.format(seq_len)\n",
    "s3_output_path = 's3://{}/{}/output'.format(BUCKET, MODEL_PREFIX)\n",
    "\n",
    "###Algorithm config\n",
    "ALGORITHM = 'xgboost'\n",
    "REPO_VERSION = '1.2-1'\n",
    "\n",
    "###Hyperparameter tuning config\n",
    "TRAIN_INSTANCE_TYPE = 'ml.m5.4xlarge'#'ml.m4.16xlarge'\n",
    "TRAIN_INSTANCE_COUNT = 1\n",
    "MAX_PARALLEL_JOBS = 1#4 #TODO: Remove\n",
    "MAX_TRAIN_JOBS = 1#20\n",
    "\n",
    "EVALUATION_METRIC = 'auc'\n",
    "OBJECTIVE = 'binary:logistic'\n",
    "OBJECTIVE_METRIC_NAME = 'validation:auc'\n",
    "\n",
    "#Update hyperparameter ranges\n",
    "# HYPERPARAMETER_RANGES = {'eta': ContinuousParameter(0, 1),\n",
    "#                         'alpha': ContinuousParameter(0, 2),\n",
    "#                         'max_depth': IntegerParameter(1, 10)}\n",
    "\n",
    "HYPERPARAMETER_RANGES = {'eta': ContinuousParameter(0.1, 0.5),\n",
    "                       'alpha': ContinuousParameter(0, 2),\n",
    "                       'max_depth': IntegerParameter(1, 10),\n",
    "                       'gamma': ContinuousParameter(0, 5),\n",
    "                       'num_round': IntegerParameter(200, 500),\n",
    "                       'colsample_bylevel': ContinuousParameter(0.1, 1.0),\n",
    "                       'colsample_bynode': ContinuousParameter(0.1, 1.0),\n",
    "                       'colsample_bytree': ContinuousParameter(0.5, 1.0),\n",
    "                       'lambda': ContinuousParameter(0, 1000),\n",
    "                       'max_delta_step': IntegerParameter(0, 10),\n",
    "                       'min_child_weight': ContinuousParameter(0, 120),\n",
    "                       'subsample': ContinuousParameter(0.5, 1.0),\n",
    "                       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #!pip install --upgrade sagemaker==2.23.1\n",
    "# import sagemaker\n",
    "# sagemaker.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for seq_len=30, label=label...\n",
      ".............................................!\n",
      "Total jobs completed: 1\n",
      "Metric: validation:auc\n",
      "Best AUC: 0.9125\n",
      "Success! Total training time=3.8008267442385355 mins.\n",
      "ALL SUCCESS!\n"
     ]
    }
   ],
   "source": [
    "### SageMaker Initialization\n",
    "region = boto3.Session().region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "smclient = boto3.Session().client('sagemaker')\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "container = retrieve(ALGORITHM, region, version=REPO_VERSION)\n",
    "\n",
    "start = time.time()\n",
    "print('Training for seq_len={}, label={}...'.format(seq_len, label))\n",
    "#Prepare the input train & validation data path\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/train'.format(BUCKET, DATA_PREFIX), content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/val'.format(BUCKET, DATA_PREFIX), content_type='csv')\n",
    "\n",
    "#Class Imbalance\n",
    "scale_pos_weight = 1.0 # negative/positive\n",
    "\n",
    "data_channels = {'train': s3_input_train, 'validation': s3_input_validation}\n",
    "\n",
    "tuner = train_hpo(hyperparameter_ranges=HYPERPARAMETER_RANGES, \n",
    "                  container=container, \n",
    "                  execution_role=role, \n",
    "                  instance_count=TRAIN_INSTANCE_COUNT, \n",
    "                  instance_type=TRAIN_INSTANCE_TYPE, \n",
    "                  output_path=s3_output_path, \n",
    "                  sagemaker_session=sess, \n",
    "                  eval_metric=EVALUATION_METRIC, \n",
    "                  objective=OBJECTIVE, \n",
    "                  objective_metric_name=OBJECTIVE_METRIC_NAME, \n",
    "                  max_train_jobs=MAX_TRAIN_JOBS, \n",
    "                  max_parallel_jobs=MAX_PARALLEL_JOBS, \n",
    "                  scale_pos_weight=scale_pos_weight, \n",
    "                  data_channels=data_channels)\n",
    "\n",
    "#Get the hyperparameter tuner status at regular interval\n",
    "val_auc, best_model_path = get_tuner_status_and_result_until_completion(tuner, seq_len, label)\n",
    "\n",
    "result = [label, seq_len, val_auc, best_model_path]\n",
    "training_results = [result]\n",
    "\n",
    "print('Success! Total training time={} mins.'.format((time.time()-start)/60.0))\n",
    "#Save the results to file\n",
    "df_results = pd.DataFrame(training_results, columns=['class', 'seq_len', 'val_auc', 'best_model_path'])\n",
    "\n",
    "if not os.path.isdir(os.path.split(output_results_path)[0]):\n",
    "    os.makedirs(os.path.split(output_results_path)[0])\n",
    "\n",
    "df_results.to_csv(output_results_path, index=False)\n",
    "print('ALL SUCCESS!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='purple'>\n",
    "\n",
    "Same thing, plot distributions etc\n",
    "And also print out the train/test/val scores for comparison\n",
    "And one or two SHAP values to confirm that model is not overtrained/undertrained\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='purple'>\n",
    "\n",
    "For XGB, it is also very quick to sanity check the global feature importances. Plot it here.\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
