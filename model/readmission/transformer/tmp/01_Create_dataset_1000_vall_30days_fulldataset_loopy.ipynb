{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output dataset for readmissions with full raw data\n",
    "\n",
    "**Author: Lin Lee Cheong <br> Last updated: 11/20/20**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notebook to convert 365 version to 1000 version, and save CSV for readmission**\n",
    "- from full raw data\n",
    "- up to 1000 events, from full 365 day dataset\n",
    "\n",
    "**Required:**\n",
    "- input file: raw_data.csv\n",
    "- outputs: csv files in 1000 format, and vocabulary\n",
    "\n",
    "**Nomenclature:**\n",
    "- d30: **30** days\n",
    "- s30: max 30 sequence a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from utils import get_cuda\n",
    "from data_proc import read_data, remove_death, build_vocab\n",
    "from dataset_func import build_dataset, BuildDataset, get_dataloader\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy('file_system') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input filepaths for training, test, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readmission_input_targets_365_v2.csv  readmission_targets_with_date.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls  ../../../data/readmission/raw_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_365_fp = '../../../data/readmission/fold_0/train/raw_train_data.csv'\n",
    "val_365_fp = '../../../data/readmission/fold_0/test/raw_test_data.csv'\n",
    "\n",
    "# Options\n",
    "ndays =30\n",
    "x_lst = [str(x) for x in range(ndays, -1, -1)]\n",
    "x_flat_lst = [str(x) for x in range(999, -1, -1)]\n",
    "y_target = \"unplanned_readmission\"\n",
    "uid = \"discharge_id\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from more_itertools import unique_everseen\n",
    "def move_ad_dis(events_in_day):\n",
    "    \"\"\"Move admission and discharge to the end of the list\"\"\"\n",
    "    if not isinstance(events_in_day, list):\n",
    "        return events_in_day\n",
    "    \n",
    "    events_in_day = list(unique_everseen(events_in_day))\n",
    "    has_admission = False\n",
    "    has_discharge = False\n",
    "    if \"admission\" in events_in_day:\n",
    "        has_admission = True\n",
    "        events_in_day.remove(\"admission\")\n",
    "        \n",
    "    if \"discharge\" in events_in_day:\n",
    "        has_discharge = True\n",
    "        events_in_day.remove(\"discharge\")\n",
    "    \n",
    "    if has_admission:\n",
    "        events_in_day.append('admission')\n",
    "    \n",
    "    if has_discharge:\n",
    "        events_in_day.append('discharge')\n",
    "    \n",
    "    return events_in_day\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_days(x):\n",
    "    \"\"\"Calculate number of days between events\"\"\"\n",
    "    new_lst = []\n",
    "    counter = 1\n",
    "    counting = False\n",
    "    \n",
    "    try:\n",
    "        for event in x:\n",
    "            nan_event = (\n",
    "                (event == np.nan)\n",
    "                or (type(event) == float and math.isnan(event))\n",
    "                or (str(event) == \"nan\")\n",
    "            )\n",
    "            \n",
    "            if nan_event:\n",
    "                if not counting:\n",
    "                    counting = True\n",
    "                counter += 1\n",
    "                \n",
    "            if not nan_event:\n",
    "                if counting:\n",
    "                    counting = False\n",
    "                    event = f\"{counter + 1}_days,\" + event\n",
    "                    new_lst.append(event)\n",
    "                    counter = 0\n",
    "                else:\n",
    "                    event = \"1_days,\" + event\n",
    "                    new_lst.append(event)\n",
    "    except:\n",
    "        print(f\"error: {event}\")\n",
    "        print(f\"counter: {counter}\")\n",
    "        print(f\"new lst: {new_lst}\")\n",
    "        print(f\"org lst: {x}\")\n",
    "\n",
    "    return new_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_flat_dataset_loopy(\n",
    "    data_fp, x_lst, x_flat_lst, y_target, uid, output_fp, return_csv=False, test=0\n",
    "):\n",
    "    '''\n",
    "    Arguments:\n",
    "    -----------\n",
    "        data_fp : input filepath to CSV containing 365 dataset\n",
    "        x_lst : list of column names to use in 365 dataset (each day is a col)\n",
    "        x_flat_lst : length of columns in flattened dataset, usually 1000\n",
    "        y_target : label name\n",
    "        uid : unique tag for each observations, used for dedupe\n",
    "        output_fp : path to write out flattened CSV\n",
    "        return_csv : bool returns DF if enabled\n",
    "        test : 0 if read all, otherwise reads test number of rows\n",
    "    '''\n",
    "    \n",
    "    # read in raw dataset, remove deaths\n",
    "    raw_df = read_data(\n",
    "        data_fp=data_fp, check=True, y_target=y_target, uid=uid, test=test\n",
    "    )\n",
    "    raw_df = remove_death(raw_df, y_target, x_lst)\n",
    "\n",
    "    # loopy instead of apply\n",
    "    patient_id, discharge_dt, discharge_id, label = [], [], [], []\n",
    "    data = []\n",
    "    n_events = len(x_flat_lst)\n",
    "    \n",
    "    for _, row in raw_df.iterrows():\n",
    "        patient_id.append(row['patient_id'])\n",
    "        discharge_dt.append(row['discharge_dt'])\n",
    "        discharge_id.append(row[uid])\n",
    "        label.append(row[y_target])\n",
    "        \n",
    "        #print(row[uid])\n",
    "        events_by_day = row[x_lst].values.tolist()\n",
    "        events_day_adjusted = np.array(get_days(events_by_day)) # counted days in between no events and inserted\n",
    "        lst = [move_ad_dis(str(day).replace(\" \", \"\").split(\",\")) for day in events_day_adjusted.ravel(\"K\")]\n",
    "        lst = [event for day in lst for event in day]\n",
    "\n",
    "        if '_days' in lst[0]:\n",
    "            lst = lst[1:]\n",
    "        if len(lst) >= n_events:\n",
    "            lst = lst[-n_events:]\n",
    "\n",
    "        data.append([\"<pad>\"] * (n_events - len(lst)) + lst)\n",
    "\n",
    "    loopy = pd.DataFrame(data)\n",
    "    loopy['patient_id'] = patient_id\n",
    "    loopy['discharge_dt'] = discharge_dt\n",
    "    loopy['discharge_id'] = discharge_id\n",
    "    loopy['unplanned_readmission'] = label        \n",
    "            \n",
    "    loopy.to_csv(output_fp, index=False)\n",
    "    \n",
    "    print(f'Completed: {loopy.shape}')\n",
    "    if return_csv:\n",
    "        return loopy\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data from ../../../data/readmission/fold_0/train/raw_train_data.csv\n",
      "\n",
      "====================Checking data====================\n",
      "\n",
      "Data size: (1295326, 370)\n",
      "\n",
      "Label ratio for unplanned_readmission\n",
      "False    0.855436\n",
      "True     0.144564\n",
      "Name: unplanned_readmission, dtype: float64\n",
      "\n",
      "Discharge_id duplicates: 0\n",
      "\n",
      "====================Removing bad word data====================\n",
      "\n",
      "Removing bad words: 44465 rows contain the word death\n"
     ]
    }
   ],
   "source": [
    "    org_df = read_data(\n",
    "        data_fp=train_365_fp, check=True, y_target=y_target, uid=uid, test=0\n",
    "    )\n",
    "    raw_df = remove_death(org_df, y_target, x_lst)\n",
    "\n",
    "    # loopy instead of apply\n",
    "    patient_id, discharge_dt, discharge_id, label = [], [], [], []\n",
    "    data = []\n",
    "    n_events = len(x_flat_lst)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for _, row in raw_df.iterrows():\n",
    "        patient_id.append(row['patient_id'])\n",
    "        discharge_dt.append(row['discharge_dt'])\n",
    "        discharge_id.append(row[uid])\n",
    "        label.append(row[y_target])\n",
    "        \n",
    "        #print(row[uid])\n",
    "        events_by_day = row[x_lst].values.tolist()\n",
    "        events_day_adjusted = np.array(get_days(events_by_day)) # counted days in between no events and inserted\n",
    "        lst = [move_ad_dis(str(day).replace(\" \", \"\").split(\",\")) for day in events_day_adjusted.ravel(\"K\")]\n",
    "        lst = [event for day in lst for event in day]\n",
    "\n",
    "        if '_days' in lst[0]:\n",
    "            lst = lst[1:]\n",
    "        if len(lst) >= n_events:\n",
    "            lst = lst[-n_events:]\n",
    "\n",
    "        data.append([\"<pad>\"] * (n_events - len(lst)) + lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id                                                       100002085\n",
       "discharge_dt                                                      20110922\n",
       "discharge_id                                            100002085_20110922\n",
       "365                                                                    NaN\n",
       "364                                                                    NaN\n",
       "                                               ...                        \n",
       "3                        d_5119, d_51919, d_7931, d_80709, h_00520, h_7...\n",
       "2                        d_5119, d_5128, d_5180, d_7931, d_80709, h_710...\n",
       "1                        d_5119, d_5183, d_80709, d_8600, d_V5399, h_32...\n",
       "0                        admission, d_496, d_72887, d_78605, d_78650, d...\n",
       "unplanned_readmission                                                False\n",
       "Name: 0, Length: 370, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "        events_by_day = row[x_lst].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 'd_43310, d_4414, h_99204',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 'admission, d_486, d_496, d_5128, d_78605, d_78650, d_80704, d_80709, d_8600, d_8604, d_E8859, d_V5399, h_3120F, h_32551, h_71010, h_71101, h_71250, h_99222, h_99285, p_3404',\n",
       " 'd_2722, d_2930, d_3310, d_3312, d_33183, d_4019, d_4928, d_5128, d_78097, d_80709, d_8600, h_70450, h_71010, h_99221, h_99223, h_99232, h_99233',\n",
       " 'd_2722, d_4019, d_43310, d_51189, d_5119, d_5128, d_80709, d_8600, h_71010, h_93880, h_99231, h_99232, h_99233',\n",
       " 'd_2722, d_4019, d_49121, d_51189, d_5128, d_80700, d_80709, d_8600, h_71010, h_99231, h_99232, h_99233',\n",
       " 'd_2722, d_4019, d_49121, d_51189, d_5119, d_5128, d_80700, d_80709, d_8600, h_71010, h_99232, h_99233',\n",
       " 'd_2722, d_4019, d_5128, d_80709, d_8600, d_V5882, h_71010, h_99231, h_99232, h_99233',\n",
       " 'd_29410, d_5128, d_80709, h_99222, h_99231, h_99233',\n",
       " 'd_486, d_5119, d_5128, d_5183, d_80709, h_71010, h_71250, h_99231, h_99233',\n",
       " 'd_496, d_80709, h_99232, h_99233',\n",
       " 'd_5119, d_80709, d_8600, h_00528, h_31645, h_32124, h_32550, h_32601, h_4048F, h_71010, p_3406, p_3421',\n",
       " 'd_496, d_51889, h_71010',\n",
       " 'd_496, d_51189, d_5119, d_7931, d_80709, h_71010, h_99232, h_99233',\n",
       " 'd_5119, d_51919, d_7931, d_80709, h_00520, h_71010, h_99231, h_99233',\n",
       " 'd_5119, d_5128, d_5180, d_7931, d_80709, h_71010, h_71250, h_99231, h_99233',\n",
       " 'd_5119, d_5183, d_80709, d_8600, d_V5399, h_32422, h_71010, h_99231, h_99233',\n",
       " 'admission, d_496, d_72887, d_78605, d_78650, d_80700, d_80704, d_80709, d_8600, discharge, h_99238, h_99306, h_A0425, h_A0428']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_by_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_day_adjusted = np.array(get_days(events_by_day)) # counted days in between no events and inserted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = events_by_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "    new_lst = []\n",
    "    counter = 1\n",
    "    counting = False\n",
    "    \n",
    "    try:\n",
    "        for event in x:\n",
    "            nan_event = (\n",
    "                (event == np.nan)\n",
    "                or (type(event) == float and math.isnan(event))\n",
    "                or (str(event) == \"nan\")\n",
    "            )\n",
    "            \n",
    "            if nan_event:\n",
    "                if not counting:\n",
    "                    counting = True\n",
    "                counter += 1\n",
    "                \n",
    "            if not nan_event:\n",
    "                if counting:\n",
    "                    counting = False\n",
    "                    event = f\"{counter + 1}_days,\" + event\n",
    "                    new_lst.append(event)\n",
    "                    counter = 0\n",
    "                else:\n",
    "                    event = \"1_days,\" + event\n",
    "                    new_lst.append(event)\n",
    "    except:\n",
    "        print(f\"error: {event}\")\n",
    "        print(f\"counter: {counter}\")\n",
    "        print(f\"new lst: {new_lst}\")\n",
    "        print(f\"org lst: {x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "(type(event) == float and math.isnan(event))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "    loopy = pd.DataFrame(data)\n",
    "    loopy['patient_id'] = patient_id[1:]\n",
    "    loopy['discharge_dt'] = discharge_dt[1:]\n",
    "    loopy['discharge_id'] = discharge_id[1:]\n",
    "    loopy['unplanned_readmission'] = label [1:]       \n",
    "            \n",
    "    loopy.to_csv('../lstm/loopy_train_all_fold0_30days.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loopy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data from ../../../data/readmission/fold_0/train/raw_train_data.csv\n",
      "\n",
      "====================Checking data====================\n",
      "\n",
      "Data size: (1295326, 370)\n",
      "\n",
      "Label ratio for unplanned_readmission\n",
      "False    0.855436\n",
      "True     0.144564\n",
      "Name: unplanned_readmission, dtype: float64\n",
      "\n",
      "Discharge_id duplicates: 0\n",
      "\n",
      "====================Removing bad word data====================\n",
      "\n",
      "Removing bad words: 44465 rows contain the word death\n",
      "error: nan\n",
      "counter: 1\n",
      "new lst: []\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-62dfd0eed534>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0moutput_fp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../lstm/loopy_train_all_fold0_30days.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mreturn_csv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-7-f3179d5f6f4d>\u001b[0m in \u001b[0;36mcreate_flat_dataset_loopy\u001b[0;34m(data_fp, x_lst, x_flat_lst, y_target, uid, output_fp, return_csv, test)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mlst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mevent\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mday\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlst\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mday\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_days'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mlst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mn_events\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "train_df = create_flat_dataset_loopy(\n",
    "    data_fp=train_365_fp, \n",
    "    x_lst=x_lst,\n",
    "    x_flat_lst=x_flat_lst, \n",
    "    y_target=y_target, \n",
    "    uid=uid, \n",
    "    output_fp='../lstm/loopy_train_all_fold0_30days.csv',\n",
    "    return_csv=True, \n",
    "    test=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data from ../../../data/readmission/fold_0/test/raw_test_data.csv\n",
      "\n",
      "====================Checking data====================\n",
      "\n",
      "Data size: (323832, 370)\n",
      "\n",
      "Label ratio for unplanned_readmission\n",
      "False    0.855434\n",
      "True     0.144566\n",
      "Name: unplanned_readmission, dtype: float64\n",
      "\n",
      "Discharge_id duplicates: 0\n",
      "\n",
      "====================Removing bad word data====================\n",
      "\n",
      "Removing bad words: 11075 rows contain the word death\n",
      "Completed: (312757, 1004)\n"
     ]
    }
   ],
   "source": [
    "val_df = create_flat_dataset_loopy(\n",
    "    data_fp=val_365_fp, \n",
    "    x_lst=x_lst,\n",
    "    x_flat_lst=x_flat_lst, \n",
    "    y_target=y_target, \n",
    "    uid=uid, \n",
    "    output_fp='../lstm/loopy_val_all_fold0_30days.csv',\n",
    "    return_csv=True, \n",
    "    test=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d_V560',\n",
       " 'h_90960',\n",
       " '5_days',\n",
       " 'd_9961',\n",
       " 'h_93990',\n",
       " '26_days',\n",
       " 'd_V560',\n",
       " 'h_90960',\n",
       " '1_days',\n",
       " 'd_36511',\n",
       " 'h_92012',\n",
       " '22_days',\n",
       " 'd_4260',\n",
       " 'd_42781',\n",
       " 'h_93288',\n",
       " 'h_99214',\n",
       " '5_days',\n",
       " 'd_V560',\n",
       " 'h_90960',\n",
       " '2_days',\n",
       " 'd_5856',\n",
       " 'd_72981',\n",
       " 'd_V4511',\n",
       " 'h_1000F',\n",
       " 'h_1036F',\n",
       " 'h_99212',\n",
       " '7_days',\n",
       " 'd_61172',\n",
       " 'd_6119',\n",
       " 'd_79389',\n",
       " 'h_76645',\n",
       " 'h_77051',\n",
       " 'h_G0204',\n",
       " '13_days',\n",
       " 'd_25052',\n",
       " 'h_A4253',\n",
       " 'p_D1E',\n",
       " '1_days',\n",
       " 'd_25000',\n",
       " 'd_2512',\n",
       " 'd_2893',\n",
       " 'd_51889',\n",
       " 'd_6111',\n",
       " 'd_61172',\n",
       " 'd_6119',\n",
       " 'd_78009',\n",
       " 'd_7808',\n",
       " 'd_79381',\n",
       " 'h_19102',\n",
       " 'h_19103',\n",
       " 'h_38505',\n",
       " 'h_71010',\n",
       " 'h_88305',\n",
       " 'h_99285',\n",
       " 'h_A0425',\n",
       " 'h_A0427',\n",
       " '7_days',\n",
       " 'd_79389',\n",
       " 'h_99212',\n",
       " '1_days',\n",
       " 'd_5856',\n",
       " 'd_99673',\n",
       " 'd_V560',\n",
       " 'h_36145',\n",
       " 'h_75790',\n",
       " 'h_75962',\n",
       " 'h_75978',\n",
       " 'h_90960',\n",
       " 'h_G0392',\n",
       " 'h_G0393',\n",
       " 'h_J2997',\n",
       " '8_days',\n",
       " 'd_44020',\n",
       " 'h_73660',\n",
       " '7_days',\n",
       " 'd_79389',\n",
       " 'h_76645',\n",
       " '6_days',\n",
       " 'd_6110',\n",
       " 'h_99243',\n",
       " '8_days',\n",
       " 'd_8930',\n",
       " 'h_99213',\n",
       " '1_days',\n",
       " 'd_V560',\n",
       " 'h_90960',\n",
       " '11_days',\n",
       " 'd_5856',\n",
       " 'd_99673',\n",
       " 'h_36145',\n",
       " 'h_75658',\n",
       " 'h_75790',\n",
       " '2_days',\n",
       " 'd_8930',\n",
       " 'h_99213',\n",
       " '7_days',\n",
       " 'd_8831',\n",
       " 'd_8920',\n",
       " 'h_73660',\n",
       " 'h_99213',\n",
       " '7_days',\n",
       " 'd_71530',\n",
       " 'h_78315',\n",
       " '4_days',\n",
       " 'd_61172',\n",
       " 'd_V560',\n",
       " 'h_90961',\n",
       " 'h_99212',\n",
       " '3_days',\n",
       " 'd_1101',\n",
       " 'h_99213',\n",
       " '18_days',\n",
       " 'd_36511',\n",
       " 'h_92012',\n",
       " 'h_92083',\n",
       " '9_days',\n",
       " 'd_V560',\n",
       " 'h_90960',\n",
       " '1_days',\n",
       " 'd_1101',\n",
       " 'h_99213',\n",
       " '11_days',\n",
       " 'd_61172',\n",
       " 'h_99212',\n",
       " '19_days',\n",
       " 'd_V560',\n",
       " 'h_90960',\n",
       " '4_days',\n",
       " 'd_72981',\n",
       " 'd_8930',\n",
       " 'h_73630',\n",
       " 'h_99213',\n",
       " '6_days',\n",
       " 'd_5856',\n",
       " 'd_9961',\n",
       " 'd_V4511',\n",
       " 'h_1000F',\n",
       " 'h_1036F',\n",
       " 'h_93990',\n",
       " 'h_99213',\n",
       " '7_days',\n",
       " 'd_4241',\n",
       " 'd_V522',\n",
       " 'h_93306',\n",
       " 'h_V2624',\n",
       " 'p_D1F',\n",
       " '2_days',\n",
       " 'd_70715',\n",
       " 'h_11041',\n",
       " '5_days',\n",
       " 'd_4240',\n",
       " 'd_4260',\n",
       " 'd_V4501',\n",
       " 'h_93005',\n",
       " 'h_93010',\n",
       " 'h_99214',\n",
       " '2_days',\n",
       " 'd_25040',\n",
       " 'd_4592',\n",
       " 'd_5856',\n",
       " 'd_99673',\n",
       " 'h_35476',\n",
       " 'h_36145',\n",
       " 'h_75820',\n",
       " 'h_75978',\n",
       " 'h_G0393',\n",
       " 'h_J1815',\n",
       " '4_days',\n",
       " 'd_70715',\n",
       " 'h_11042',\n",
       " '1_days',\n",
       " 'd_44023',\n",
       " 'd_4510',\n",
       " 'd_5856',\n",
       " 'd_99673',\n",
       " 'd_V4511',\n",
       " 'd_V560',\n",
       " 'h_1000F',\n",
       " 'h_1036F',\n",
       " 'h_90960',\n",
       " 'h_93923',\n",
       " 'h_93970',\n",
       " 'h_99213',\n",
       " '7_days',\n",
       " 'd_44422',\n",
       " 'd_5856',\n",
       " 'd_99673',\n",
       " 'h_01270',\n",
       " 'h_36825',\n",
       " 'h_6045F',\n",
       " 'h_75710',\n",
       " 'h_75790',\n",
       " 'h_93010',\n",
       " '2_days',\n",
       " 'd_V7285',\n",
       " 'h_99212',\n",
       " '7_days',\n",
       " 'd_1101',\n",
       " 'h_11721',\n",
       " '5_days',\n",
       " 'd_99673',\n",
       " 'h_93990',\n",
       " '9_days',\n",
       " 'd_V560',\n",
       " 'h_90960',\n",
       " '3_days',\n",
       " 'd_25052',\n",
       " 'h_A4253',\n",
       " 'p_D1E',\n",
       " '9_days',\n",
       " 'd_5856',\n",
       " 'd_72981',\n",
       " 'd_9961',\n",
       " 'h_1000F',\n",
       " 'h_1036F',\n",
       " 'h_99213',\n",
       " '2_days',\n",
       " 'd_99673',\n",
       " 'h_36145',\n",
       " 'h_75790',\n",
       " 'h_93041',\n",
       " '5_days',\n",
       " 'd_61179',\n",
       " 'h_76645',\n",
       " 'h_77051',\n",
       " 'h_G0204',\n",
       " '3_days',\n",
       " 'd_5856',\n",
       " 'd_99673',\n",
       " 'h_75790',\n",
       " 'h_75978',\n",
       " 'h_G0393',\n",
       " '4_days',\n",
       " 'd_44023',\n",
       " 'd_5856',\n",
       " 'd_V4511',\n",
       " 'h_1000F',\n",
       " 'h_1036F',\n",
       " 'h_99213',\n",
       " '2_days',\n",
       " 'd_40391',\n",
       " 'd_4293',\n",
       " 'd_44023',\n",
       " 'd_5849',\n",
       " 'd_5856',\n",
       " 'd_99673',\n",
       " 'h_35470',\n",
       " 'h_35474',\n",
       " 'h_36415',\n",
       " 'h_71010',\n",
       " 'h_93010',\n",
       " 'h_J2250',\n",
       " 'h_J3010',\n",
       " 'admission',\n",
       " '1_days',\n",
       " 'd_25002',\n",
       " 'd_40391',\n",
       " 'd_5856',\n",
       " 'd_7854',\n",
       " 'd_99673',\n",
       " 'h_01844',\n",
       " 'h_36832',\n",
       " 'h_90935',\n",
       " 'h_99253',\n",
       " 'h_99255',\n",
       " 'p_3942',\n",
       " '1_days',\n",
       " 'd_44024',\n",
       " 'd_5856',\n",
       " 'h_93923',\n",
       " 'h_99232',\n",
       " '1_days',\n",
       " 'd_5856',\n",
       " 'h_99232',\n",
       " '1_days',\n",
       " 'd_4439',\n",
       " 'd_44422',\n",
       " 'd_5856',\n",
       " 'd_70715',\n",
       " 'h_75625',\n",
       " 'h_75716',\n",
       " 'h_75898',\n",
       " 'h_75962',\n",
       " 'h_90935',\n",
       " 'h_99222',\n",
       " 'p_3950',\n",
       " '1_days',\n",
       " 'd_4011',\n",
       " 'd_4293',\n",
       " 'd_4439',\n",
       " 'd_44422',\n",
       " 'd_5856',\n",
       " 'd_586',\n",
       " 'h_35470',\n",
       " 'h_37205',\n",
       " 'h_71010',\n",
       " 'h_75960',\n",
       " 'h_99232',\n",
       " 'p_3950',\n",
       " '1_days',\n",
       " 'd_25000',\n",
       " 'd_4439',\n",
       " 'd_5856',\n",
       " 'd_8921',\n",
       " 'd_99673',\n",
       " 'h_11040',\n",
       " 'h_71010',\n",
       " 'h_90935',\n",
       " 'h_99232',\n",
       " '1_days',\n",
       " 'd_5856',\n",
       " 'h_99232',\n",
       " '1_days',\n",
       " 'd_5856',\n",
       " 'h_99232',\n",
       " '1_days',\n",
       " 'd_5856',\n",
       " 'h_99231',\n",
       " '1_days',\n",
       " 'd_25060',\n",
       " 'd_261',\n",
       " 'd_5856',\n",
       " 'h_99231',\n",
       " 'admission',\n",
       " 'discharge',\n",
       " '1_days',\n",
       " 'd_4439',\n",
       " 'd_5856',\n",
       " 'h_99222',\n",
       " 'h_99233',\n",
       " '1_days',\n",
       " 'd_25000',\n",
       " 'd_4439',\n",
       " 'd_5856',\n",
       " 'h_90935',\n",
       " 'h_99232',\n",
       " 'p_3995',\n",
       " '1_days',\n",
       " 'd_4439',\n",
       " 'd_5856',\n",
       " 'h_99231',\n",
       " 'h_99233',\n",
       " '1_days',\n",
       " 'd_5856',\n",
       " 'h_99233',\n",
       " '1_days',\n",
       " 'd_25000',\n",
       " 'd_5856',\n",
       " 'h_99232',\n",
       " 'h_99233',\n",
       " '1_days',\n",
       " 'd_5856',\n",
       " 'h_99232',\n",
       " '1_days',\n",
       " 'd_4011',\n",
       " 'd_5856',\n",
       " 'h_99232',\n",
       " '1_days',\n",
       " 'd_5856',\n",
       " 'h_99232',\n",
       " '1_days',\n",
       " 'd_25070',\n",
       " 'd_5856',\n",
       " 'd_7854',\n",
       " 'h_01232',\n",
       " 'h_27590',\n",
       " 'h_99232',\n",
       " 'p_8417',\n",
       " '2_days',\n",
       " 'd_5856',\n",
       " 'h_90935',\n",
       " 'p_9904',\n",
       " '1_days',\n",
       " 'd_5856',\n",
       " 'h_90935',\n",
       " '1_days',\n",
       " 'd_4439',\n",
       " 'd_5856',\n",
       " 'h_99231',\n",
       " 'h_99232',\n",
       " '1_days',\n",
       " 'd_25000',\n",
       " 'd_4439',\n",
       " 'h_99231',\n",
       " 'h_99232',\n",
       " '1_days',\n",
       " 'd_4439',\n",
       " 'h_99231',\n",
       " '1_days',\n",
       " 'd_5856',\n",
       " 'h_99233',\n",
       " '1_days',\n",
       " 'd_44389',\n",
       " 'd_5856',\n",
       " 'h_90935',\n",
       " 'h_99232',\n",
       " '1_days',\n",
       " 'd_4011',\n",
       " 'd_44389',\n",
       " 'h_99232',\n",
       " '1_days',\n",
       " 'd_25002',\n",
       " 'd_44389',\n",
       " 'd_5856',\n",
       " 'h_90935',\n",
       " 'h_99231',\n",
       " '1_days',\n",
       " 'd_5856',\n",
       " 'h_99233',\n",
       " '2_days',\n",
       " 'd_5856',\n",
       " 'h_99232',\n",
       " '2_days',\n",
       " 'd_5856',\n",
       " 'h_90935',\n",
       " '1_days',\n",
       " 'd_5856',\n",
       " 'h_99232',\n",
       " '1_days',\n",
       " 'd_5856',\n",
       " 'h_99232',\n",
       " '2_days',\n",
       " 'd_5856',\n",
       " 'h_99231',\n",
       " '1_days',\n",
       " 'd_5856',\n",
       " 'h_99233',\n",
       " '1_days',\n",
       " 'd_40391',\n",
       " 'd_5856',\n",
       " 'd_V5789',\n",
       " 'h_99233',\n",
       " 'p_9339',\n",
       " 'p_9383',\n",
       " 'admission',\n",
       " 'discharge',\n",
       " '1_days',\n",
       " 'd_5856',\n",
       " 'd_8972',\n",
       " 'd_V4976',\n",
       " 'h_90801',\n",
       " 'h_99222',\n",
       " 'h_99233',\n",
       " 'p_3995',\n",
       " '1_days',\n",
       " 'd_4439',\n",
       " 'd_5856',\n",
       " 'd_8972',\n",
       " 'd_V4976',\n",
       " 'd_V5789',\n",
       " 'h_90816',\n",
       " 'h_99231',\n",
       " 'h_99233',\n",
       " '1_days',\n",
       " 'd_25000',\n",
       " 'd_4439',\n",
       " 'd_8972',\n",
       " 'h_99231',\n",
       " '1_days',\n",
       " 'd_5855',\n",
       " 'h_99232',\n",
       " '2_days',\n",
       " 'd_4439',\n",
       " 'd_5856',\n",
       " 'h_90935',\n",
       " 'h_99231',\n",
       " '1_days',\n",
       " 'd_8972',\n",
       " 'h_99231',\n",
       " '1_days',\n",
       " 'd_5856',\n",
       " 'd_8972',\n",
       " 'h_90935',\n",
       " 'h_99231',\n",
       " '1_days',\n",
       " 'd_8972',\n",
       " 'h_99231',\n",
       " '1_days',\n",
       " 'd_5856',\n",
       " 'd_8972',\n",
       " 'd_V4976',\n",
       " 'h_90816',\n",
       " 'h_90935',\n",
       " 'h_99231',\n",
       " '1_days',\n",
       " 'd_5856',\n",
       " 'd_V4976',\n",
       " 'h_99231',\n",
       " 'h_99232',\n",
       " '3_days',\n",
       " 'd_8972',\n",
       " 'h_E0143',\n",
       " 'h_E0163',\n",
       " 'h_E0961',\n",
       " 'p_D1D',\n",
       " 'p_D1E',\n",
       " 'discharge',\n",
       " True,\n",
       " '102878613_20111115',\n",
       " 20111115.0,\n",
       " 102878613.0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "did = '102878613_20111115'\n",
    "[x for x in raw_df[raw_df.discharge_id == did].values.tolist()[0] if x != '<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admission, d_486, d_486, d_5990, d_7197, d_7282, discharge, h_99239, h_A0425, h_A0428']\n",
      "[nan]\n",
      "[nan]\n",
      "['d_78079, h_93010']\n",
      "['admission, d_340, d_490, d_51889, d_5990, d_7850, h_71020, h_71020, h_96361, h_96374, h_99285, h_A0425, h_A0429, h_J7030']\n",
      "[nan]\n",
      "[nan]\n",
      "[nan]\n",
      "[nan]\n",
      "[nan]\n",
      "[nan]\n",
      "[nan]\n",
      "[nan]\n",
      "[nan]\n",
      "[nan]\n",
      "[nan]\n",
      "[nan]\n",
      "[nan]\n",
      "[nan]\n",
      "[nan]\n",
      "[nan]\n",
      "[nan]\n",
      "[nan]\n",
      "[nan]\n",
      "[nan]\n",
      "[nan]\n",
      "['d_5950, h_81002, h_99213']\n",
      "[nan]\n",
      "[nan]\n",
      "[nan]\n"
     ]
    }
   ],
   "source": [
    "for idx in range(0, 30):\n",
    "    print([x for x in org_df.loc[org_df.discharge_id==did, str(idx)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>discharge_dt</th>\n",
       "      <th>discharge_id</th>\n",
       "      <th>365</th>\n",
       "      <th>364</th>\n",
       "      <th>363</th>\n",
       "      <th>362</th>\n",
       "      <th>361</th>\n",
       "      <th>360</th>\n",
       "      <th>359</th>\n",
       "      <th>...</th>\n",
       "      <th>8</th>\n",
       "      <th>7</th>\n",
       "      <th>6</th>\n",
       "      <th>5</th>\n",
       "      <th>4</th>\n",
       "      <th>3</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>unplanned_readmission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48314</th>\n",
       "      <td>102878613</td>\n",
       "      <td>20111115</td>\n",
       "      <td>102878613_20111115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>admission, d_340, d_490, d_51889, d_5990, d_78...</td>\n",
       "      <td>d_78079, h_93010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>admission, d_486, d_486, d_5990, d_7197, d_728...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 370 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       patient_id  discharge_dt        discharge_id  365  364  363  362  361  \\\n",
       "48314   102878613      20111115  102878613_20111115  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "       360  359  ...    8    7    6    5  \\\n",
       "48314  NaN  NaN  ...  NaN  NaN  NaN  NaN   \n",
       "\n",
       "                                                       4                 3  \\\n",
       "48314  admission, d_340, d_490, d_51889, d_5990, d_78...  d_78079, h_93010   \n",
       "\n",
       "         2    1                                                  0  \\\n",
       "48314  NaN  NaN  admission, d_486, d_486, d_5990, d_7197, d_728...   \n",
       "\n",
       "      unplanned_readmission  \n",
       "48314                  True  \n",
       "\n",
       "[1 rows x 370 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_obs = org_df[org_df.discharge_id == did]\n",
    "org_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    x = np.array(get_days(org_obs[x_lst].values[0]))\n",
    "    lst = [move_ad_dis(str(day).replace(\" \", \"\").split(\",\")) for day in x.ravel(\"K\")]\n",
    "    lst = [event for day in lst for event in day]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['21_days',\n",
       " 'discharge',\n",
       " '1_days',\n",
       " 'h_1BGL1',\n",
       " '4_days',\n",
       " 'h_G0151',\n",
       " '14_days',\n",
       " 'h_G0151',\n",
       " '14_days',\n",
       " 'd_340',\n",
       " 'h_99214',\n",
       " '5_days',\n",
       " 'd_340',\n",
       " 'h_G0180',\n",
       " '1_days',\n",
       " 'd_7859',\n",
       " 'h_93880',\n",
       " '26_days',\n",
       " 'd_43311',\n",
       " 'h_99213',\n",
       " '79_days',\n",
       " 'd_340',\n",
       " 'h_99213',\n",
       " 'h_G8553',\n",
       " '92_days',\n",
       " 'd_7823',\n",
       " 'h_36415',\n",
       " 'h_80051',\n",
       " 'h_82565',\n",
       " 'h_84520',\n",
       " 'h_99213',\n",
       " '6_days',\n",
       " 'd_7852',\n",
       " 'h_93306',\n",
       " '22_days',\n",
       " 'd_5854',\n",
       " 'h_99205',\n",
       " '4_days',\n",
       " 'h_36415',\n",
       " 'h_80069',\n",
       " 'h_81001',\n",
       " 'h_82306',\n",
       " 'h_82570',\n",
       " 'h_83540',\n",
       " 'h_83550',\n",
       " 'h_83970',\n",
       " 'h_84156',\n",
       " 'h_85025',\n",
       " 'h_86334',\n",
       " 'h_86335',\n",
       " '2_days',\n",
       " 'd_5854',\n",
       " 'h_76775',\n",
       " '15_days',\n",
       " 'h_36415',\n",
       " 'h_80053',\n",
       " 'h_80061',\n",
       " 'h_84443',\n",
       " 'h_85025',\n",
       " 'h_86141',\n",
       " '7_days',\n",
       " 'd_5854',\n",
       " 'h_99214',\n",
       " '18_days',\n",
       " 'd_5854',\n",
       " 'h_99214',\n",
       " 'h_G0420',\n",
       " '10_days',\n",
       " 'd_5950',\n",
       " 'h_81002',\n",
       " 'h_99213',\n",
       " '22_days',\n",
       " 'd_340',\n",
       " 'd_490',\n",
       " 'd_51889',\n",
       " 'd_5990',\n",
       " 'd_7850',\n",
       " 'h_71020',\n",
       " 'h_96361',\n",
       " 'h_96374',\n",
       " 'h_99285',\n",
       " 'h_A0425',\n",
       " 'h_A0429',\n",
       " 'h_J7030',\n",
       " 'admission',\n",
       " '1_days',\n",
       " 'd_78079',\n",
       " 'h_93010',\n",
       " '3_days',\n",
       " 'd_486',\n",
       " 'd_5990',\n",
       " 'd_7197',\n",
       " 'd_7282',\n",
       " 'h_99239',\n",
       " 'h_A0425',\n",
       " 'h_A0428',\n",
       " 'admission',\n",
       " 'discharge']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================Removing bad word data====================\n",
      "\n",
      "Removing bad words: 44492 rows contain the word death\n"
     ]
    }
   ],
   "source": [
    "no_death_df = remove_death(org_df, y_target, x_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>discharge_dt</th>\n",
       "      <th>discharge_id</th>\n",
       "      <th>365</th>\n",
       "      <th>364</th>\n",
       "      <th>363</th>\n",
       "      <th>362</th>\n",
       "      <th>361</th>\n",
       "      <th>360</th>\n",
       "      <th>359</th>\n",
       "      <th>...</th>\n",
       "      <th>8</th>\n",
       "      <th>7</th>\n",
       "      <th>6</th>\n",
       "      <th>5</th>\n",
       "      <th>4</th>\n",
       "      <th>3</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>unplanned_readmission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48314</th>\n",
       "      <td>102878613</td>\n",
       "      <td>20111115</td>\n",
       "      <td>102878613_20111115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>admission, d_340, d_490, d_51889, d_5990, d_78...</td>\n",
       "      <td>d_78079, h_93010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>admission, d_486, d_486, d_5990, d_7197, d_728...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 370 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       patient_id  discharge_dt        discharge_id  365  364  363  362  361  \\\n",
       "48314   102878613      20111115  102878613_20111115  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "       360  359  ...    8    7    6    5  \\\n",
       "48314  NaN  NaN  ...  NaN  NaN  NaN  NaN   \n",
       "\n",
       "                                                       4                 3  \\\n",
       "48314  admission, d_340, d_490, d_51889, d_5990, d_78...  d_78079, h_93010   \n",
       "\n",
       "         2    1                                                  0  \\\n",
       "48314  NaN  NaN  admission, d_486, d_486, d_5990, d_7197, d_728...   \n",
       "\n",
       "      unplanned_readmission  \n",
       "48314                  True  \n",
       "\n",
       "[1 rows x 370 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodeath_obs = no_death_df[no_death_df.discharge_id == did]\n",
    "nodeath_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "    nodeath_x = np.array(get_days(nodeath_obs[x_lst].values[0]))\n",
    "    nodeath_lst = [move_ad_dis(str(day).replace(\" \", \"\").split(\",\")) for day in nodeath_x.ravel(\"K\")]\n",
    "    nodeath_lst = [event for day in nodeath_lst for event in day]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodeath_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  '<pad>',\n",
       "  'discharge',\n",
       "  '1_days',\n",
       "  'h_1BGL1',\n",
       "  '4_days',\n",
       "  'h_G0151',\n",
       "  '14_days',\n",
       "  'h_G0151',\n",
       "  '14_days',\n",
       "  'd_340',\n",
       "  'h_99214',\n",
       "  '5_days',\n",
       "  'd_340',\n",
       "  'h_G0180',\n",
       "  '1_days',\n",
       "  'd_7859',\n",
       "  'h_93880',\n",
       "  '26_days',\n",
       "  'd_43311',\n",
       "  'h_99213',\n",
       "  '79_days',\n",
       "  'd_340',\n",
       "  'h_99213',\n",
       "  'h_G8553',\n",
       "  '92_days',\n",
       "  'd_7823',\n",
       "  'h_36415',\n",
       "  'h_80051',\n",
       "  'h_82565',\n",
       "  'h_84520',\n",
       "  'h_99213',\n",
       "  '6_days',\n",
       "  'd_7852',\n",
       "  'h_93306',\n",
       "  '22_days',\n",
       "  'd_5854',\n",
       "  'h_99205',\n",
       "  '4_days',\n",
       "  'h_36415',\n",
       "  'h_80069',\n",
       "  'h_81001',\n",
       "  'h_82306',\n",
       "  'h_82570',\n",
       "  'h_83540',\n",
       "  'h_83550',\n",
       "  'h_83970',\n",
       "  'h_84156',\n",
       "  'h_85025',\n",
       "  'h_86334',\n",
       "  'h_86335',\n",
       "  '2_days',\n",
       "  'd_5854',\n",
       "  'h_76775',\n",
       "  '15_days',\n",
       "  'h_36415',\n",
       "  'h_80053',\n",
       "  'h_80061',\n",
       "  'h_84443',\n",
       "  'h_85025',\n",
       "  'h_86141',\n",
       "  '7_days',\n",
       "  'd_5854',\n",
       "  'h_99214',\n",
       "  '18_days',\n",
       "  'd_5854',\n",
       "  'h_99214',\n",
       "  'h_G0420',\n",
       "  '10_days',\n",
       "  'd_5950',\n",
       "  'h_81002',\n",
       "  'h_99213',\n",
       "  '22_days',\n",
       "  'd_340',\n",
       "  'd_490',\n",
       "  'd_51889',\n",
       "  'd_5990',\n",
       "  'd_7850',\n",
       "  'h_71020',\n",
       "  'h_96361',\n",
       "  'h_96374',\n",
       "  'h_99285',\n",
       "  'h_A0425',\n",
       "  'h_A0429',\n",
       "  'h_J7030',\n",
       "  'admission',\n",
       "  '1_days',\n",
       "  'd_78079',\n",
       "  'h_93010',\n",
       "  '3_days',\n",
       "  'd_486',\n",
       "  'd_5990',\n",
       "  'd_7197',\n",
       "  'd_7282',\n",
       "  'h_99239',\n",
       "  'h_A0425',\n",
       "  'h_A0428',\n",
       "  'admission',\n",
       "  'discharge']]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodeath_obs[x_lst].apply(flatten, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_id, discharge_dt, discharge_id, label = [], [], [], []\n",
    "data = []\n",
    "n_events = 1000\n",
    "counter = 0\n",
    "lim = 1e9\n",
    "for _, row in no_death_df.iterrows():\n",
    "    patient_id.append(row['patient_id'])\n",
    "    discharge_dt.append(row['discharge_dt'])\n",
    "    discharge_id.append(row['discharge_id'])\n",
    "    label.append(row['unplanned_readmission'])\n",
    "    \n",
    "    x = row[x_lst].values.tolist()\n",
    "    x2 = np.array(get_days(x))\n",
    "    lst = [move_ad_dis(str(day).replace(\" \", \"\").split(\",\")) for day in x2.ravel(\"K\")]\n",
    "    lst = [event for day in lst for event in day]\n",
    "    \n",
    "    if '_days' in lst[0]:\n",
    "        lst = lst[1:]\n",
    "    if len(lst) >= n_events:\n",
    "        lst = lst[-n_events:]\n",
    "\n",
    "    data.append([\"<pad>\"] * (n_events - len(lst)) + lst)\n",
    "    \n",
    "    counter += 1\n",
    "    if counter > lim:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "loopy = pd.DataFrame(data)\n",
    "loopy['patient_id'] = patient_id\n",
    "loopy['discharge_dt'] = discharge_dt\n",
    "loopy['discharge_id'] = discharge_id\n",
    "loopy['unplanned_readmission'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>discharge_dt</th>\n",
       "      <th>discharge_id</th>\n",
       "      <th>unplanned_readmission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>h_99238</td>\n",
       "      <td>h_99306</td>\n",
       "      <td>h_A0425</td>\n",
       "      <td>h_A0428</td>\n",
       "      <td>admission</td>\n",
       "      <td>discharge</td>\n",
       "      <td>100002085</td>\n",
       "      <td>20110922</td>\n",
       "      <td>100002085_20110922</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>h_90732</td>\n",
       "      <td>h_99232</td>\n",
       "      <td>h_99233</td>\n",
       "      <td>h_G0009</td>\n",
       "      <td>p_9955</td>\n",
       "      <td>discharge</td>\n",
       "      <td>100002829</td>\n",
       "      <td>20111013</td>\n",
       "      <td>100002829_20111013</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>d_V4989</td>\n",
       "      <td>h_99231</td>\n",
       "      <td>h_A0425</td>\n",
       "      <td>h_A0428</td>\n",
       "      <td>admission</td>\n",
       "      <td>discharge</td>\n",
       "      <td>100003379</td>\n",
       "      <td>20091207</td>\n",
       "      <td>100003379_20091207</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>d_78650</td>\n",
       "      <td>h_99231</td>\n",
       "      <td>2_days</td>\n",
       "      <td>d_78650</td>\n",
       "      <td>h_99238</td>\n",
       "      <td>discharge</td>\n",
       "      <td>100008869</td>\n",
       "      <td>20101116</td>\n",
       "      <td>100008869_20101116</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>d_5849</td>\n",
       "      <td>d_78904</td>\n",
       "      <td>h_99232</td>\n",
       "      <td>h_99239</td>\n",
       "      <td>admission</td>\n",
       "      <td>discharge</td>\n",
       "      <td>100009927</td>\n",
       "      <td>20090617</td>\n",
       "      <td>100009927_20090617</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1004 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5      6      7      8      9  ...  \\\n",
       "0  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  ...   \n",
       "1  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  ...   \n",
       "2  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  ...   \n",
       "3  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  ...   \n",
       "4  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  ...   \n",
       "\n",
       "       994      995      996      997        998        999 patient_id  \\\n",
       "0  h_99238  h_99306  h_A0425  h_A0428  admission  discharge  100002085   \n",
       "1  h_90732  h_99232  h_99233  h_G0009     p_9955  discharge  100002829   \n",
       "2  d_V4989  h_99231  h_A0425  h_A0428  admission  discharge  100003379   \n",
       "3  d_78650  h_99231   2_days  d_78650    h_99238  discharge  100008869   \n",
       "4   d_5849  d_78904  h_99232  h_99239  admission  discharge  100009927   \n",
       "\n",
       "  discharge_dt        discharge_id unplanned_readmission  \n",
       "0     20110922  100002085_20110922                 False  \n",
       "1     20111013  100002829_20111013                 False  \n",
       "2     20091207  100003379_20091207                  True  \n",
       "3     20101116  100008869_20101116                 False  \n",
       "4     20090617  100009927_20090617                 False  \n",
       "\n",
       "[5 rows x 1004 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loopy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '../lstm/tmp_loopy/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-6f4476e09327>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../lstm/tmp_loopy/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '../lstm/tmp_loopy/'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs('../lstm/tmp_loopy/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loopy.iloc[:-10000].to_csv('../lstm/tmp_loopy/loppy_train_all.csv', index=False)\n",
    "\n",
    "loopy.iloc[-10000:].to_csv('../lstm/tmp_loopy/loppy_test_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate training data and vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Processing fold 0\n",
      "****************************************************************************************************\n",
      "Read data from ../../../data/readmission/fold_0/train/raw_train_data.csv\n",
      "\n",
      "====================Checking data====================\n",
      "\n",
      "Data size: (50000, 370)\n",
      "\n",
      "Label ratio for unplanned_readmission\n",
      "False    0.8539\n",
      "True     0.1461\n",
      "Name: unplanned_readmission, dtype: float64\n",
      "\n",
      "Discharge_id duplicates: 0\n",
      "\n",
      "====================Removing bad word data====================\n",
      "\n",
      "Removing bad words: 1637 rows contain the word death\n",
      "Vocab generation required\n",
      "\n",
      "====================Build vocabulary====================\n",
      "\n",
      "start word number:  (48363000,)\n",
      "exact word number:  48363000\n",
      "Completed vocabulary: 20058 vocabs\n",
      "Nb of tokens: 20058\n",
      "Completed, wrote to vocab: ../../../data/readmission/fold_0/vocab/vocab_1000_vall_30days, \n",
      " train data:../../../data/readmission/fold_0/train/train_datalist_1000_vall_30days.pkl\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Processing fold 1\n",
      "****************************************************************************************************\n",
      "Read data from ../../../data/readmission/fold_1/train/raw_train_data.csv\n",
      "\n",
      "====================Checking data====================\n",
      "\n",
      "Data size: (50000, 370)\n",
      "\n",
      "Label ratio for unplanned_readmission\n",
      "False    0.85422\n",
      "True     0.14578\n",
      "Name: unplanned_readmission, dtype: float64\n",
      "\n",
      "Discharge_id duplicates: 0\n",
      "\n",
      "====================Removing bad word data====================\n",
      "\n",
      "Removing bad words: 1603 rows contain the word death\n",
      "Vocab generation required\n",
      "\n",
      "====================Build vocabulary====================\n",
      "\n",
      "start word number:  (48397000,)\n",
      "exact word number:  48397000\n",
      "Completed vocabulary: 20083 vocabs\n",
      "Nb of tokens: 20083\n",
      "Completed, wrote to vocab: ../../../data/readmission/fold_1/vocab/vocab_1000_vall_30days, \n",
      " train data:../../../data/readmission/fold_1/train/train_datalist_1000_vall_30days.pkl\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Processing fold 2\n",
      "****************************************************************************************************\n",
      "Read data from ../../../data/readmission/fold_2/train/raw_train_data.csv\n",
      "\n",
      "====================Checking data====================\n",
      "\n",
      "Data size: (50000, 370)\n",
      "\n",
      "Label ratio for unplanned_readmission\n",
      "False    0.85416\n",
      "True     0.14584\n",
      "Name: unplanned_readmission, dtype: float64\n",
      "\n",
      "Discharge_id duplicates: 0\n",
      "\n",
      "====================Removing bad word data====================\n",
      "\n",
      "Removing bad words: 1626 rows contain the word death\n",
      "Vocab generation required\n",
      "\n",
      "====================Build vocabulary====================\n",
      "\n",
      "start word number:  (48374000,)\n",
      "exact word number:  48374000\n",
      "Completed vocabulary: 20075 vocabs\n",
      "Nb of tokens: 20075\n",
      "Completed, wrote to vocab: ../../../data/readmission/fold_2/vocab/vocab_1000_vall_30days, \n",
      " train data:../../../data/readmission/fold_2/train/train_datalist_1000_vall_30days.pkl\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Processing fold 3\n",
      "****************************************************************************************************\n",
      "Read data from ../../../data/readmission/fold_3/train/raw_train_data.csv\n",
      "\n",
      "====================Checking data====================\n",
      "\n",
      "Data size: (50000, 370)\n",
      "\n",
      "Label ratio for unplanned_readmission\n",
      "False    0.85488\n",
      "True     0.14512\n",
      "Name: unplanned_readmission, dtype: float64\n",
      "\n",
      "Discharge_id duplicates: 0\n",
      "\n",
      "====================Removing bad word data====================\n",
      "\n",
      "Removing bad words: 1604 rows contain the word death\n",
      "Vocab generation required\n",
      "\n",
      "====================Build vocabulary====================\n",
      "\n",
      "start word number:  (48396000,)\n",
      "exact word number:  48396000\n",
      "Completed vocabulary: 20081 vocabs\n",
      "Nb of tokens: 20081\n",
      "Completed, wrote to vocab: ../../../data/readmission/fold_3/vocab/vocab_1000_vall_30days, \n",
      " train data:../../../data/readmission/fold_3/train/train_datalist_1000_vall_30days.pkl\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Processing fold 4\n",
      "****************************************************************************************************\n",
      "Read data from ../../../data/readmission/fold_4/train/raw_train_data.csv\n",
      "\n",
      "====================Checking data====================\n",
      "\n",
      "Data size: (50000, 370)\n",
      "\n",
      "Label ratio for unplanned_readmission\n",
      "False    0.8531\n",
      "True     0.1469\n",
      "Name: unplanned_readmission, dtype: float64\n",
      "\n",
      "Discharge_id duplicates: 0\n",
      "\n",
      "====================Removing bad word data====================\n",
      "\n",
      "Removing bad words: 1608 rows contain the word death\n",
      "Vocab generation required\n",
      "\n",
      "====================Build vocabulary====================\n",
      "\n",
      "start word number:  (48392000,)\n",
      "exact word number:  48392000\n",
      "Completed vocabulary: 20137 vocabs\n",
      "Nb of tokens: 20137\n",
      "Completed, wrote to vocab: ../../../data/readmission/fold_4/vocab/vocab_1000_vall_30days, \n",
      " train data:../../../data/readmission/fold_4/train/train_datalist_1000_vall_30days.pkl\n"
     ]
    }
   ],
   "source": [
    "for idx, (train_fp, train_dl_fp, vocab_fp) in enumerate(zip(train_fps, train_dl_fps, vocab_fps)):\n",
    "    print(\"\\n\\n\" + \"*\" * 100)\n",
    "    print(f\"Processing fold {idx}\\n\" + \"*\" * 100)\n",
    "    \n",
    "    create_flat_dataset(\n",
    "        data_fp=train_fp,\n",
    "        x_lst=x_lst,\n",
    "        x_flat_lst=x_flat_lst,\n",
    "        y_target=y_target,\n",
    "        uid=uid,\n",
    "        train=True,\n",
    "        vocab_fp=vocab_fp,\n",
    "        datalist_fp=train_dl_fp,\n",
    "        min_freq=1,\n",
    "        save_csv=True,\n",
    "    )\n",
    "    \n",
    "    print(f\"Completed, wrote to vocab: {vocab_fp}, \\n train data:{train_dl_fp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Processing fold 0\n",
      "****************************************************************************************************\n",
      "Read data from ../../../data/readmission/fold_0/test/raw_test_data.csv\n",
      "\n",
      "====================Checking data====================\n",
      "\n",
      "Data size: (50000, 370)\n",
      "\n",
      "Label ratio for unplanned_readmission\n",
      "False    0.8579\n",
      "True     0.1421\n",
      "Name: unplanned_readmission, dtype: float64\n",
      "\n",
      "Discharge_id duplicates: 0\n",
      "\n",
      "====================Removing bad word data====================\n",
      "\n",
      "Removing bad words: 1807 rows contain the word death\n",
      "Completed, read from vocab: ../../../data/readmission/fold_0/vocab/vocab_1000_vall_30days, \n",
      " wrote to ../../../data/readmission/fold_0/test/test_datalist_1000_vall_30days.pkl\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Processing fold 1\n",
      "****************************************************************************************************\n",
      "Read data from ../../../data/readmission/fold_1/test/raw_test_data.csv\n",
      "\n",
      "====================Checking data====================\n",
      "\n",
      "Data size: (50000, 370)\n",
      "\n",
      "Label ratio for unplanned_readmission\n",
      "False    0.85646\n",
      "True     0.14354\n",
      "Name: unplanned_readmission, dtype: float64\n",
      "\n",
      "Discharge_id duplicates: 0\n",
      "\n",
      "====================Removing bad word data====================\n",
      "\n",
      "Removing bad words: 1870 rows contain the word death\n",
      "Completed, read from vocab: ../../../data/readmission/fold_1/vocab/vocab_1000_vall_30days, \n",
      " wrote to ../../../data/readmission/fold_1/test/test_datalist_1000_vall_30days.pkl\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Processing fold 2\n",
      "****************************************************************************************************\n",
      "Read data from ../../../data/readmission/fold_2/test/raw_test_data.csv\n",
      "\n",
      "====================Checking data====================\n",
      "\n",
      "Data size: (50000, 370)\n",
      "\n",
      "Label ratio for unplanned_readmission\n",
      "False    0.85806\n",
      "True     0.14194\n",
      "Name: unplanned_readmission, dtype: float64\n",
      "\n",
      "Discharge_id duplicates: 0\n",
      "\n",
      "====================Removing bad word data====================\n",
      "\n",
      "Removing bad words: 1753 rows contain the word death\n",
      "Completed, read from vocab: ../../../data/readmission/fold_2/vocab/vocab_1000_vall_30days, \n",
      " wrote to ../../../data/readmission/fold_2/test/test_datalist_1000_vall_30days.pkl\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Processing fold 3\n",
      "****************************************************************************************************\n",
      "Read data from ../../../data/readmission/fold_3/test/raw_test_data.csv\n",
      "\n",
      "====================Checking data====================\n",
      "\n",
      "Data size: (50000, 370)\n",
      "\n",
      "Label ratio for unplanned_readmission\n",
      "False    0.85754\n",
      "True     0.14246\n",
      "Name: unplanned_readmission, dtype: float64\n",
      "\n",
      "Discharge_id duplicates: 0\n",
      "\n",
      "====================Removing bad word data====================\n",
      "\n",
      "Removing bad words: 1795 rows contain the word death\n",
      "Completed, read from vocab: ../../../data/readmission/fold_3/vocab/vocab_1000_vall_30days, \n",
      " wrote to ../../../data/readmission/fold_3/test/test_datalist_1000_vall_30days.pkl\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Processing fold 4\n",
      "****************************************************************************************************\n",
      "Read data from ../../../data/readmission/fold_4/test/raw_test_data.csv\n",
      "\n",
      "====================Checking data====================\n",
      "\n",
      "Data size: (50000, 370)\n",
      "\n",
      "Label ratio for unplanned_readmission\n",
      "False    0.85754\n",
      "True     0.14246\n",
      "Name: unplanned_readmission, dtype: float64\n",
      "\n",
      "Discharge_id duplicates: 0\n",
      "\n",
      "====================Removing bad word data====================\n",
      "\n",
      "Removing bad words: 1859 rows contain the word death\n",
      "Completed, read from vocab: ../../../data/readmission/fold_4/vocab/vocab_1000_vall_30days, \n",
      " wrote to ../../../data/readmission/fold_4/test/test_datalist_1000_vall_30days.pkl\n"
     ]
    }
   ],
   "source": [
    "for idx, (test_fp, test_dl_fp, vocab_fp) in enumerate(\n",
    "    zip(test_fps, test_dl_fps, vocab_fps)\n",
    "):\n",
    "    print(\"\\n\\n\" + \"*\" * 100)\n",
    "    print(f\"Processing fold {idx}\\n\" + \"*\" * 100)\n",
    "    create_flat_dataset(\n",
    "        data_fp=test_fp,\n",
    "        x_lst=x_lst,\n",
    "        x_flat_lst=x_flat_lst,\n",
    "        y_target=y_target,\n",
    "        uid=uid,\n",
    "        train=False,\n",
    "        vocab_fp=vocab_fp,\n",
    "        datalist_fp=train_dl_fp,\n",
    "        save_csv=True\n",
    "    )\n",
    "\n",
    "    print(f\"Completed, read from vocab: {vocab_fp}, \\n wrote to {test_dl_fp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
