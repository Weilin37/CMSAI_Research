{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating and Analyzing of XGBoost Trainined Models for Hospital Readmissions prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to analyze a trained xgboost models to predict hospital readmissions for given patients based on their historical data.\n",
    "Let's first start to import the packages needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import boto3\n",
    "\n",
    "import shap\n",
    "import tarfile\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "##User defined import\n",
    "from metrics import compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_model_from_s3(s3_model_path, local_model_dir):\n",
    "    \"\"\"Copy model from s3 to local\n",
    "    Args:\n",
    "        s3_model_path(str): S3 path where the model gz is saved\n",
    "    Returns:\n",
    "        Destination model path\n",
    "    \"\"\"\n",
    "    client = boto3.client('s3')\n",
    "    o = urlparse(s3_model_path)\n",
    "    bucket = o.netloc\n",
    "    key = o.path\n",
    "    key = key.lstrip('/')\n",
    "    if not os.path.exists(local_model_dir): \n",
    "        os.makedirs(local_model_dir) \n",
    "    fname = os.path.basename(s3_model_path) \n",
    "    output_path = os.path.join(local_model_dir, fname)\n",
    "    \n",
    "    client.download_file(bucket, key, output_path)\n",
    "    \n",
    "    return output_path\n",
    "   \n",
    "\n",
    "def load_model(gz_model_path): \n",
    "    \"\"\"\n",
    "    Loads xgboost trained model from disk\n",
    "    Args:\n",
    "        gz_model_path(str): Compressed Model path\n",
    "    Returns:\n",
    "        xgboost: Xgboost model object\n",
    "    \"\"\"\n",
    "    model_dir = os.path.dirname(gz_model_path)\n",
    "    model_path = os.path.join(model_dir, 'xgboost-model')\n",
    "\n",
    "    tar = tarfile.open(gz_model_path, \"r:gz\")\n",
    "    tar.extractall(model_dir)\n",
    "    tar.close()\n",
    "    \n",
    "    #Load Model\n",
    "    model = pickle.load(open(model_path, \"rb\"))\n",
    "    \n",
    "    #Remove the local copy of the model files\n",
    "    shutil.rmtree(model_dir)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_labels_scores(df_preds_labels, target_names=None):\n",
    "    \"\"\"Get labels and scores/predictions to compute model metrics\n",
    "    Args:\n",
    "        df_preds_labels(pd.DataFrame): Dataframe of predictions & true labels\n",
    "        target_names(list): List of target events\n",
    "    Returns:\n",
    "        Tuple of labels(np.array), scores(np.array) and Event names(list)\n",
    "    \"\"\"\n",
    "    labels = None\n",
    "    scores = None\n",
    "    if target_names is None:\n",
    "        cols = df_preds_labels.columns.tolist()\n",
    "        label_names = [col for col in cols if not col.endswith('_')]\n",
    "        label_names = [name for name in label_names if not name.endswith('probs')]\n",
    "        pred_names = [col for col in cols if col.endswith('probs')]\n",
    "    else:\n",
    "        label_names = target_names\n",
    "        pred_names = [name+'_probs' for name in target_names]\n",
    "    \n",
    "    labels = df_preds_labels[label_names].values\n",
    "    scores = df_preds_labels[pred_names].values\n",
    "\n",
    "    return labels, scores, label_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS = ['fold_'+str(i) for i in range(5)] + ['all']\n",
    "FOLD_INDX = 4\n",
    "CURRENT_FOLD = FOLDS[FOLD_INDX]\n",
    "SPLIT = 'val'\n",
    "NUM_FEATURES = 100\n",
    "PREPROCESSED_DATA_DIR = '/home/ec2-user/SageMaker/CMSAI/modeling/tes/data/final-global/re/1000/preprocessed/{}'.format(CURRENT_FOLD)\n",
    "DATA_PATH = os.path.join(PREPROCESSED_DATA_DIR, SPLIT+'.csv')\n",
    "\n",
    "TRAIN_DATA_DIR = '/home/ec2-user/SageMaker/CMSAI/modeling/tes/data/final-global/re/1000/training/'\n",
    "MODEL_DIR = '/home/ec2-user/SageMaker/CMSAI/modeling/tes/data/final-global/re/1000/model/'\n",
    "\n",
    "TRAIN_RESULTS_PATH = os.path.join(TRAIN_DATA_DIR, str(NUM_FEATURES), CURRENT_FOLD, 'train_results.csv')\n",
    "FINAL_RESULTS_DIR = os.path.join(TRAIN_DATA_DIR, str(NUM_FEATURES), CURRENT_FOLD, 'final_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will add all the values/paths needed to train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>num_features</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>best_model_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unplanned_readmission</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6379</td>\n",
       "      <td>s3://cmsai-mrk-amzn/FinalData/RE/Models/XGBoos...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   class  num_features  val_auc  \\\n",
       "0  unplanned_readmission           100   0.6379   \n",
       "\n",
       "                                     best_model_path  \n",
       "0  s3://cmsai-mrk-amzn/FinalData/RE/Models/XGBoos...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.read_csv(TRAIN_RESULTS_PATH)\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_vis = df_results.pivot(index='num_features', columns='class', values='val_auc')\n",
    "# df_vis.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>num_features</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>best_model_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unplanned_readmission</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6379</td>\n",
       "      <td>s3://cmsai-mrk-amzn/FinalData/RE/Models/XGBoos...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   class  num_features  val_auc  \\\n",
       "0  unplanned_readmission           100   0.6379   \n",
       "\n",
       "                                     best_model_path  \n",
       "0  s3://cmsai-mrk-amzn/FinalData/RE/Models/XGBoos...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get models having the best performance for each target variable\n",
    "idx = df_results.groupby('class')['val_auc'].transform(max) ==df_results['val_auc']\n",
    "df_best = df_results[idx]\n",
    "print(df_best.shape)\n",
    "df_best.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_models = [['d_5990', 100, 0.7, 's3://cmsai-mrk-amzn/CSVModelInputs/Tes/models/re/final/month-0/xgboost/2020-11-10-20-48-57/100/d_5990/output/sagemaker-xgboost-201110-2049-020-212dc74f/output/model.tar.gz'],\n",
    "#                ['d_78605', 100, 0.6, 's3://cmsai-mrk-amzn/CSVModelInputs/Tes/models/re/final/month-0/xgboost/2020-11-10-20-48-57/100/d_5990/output/sagemaker-xgboost-201110-2049-016-3e3ab8f4/output/model.tar.gz']]\n",
    "# columns = ['class', 'num_features', 'val_auc', 'best_model_path']\n",
    "# df_best = pd.DataFrame(best_models, columns=columns)\n",
    "# print(df_best.shape)\n",
    "# df_best.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(312836, 301)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h_99232</th>\n",
       "      <th>h_99233</th>\n",
       "      <th>h_71010</th>\n",
       "      <th>h_93010</th>\n",
       "      <th>h_99231</th>\n",
       "      <th>h_99223</th>\n",
       "      <th>h_A0425</th>\n",
       "      <th>h_99285</th>\n",
       "      <th>d_4280</th>\n",
       "      <th>d_4019</th>\n",
       "      <th>...</th>\n",
       "      <th>h_11721</th>\n",
       "      <th>d_71941</th>\n",
       "      <th>d_V0481</th>\n",
       "      <th>h_81003</th>\n",
       "      <th>d_5183</th>\n",
       "      <th>d_40390</th>\n",
       "      <th>h_76700</th>\n",
       "      <th>d_V7284</th>\n",
       "      <th>h_01402</th>\n",
       "      <th>unplanned_readmission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   h_99232  h_99233  h_71010  h_93010  h_99231  h_99223  h_A0425  h_99285  \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        1        1        1        1        0        1        1        1   \n",
       "2        1        0        0        0        0        0        0        0   \n",
       "3        1        0        0        1        0        0        0        0   \n",
       "4        0        0        0        0        0        1        0        1   \n",
       "\n",
       "   d_4280  d_4019  ...  h_11721  d_71941  d_V0481  h_81003  d_5183  d_40390  \\\n",
       "0       0       0  ...        0        0        0        0       0        0   \n",
       "1       0       0  ...        0        0        0        0       0        0   \n",
       "2       0       1  ...        1        0        0        0       0        0   \n",
       "3       0       1  ...        0        0        0        0       0        0   \n",
       "4       0       1  ...        0        0        0        0       0        0   \n",
       "\n",
       "   h_76700  d_V7284  h_01402  unplanned_readmission  \n",
       "0        0        0        0                      0  \n",
       "1        0        0        0                      0  \n",
       "2        0        0        1                      0  \n",
       "3        0        0        0                      0  \n",
       "4        0        0        0                      1  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv(DATA_PATH)\n",
    "print(df_data.shape)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_predictions(row, df_data, local_model_dir):\n",
    "    \"\"\"Process the predictions and performance for best model for each class.\n",
    "    df_data first column is labels and others are features\n",
    "    \"\"\"\n",
    "    best_model_path = row['best_model_path']\n",
    "    target = row['class']\n",
    "    num_features = row['num_features']\n",
    "    \n",
    "    #Copy the best model from s3 to local\n",
    "    output_path = copy_model_from_s3(best_model_path, local_model_dir)\n",
    "\n",
    "    #Load the copied model\n",
    "    model = load_model(output_path)\n",
    "    \n",
    "    preds = []\n",
    "    features = df_data.columns.tolist()[:num_features]\n",
    "    #Predict for data and save in pd Dataframe\n",
    "    probs = model.predict(xgb.DMatrix(df_data[features].values, df_data[target].values))\n",
    "    #probs = model.predict(xgb.DMatrix(df_data.iloc[:, :num_features], df_data[target].values, feature_names=feature_names))\n",
    "    preds.append(df_data[target].tolist())\n",
    "    preds.append((probs>=0.5).astype(int).tolist())\n",
    "    preds.append(probs.tolist())\n",
    "    \n",
    "    columns = [target, target+'_', target+'_probs']\n",
    "    return preds, columns\n",
    "\n",
    "\n",
    "def get_all_predictions(df_best_models, df_data, local_model_dir):\n",
    "    \"\"\"Get predictions from each of the best models of each target variable.\"\"\"\n",
    "    num_rows = df_best_models.shape[0]\n",
    "    all_columns = []\n",
    "    all_preds = []\n",
    "    for i in range(num_rows):\n",
    "        row = df_best_models.iloc[i, :]\n",
    "        preds, columns = get_model_predictions(row, df_data, local_model_dir)\n",
    "        all_preds += preds\n",
    "        all_columns += columns\n",
    "        \n",
    "    df_preds = pd.DataFrame(np.array(all_preds).T, columns=all_columns)\n",
    "    return df_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate for a sample model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_best.iloc[0, 0]\n",
    "# num_features = df_best.iloc[0,1]\n",
    "# best_model_path = df_best.iloc[0, 3]\n",
    "\n",
    "# #Copy the best model from s3 to local\n",
    "# output_path = copy_model_from_s3(best_model_path, MODEL_DIR)\n",
    "# #Load the copied model\n",
    "# model = load_model(output_path)\n",
    "# #model.feature_names\n",
    "\n",
    "# #Evaluate model on data\n",
    "# feature_names = df_data.columns.tolist()[:num_features]\n",
    "# auc = model.eval(xgb.DMatrix(df_data[feature_names].values, df_data[target].values))\n",
    "# print('AUC: - {}'.format(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = get_all_predictions(df_best, df_data, MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(312836, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unplanned_readmission</th>\n",
       "      <th>unplanned_readmission_</th>\n",
       "      <th>unplanned_readmission_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.352270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.564397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.314813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.404611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unplanned_readmission  unplanned_readmission_  unplanned_readmission_probs\n",
       "0                    0.0                     0.0                     0.352270\n",
       "1                    0.0                     1.0                     0.564397\n",
       "2                    0.0                     0.0                     0.300529\n",
       "3                    0.0                     0.0                     0.314813\n",
       "4                    1.0                     0.0                     0.404611"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_preds.shape)\n",
    "df_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_labels, np_scores, _ = get_labels_scores(df_preds)\n",
    "target_names = df_best['class'].tolist()\n",
    "df_metrics = compute_metrics(np_labels, np_scores, target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels Shape: (312836, 1), Scores Shape: (312836, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auroc</th>\n",
       "      <th>avgpr</th>\n",
       "      <th>precis_5%</th>\n",
       "      <th>recall_5%</th>\n",
       "      <th>precis_2%</th>\n",
       "      <th>recall_2%</th>\n",
       "      <th>precis_1%</th>\n",
       "      <th>recall_1%</th>\n",
       "      <th>precis_0.5%</th>\n",
       "      <th>recall_0.5%</th>\n",
       "      <th>precis_0.25%</th>\n",
       "      <th>recall_0.25%</th>\n",
       "      <th>calib_mean</th>\n",
       "      <th>calib_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>unplanned_readmission</th>\n",
       "      <td>0.637935</td>\n",
       "      <td>0.22417</td>\n",
       "      <td>0.282061</td>\n",
       "      <td>0.094245</td>\n",
       "      <td>0.302541</td>\n",
       "      <td>0.040437</td>\n",
       "      <td>0.331735</td>\n",
       "      <td>0.022173</td>\n",
       "      <td>0.344409</td>\n",
       "      <td>0.011514</td>\n",
       "      <td>0.342273</td>\n",
       "      <td>0.005725</td>\n",
       "      <td>0.324013</td>\n",
       "      <td>0.232542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          auroc    avgpr  precis_5%  recall_5%  precis_2%  \\\n",
       "unplanned_readmission  0.637935  0.22417   0.282061   0.094245   0.302541   \n",
       "\n",
       "                       recall_2%  precis_1%  recall_1%  precis_0.5%  \\\n",
       "unplanned_readmission   0.040437   0.331735   0.022173     0.344409   \n",
       "\n",
       "                       recall_0.5%  precis_0.25%  recall_0.25%  calib_mean  \\\n",
       "unplanned_readmission     0.011514      0.342273      0.005725    0.324013   \n",
       "\n",
       "                       calib_mse  \n",
       "unplanned_readmission   0.232542  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Labels Shape: {}, Scores Shape: {}'.format(np_labels.shape, np_scores.shape))\n",
    "df_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(df_metrics.mean()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mn = df_metrics.min()\n",
    "# mx = df_metrics.max()\n",
    "# avg = df_metrics.mean()\n",
    "\n",
    "# df_metrics.loc['Min'] = mn\n",
    "# df_metrics.loc['Max'] = mx\n",
    "# df_metrics.loc['Average'] = avg\n",
    "# df_metrics.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = df_data.columns.tolist()[:NUM_FEATURES]\n",
    "if not os.path.exists(FINAL_RESULTS_DIR):\n",
    "    os.makedirs(FINAL_RESULTS_DIR)\n",
    "    \n",
    "#Save the features used\n",
    "features_list_path = os.path.join(FINAL_RESULTS_DIR, 'features.txt')\n",
    "with open(features_list_path, 'w') as fp:\n",
    "    fp.write('\\n'.join(feature_names))\n",
    "\n",
    "#Save the final metrics results\n",
    "final_results_path = os.path.join(FINAL_RESULTS_DIR, SPLIT+'_metrics.csv')\n",
    "df_metrics.to_csv(final_results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainability and Visualization using SHAP (SHapley Additive exPlanations)\n",
    "\n",
    "*Source: https://github.com/slundberg/shap*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# load JS visualization code to notebook\n",
    "#shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing for fold0_val data...\n"
     ]
    }
   ],
   "source": [
    "print('Processing for {} data...'.format(SPLIT))\n",
    "feature_names = df_data.columns.tolist()[:NUM_FEATURES]\n",
    "X = df_data[feature_names]\n",
    "\n",
    "#Create a new shap dir if not available\n",
    "shap_dir = os.path.join(FINAL_RESULTS_DIR, 'shap_'+SPLIT)\n",
    "if not os.path.exists(shap_dir):\n",
    "    os.makedirs(shap_dir)\n",
    "    \n",
    "num_rows = df_best.shape[0]\n",
    "for i in range(num_rows):\n",
    "    target = df_best.iloc[i, 0]\n",
    "    num_features = df_best.iloc[i, 1]\n",
    "    best_model_path = df_best.iloc[i, 3]\n",
    "\n",
    "    y = df_data[target]\n",
    "\n",
    "    #Copy the best model from s3 to local\n",
    "    output_path = copy_model_from_s3(best_model_path, MODEL_DIR)\n",
    "    #Load the copied model\n",
    "    model = load_model(output_path)\n",
    "    \n",
    "    # explain the model's predictions using SHAP\n",
    "    # (same syntax works for LightGBM, CatBoost, scikit-learn and spark models)\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X)\n",
    "    \n",
    "    print('Computing SHAP Results for Target={}...'.format(target))\n",
    "    \n",
    "#     vis_path = os.path.join(shap_dir, target+'_shap_values.pkl')\n",
    "#     with open(vis_path, 'wb') as fp:\n",
    "#         pickle.dump(shap_values, fp)\n",
    "        \n",
    "    # visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)\n",
    "    vis_path = os.path.join(shap_dir, target+'_per_patient_shap.png')\n",
    "    shap.force_plot(explainer.expected_value, shap_values[0,:], X.iloc[0,:], matplotlib=True, show=False)\n",
    "    plt.savefig(vis_path, bbox_inches='tight')\n",
    "    plt.close(\"all\")\n",
    "    \n",
    "    # visualize the training set predictions\n",
    "    #shap.force_plot(explainer.expected_value, shap_values, X) ## Out-of-memory Error\n",
    "    \n",
    "    # create a dependence plot to show the effect of a single feature across the whole dataset\n",
    "    vis_path = os.path.join(shap_dir, target+'_per_feature_shap.png')\n",
    "    shap.dependence_plot(feature_names[0], shap_values, X, show=False)\n",
    "    plt.savefig(vis_path, bbox_inches='tight')\n",
    "    plt.close(\"all\")\n",
    "    \n",
    "    # summarize the effects of all the features\n",
    "    shap.summary_plot(shap_values, X, show=False)\n",
    "    vis_path = os.path.join(shap_dir, target+'_all_features_shap.png')\n",
    "    plt.savefig(vis_path, bbox_inches='tight')\n",
    "    plt.close(\"all\")\n",
    "    \n",
    "    #Compute the mean absolute value of the SHAP values for each feature to get a standard bar plot\n",
    "    shap.summary_plot(shap_values, X, plot_type=\"bar\", show=False)\n",
    "    vis_path = os.path.join(shap_dir, target+'_all_features_importance.png')\n",
    "    plt.savefig(vis_path, bbox_inches='tight')\n",
    "    plt.close(\"all\")\n",
    "    \n",
    "print('Shap Values and Visualizations Successfully Saved to {}!'.format(shap_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-python3",
   "language": "python",
   "name": "venv-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
