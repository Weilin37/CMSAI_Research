{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import torch \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import boto3\n",
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from torchvision import transforms\n",
    "import math\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(df, vocab, feat_colnames, label_colnames, day_length=90, max_length=30, max_sentence_length=500):\n",
    "    '''\n",
    "    Subsets the entire dataset into a dataset to be used later.\n",
    "    - Specific vocabulary\n",
    "    - By number of days (whole dataset is 365)\n",
    "    \n",
    "    Returns a list of data and attributes needed by Script 2: patientid_dischargeid key, sequence of events, targets, and \n",
    "    mask (identifying padded regions)\n",
    "    '''\n",
    "    start_time = time.time()\n",
    "    print(\"used days: \", feat_colnames[-day_length], feat_colnames[-1])\n",
    "    \n",
    "    data = df[feat_colnames[-day_length:]].to_numpy()\n",
    "    labels = df[label_colnames].to_numpy()\n",
    "    \n",
    "    count = 0\n",
    "    sequence = []\n",
    "    valid_id = []\n",
    "    pad_mask = []\n",
    "    dates = []\n",
    "    index_dates = []\n",
    "    \n",
    "    whole_dates = df['index_date'].to_numpy()\n",
    "    print(\"total size before: \", data.shape)\n",
    "    for i in range(len(data)):\n",
    "        sentence = []\n",
    "        mask = []\n",
    "        event_date = []\n",
    "        for j in range(len(data[i])-1, -1, -1):\n",
    "            words = str(data[i][j])\n",
    "            if words == 'nan':\n",
    "                continue\n",
    "            words = words.replace('d_s', 'd_').replace(' ', '').split(',')\n",
    "            words = sorted([vocab.stoi[w] if w in vocab.stoi else vocab.stoi['nan'] for w in words]) # training use \"unk\"\n",
    "            \n",
    "            if len(words) > max_length:\n",
    "                words = words[:max_length]\n",
    "            \n",
    "            sentence = words + sentence\n",
    "            \n",
    "            event_date = [day_length-j-1] * len(words) + event_date\n",
    "\n",
    "            if len(sentence) > max_sentence_length:\n",
    "                sentence = sentence[-max_sentence_length:]\n",
    "                event_date = event_date[-max_sentence_length:]\n",
    "                break\n",
    "                \n",
    "        if len(sentence) == 0:\n",
    "            if labels[i].any():\n",
    "                count += 1\n",
    "            continue\n",
    "            \n",
    "        valid_id.append(i)\n",
    "        pad_l = (max_sentence_length - len(sentence))\n",
    "        mask = [1] * len(sentence) + [0] * pad_l\n",
    "        event_date = event_date + [-1] * pad_l\n",
    "        sentence = sentence + [vocab.stoi['<pad>']] * pad_l\n",
    "        sequence.append(sentence)\n",
    "        pad_mask.append(mask)\n",
    "        dates.append(event_date)\n",
    "        index_dates.append(i)\n",
    "        \n",
    "        \n",
    "    finish_time = time.time()\n",
    "    \n",
    "    print('New dataset created')\n",
    "    print(\"sequence length: \", len(sequence))\n",
    "    print(\"empty events with nonzero labels: \", count)\n",
    "    \n",
    "    labels = labels[valid_id]\n",
    "    patient_ids = df['patient_id'].to_numpy()[valid_id]\n",
    "    pad_mask = np.array(pad_mask)\n",
    "    sequence = np.array(sequence)\n",
    "    print(\"time: \", finish_time - start_time)\n",
    "    \n",
    "    return [patient_ids, sequence, labels, pad_mask, np.array(dates), whole_dates[index_dates]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, num_classes, num_events=500, seq_length=120, dropout=0.5):\n",
    "        '''\n",
    "        Initialize a transformer model for adverse events. The model consists of the following:\n",
    "        - Transformer encoder layers\n",
    "        - Single 1D CNN layer\n",
    "        - Final fully connected layer to determine probability of readmissions\n",
    "        \n",
    "        Args:\n",
    "            \n",
    "            ntoken: number of tokens in embedding layer (vocabulary size)\n",
    "            ninp: embedding dimension (number of inputs)\n",
    "            \n",
    "            nhead: number of heads in transformers\n",
    "            nhid: number of transformer linear dimensions\n",
    "            \n",
    "            nlayers: number of layers in transfromer\n",
    "            \n",
    "            num_classes: number of classes to predict (in this case, binary)\n",
    "            \n",
    "            seq_length: dimension of linear layer output\n",
    "            num_events: maximum number of events per patient\n",
    "            \n",
    "            dropout: strength of regularization\n",
    "        '''\n",
    "        super(TransformerModel, self).__init__()\n",
    "        from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "        self.model_type = 'Transformer'\n",
    "        print(\"parameters: embsize:{}, nhead:{}, nhid:{}, nlayers:{}, dropout:{}\".format(ninp, nhead, nhid, nlayers, dropout))\n",
    "        \n",
    "        # Inputs into transformer: mask for padding and embeddings\n",
    "        self.src_mask = None\n",
    "        self.event_emb = nn.Embedding(ntoken, ninp)\n",
    "        \n",
    "        # Transformer layer\n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        \n",
    "         # CNN & fully connected layers\n",
    "        \n",
    "        self.ff = nn.Linear(int(num_events), int(seq_length))\n",
    "        self.fc = nn.Linear(int(seq_length), num_classes)\n",
    "        self.nonlinear = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(-1)\n",
    "        self.Conv1d = nn.Conv1d(ninp, 1, 1, stride=1)\n",
    "        \n",
    "        # record\n",
    "        self.ninp = ninp\n",
    "        self.dropout = dropout\n",
    "        self.num_events= num_events\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # initalize weights\n",
    "        self.init_weights()\n",
    "    \n",
    "\n",
    "    def init_weights(self):\n",
    "        '''Initialize weights in embedding and fully connected layers'''\n",
    "        initrange = 0.1\n",
    "        self.event_emb.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "        self.fc.bias.data.zero_()\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "        self.ff.bias.data.zero_()\n",
    "        self.ff.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "        \n",
    "    def forward(self, src, mask=None, pos=None): \n",
    "        '''\n",
    "        Forward propagation steps:\n",
    "        - convert events into embedding vectors & positional encoding\n",
    "        - transformer encoder layers\n",
    "        - CNN layer\n",
    "        - final \n",
    "        Notes:\n",
    "        no position encoding here, no obvious clues for sequential or order found \n",
    "        '''        \n",
    "        if mask is not None:\n",
    "            #src_key_padding_mask needs boolean mask\n",
    "            src_mask = (mask == 0)\n",
    "\n",
    "        src = self.event_emb(src).transpose(0,1) * math.sqrt(self.ninp)\n",
    "        \n",
    "        trans_output = self.transformer_encoder(src, src_key_padding_mask=src_mask).transpose(0, 1).transpose(1,2)\n",
    "        final_feature_map = self.Conv1d(trans_output).squeeze()\n",
    "        \n",
    "        out_mask = mask.float().masked_fill(mask == 0.0, float(-100.0)).masked_fill(mask == 1.0, float(0.0)).view(mask.size()[0], -1)\n",
    "        # extract normalized feature importances per prediction\n",
    "        importance_out = self.softmax(final_feature_map+out_mask)\n",
    "        \n",
    "        output = self.ff(final_feature_map)\n",
    "        output = self.nonlinear(output)\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output, importance_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildDataset(Dataset):\n",
    "    '''\n",
    "    Read in dataset, if data is already split into train, test, and/or validation sets.\n",
    "    \n",
    "    ProcessData: extract input, labels, mask from an existing Python object (via pickle or otherwise)\n",
    "    '''\n",
    "    def __init__(self, data_file, event_length=500, data_list=None, mode='read'): \n",
    "        if mode != 'read' and data_list != None:\n",
    "            self.data, self.label, self.mask = self.ProcessData(data_list, event_length)\n",
    "            \n",
    "    def ProcessData(self, data_list, event_length):\n",
    "        input_data, labels, mask = data_list[0][:,-event_length:], data_list[1], data_list[2][:,-event_length:]\n",
    "        return input_data, labels, mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        return torch.tensor(self.data[idx]), torch.tensor(self.label[idx]), torch.tensor(self.mask[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from the saved pickle file, the order is [patietn_id, input_data, labels, mask_for_padding, position(no used here)]\n",
    "def ReadData(file_dir, event_length):\n",
    "    with open(file_dir, 'rb') as f:\n",
    "        ids, data, label, mask = pickle.load(f)\n",
    "        ids = ids.astype(str)\n",
    "        cut_data = data[:,-event_length:]\n",
    "        cut_mask = mask[:,-event_length:]\n",
    "        label = label.astype(int)\n",
    "    return ids, cut_data, label, cut_mask#, cut_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EopochVal(model, dataloader, device=\"cuda\", metric='auc'):\n",
    "    '''\n",
    "    Evaluate model performance, called by ModelProcess function\n",
    "    \n",
    "    Returns predictions, metrics and importance scores\n",
    "    '''\n",
    "    epoch_loss = 0\n",
    "    epoch_metric = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    order_labels = None\n",
    "    prediction_scores = None\n",
    "    events = None\n",
    "    important_scores = None\n",
    "    \n",
    "    for idx, [seq, labels, mask] in enumerate(dataloader):\n",
    "        with torch.no_grad():\n",
    "            labels = labels.squeeze().float()\n",
    "            seq, labels, mask = seq.cuda(), labels.cuda(), mask.cuda()\n",
    "            predictions, importance = model(seq, mask=mask)\n",
    "\n",
    "            loss = criterion(predictions, labels)\n",
    "\n",
    "            if order_labels is None:\n",
    "                order_labels = labels.cpu().numpy()\n",
    "                prediction_scores = torch.sigmoid(predictions).detach().cpu().numpy()\n",
    "                events = seq.cpu().numpy()\n",
    "                important_scores = importance.detach().cpu().numpy()\n",
    "            else:\n",
    "                order_labels = np.concatenate((order_labels, labels.cpu().numpy()))\n",
    "                prediction_scores =np.concatenate((prediction_scores, torch.sigmoid(predictions).detach().cpu().numpy()))\n",
    "                events = np.concatenate((events, seq.cpu().numpy()))\n",
    "                important_scores = np.concatenate((important_scores, importance.detach().cpu().numpy()))\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        del predictions\n",
    "        del importance\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    if metric == 'acc':\n",
    "        epoch_metric = get_average_accuracy(prediction_scores, order_labels)\n",
    "    elif metric == 'auc':\n",
    "        epoch_metric = roc_auc_score(order_labels, prediction_scores)\n",
    "        \n",
    "    return epoch_loss / len(dataloader), epoch_metric, [order_labels, events, important_scores, prediction_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestProcess(model, dataloaders):\n",
    "\n",
    "        \n",
    "    if torch.cuda.is_available():\n",
    "        device=\"cuda\"\n",
    "    else:\n",
    "        device=\"cpu\"\n",
    "    \n",
    "    print(\"device: \", device)\n",
    "    \n",
    "    #optimizer = optim.AdamW(model.parameters())\n",
    "\n",
    "    final_test_metric = 0.0\n",
    "\n",
    "    epoch_test_loss, epoch_test_metric, importance_results = EopochVal(model, dataloaders, device=\"cuda\", metric='auc')\n",
    "    #test_loss.append(epoch_test_loss)\n",
    "    print('epoch_test_loss:', np.mean(epoch_test_loss), 'epoch_test_metric:', np.mean(epoch_test_metric))\n",
    "\n",
    "    final_test_metric = epoch_test_metric\n",
    "    final_importance_results = importance_results\n",
    "    #torch.save(model.module.state_dict(), './model_weights/month-{}_emsize-{}_head-{}_layers-{}_valauc-{}.pth'.format(month, emsize, nhead, nlayers, np.round(epoch_val_metric, decimals=3)))\n",
    "        #scheduler.step()\n",
    "        \n",
    "    return final_test_metric, final_importance_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! aws s3 cp s3://cmsai-mrk-amzn/pretest\\ phase/pretest\\ input\\ files\\ to\\ model/ae_patients_365_20120601.csv pretest_ae_patients_365_20120601.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (3,4,5,10,11,12,17,18,19,24,25,26,32,33,34,37,38,39,40,45,46,47,53,54,59,60,61,66,67,68,73,74,75,80,81,82,85,86,87,88,89,92,94,95,96,97,100,101,102,103,108,109,110,115,116,117,121,122,123,124,129,130,131,136,137,138,143,144,145,150,151,152,157,158,159,164,165,166,171,172,173,177,178,179,180,185,186,187,192,193,194,195,199,200,201,203,205,206,207,208,209,210,213,214,215,216,217,219,220,221,222,227,228,229,232,234,235,236,241,242,243,248,249,250,254,255,256,257,262,263,264,269,270,271,276,277,278,283,284,285,290,291,292,294,297,298,299,304,305,306,308,311,312,313,318,319,320,325,326,327,332,333,334,339,340,341,346,347,348,353,354,355,358,360,361,362,363,367) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "FP = './data/ae_data.csv'\n",
    "ae_targets_365_df = pd.read_csv(FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_date</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>365</th>\n",
       "      <th>364</th>\n",
       "      <th>363</th>\n",
       "      <th>362</th>\n",
       "      <th>361</th>\n",
       "      <th>360</th>\n",
       "      <th>359</th>\n",
       "      <th>358</th>\n",
       "      <th>...</th>\n",
       "      <th>d_78791</th>\n",
       "      <th>d_6826</th>\n",
       "      <th>d_78659</th>\n",
       "      <th>d_78907</th>\n",
       "      <th>d_7840</th>\n",
       "      <th>d_28860</th>\n",
       "      <th>d_4660</th>\n",
       "      <th>d_6829</th>\n",
       "      <th>d_00845</th>\n",
       "      <th>index_date.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20120601</td>\n",
       "      <td>100000099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20120601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20120601</td>\n",
       "      <td>100000315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d_4241, d_4241, d_42832, d_7852, h_99214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20120601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20120601</td>\n",
       "      <td>100000379</td>\n",
       "      <td>d_V5861, d_V5861, h_85610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20120601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20120601</td>\n",
       "      <td>100000437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20120601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20120601</td>\n",
       "      <td>100000559</td>\n",
       "      <td>d_V5861, d_V5861, h_85610, h_90999, h_A4657, h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>h_90999, h_J2501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>h_90999, h_J2501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d_5856, d_5856, d_V5861, d_V5861, d_V5869, d_V...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20120601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 389 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index_date  patient_id                                                365  \\\n",
       "0    20120601   100000099                                                NaN   \n",
       "1    20120601   100000315                                                NaN   \n",
       "2    20120601   100000379                          d_V5861, d_V5861, h_85610   \n",
       "3    20120601   100000437                                                NaN   \n",
       "4    20120601   100000559  d_V5861, d_V5861, h_85610, h_90999, h_A4657, h...   \n",
       "\n",
       "   364               363  362  361               360  \\\n",
       "0  NaN               NaN  NaN  NaN               NaN   \n",
       "1  NaN               NaN  NaN  NaN               NaN   \n",
       "2  NaN               NaN  NaN  NaN               NaN   \n",
       "3  NaN               NaN  NaN  NaN               NaN   \n",
       "4  NaN  h_90999, h_J2501  NaN  NaN  h_90999, h_J2501   \n",
       "\n",
       "                                        359  \\\n",
       "0                                       NaN   \n",
       "1  d_4241, d_4241, d_42832, d_7852, h_99214   \n",
       "2                                       NaN   \n",
       "3                                       NaN   \n",
       "4                                       NaN   \n",
       "\n",
       "                                                 358  ... d_78791 d_6826  \\\n",
       "0                                                NaN  ...       0      0   \n",
       "1                                                NaN  ...       0      0   \n",
       "2                                                NaN  ...       0      0   \n",
       "3                                                NaN  ...       0      0   \n",
       "4  d_5856, d_5856, d_V5861, d_V5861, d_V5869, d_V...  ...       0      0   \n",
       "\n",
       "  d_78659 d_78907 d_7840 d_28860 d_4660 d_6829 d_00845 index_date.1  \n",
       "0       0       0      0       0      0      0       0     20120601  \n",
       "1       0       0      0       0      0      0       0     20120601  \n",
       "2       0       0      0       0      0      0       0     20120601  \n",
       "3       0       0      0       0      0      0       0     20120601  \n",
       "4       0       0      0       0      0      0       0     20120601  \n",
       "\n",
       "[5 rows x 389 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_targets_365_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "863\n",
      "(5378701, 389)\n"
     ]
    }
   ],
   "source": [
    "# remove death\n",
    "indeces = set()\n",
    "x_lst = [str(x) for x in range(365,-1,-1)]\n",
    "y_lst = ['d_5990', 'd_78605', 'd_486', 'd_78650', 'd_78079', 'd_78900', 'd_78609', 'd_7862', 'd_1101',\n",
    "         'd_78701', 'd_5789', 'd_78791', 'd_6826', 'd_78659', 'd_78907',\n",
    "         'd_7840', 'd_28860', 'd_4660', 'd_6829', 'd_00845']\n",
    "for i in x_lst:\n",
    "    indeces.update(ae_targets_365_df[ae_targets_365_df[i].str.contains('death', na=False)].index)\n",
    "print(len(indeces)) #55568\n",
    "ae_targets_365_nd_df = ae_targets_365_df[~ae_targets_365_df.index.isin(indeces)]\n",
    "print(ae_targets_365_nd_df.shape) #(1563578, 370)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5378701, 389)\n"
     ]
    }
   ],
   "source": [
    "print(ae_targets_365_nd_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used days:  119 0\n",
      "total size before:  (5378701, 120)\n",
      "New dataset created\n",
      "sequence length:  4484933\n",
      "empty events with nonzero labels:  27681\n",
      "time:  1036.592157125473\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocab = torch.load('data/ae_pos_vocab_last90_whole_non3')\n",
    "\n",
    "# Define the columns \n",
    "x_lst = [str(x) for x in range(365,-1,-1)]\n",
    "y_lst = ['d_5990', 'd_78605', 'd_486', 'd_78650', 'd_78079', 'd_78900', 'd_78609', 'd_7862', 'd_1101',\n",
    "         'd_78701', 'd_5789', 'd_78791', 'd_6826', 'd_78659', 'd_78907',\n",
    "         'd_7840', 'd_28860', 'd_4660', 'd_6829', 'd_00845']\n",
    "\n",
    "whole_ids, whole_data, whole_labels, whole_mask, whole_dates, index_dates = build_dataset(ae_targets_365_nd_df, vocab, x_lst, y_lst, day_length=120, max_length=30, max_sentence_length=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = 30000\n",
    "test_dataset = BuildDataset('', event_length=500, data_list=[whole_data, whole_labels, whole_mask], mode='load')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: embsize:16, nhead:1, nhid:32, nlayers:1, dropout:0.5\n",
      "device:  cuda\n",
      "epoch_test_loss: 0.051057802826787034 epoch_test_metric: 0.747287918203524\n"
     ]
    }
   ],
   "source": [
    "vocab = torch.load('data/ae_pos_vocab_last90_whole_non3')\n",
    "ntokens = len(vocab.stoi) # the size of vocabulary\n",
    "emsize = 16 # embedding dimension\n",
    "nhid = 32 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 1 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 1 # the number of heads in the multiheadattention models\n",
    "dropout = 0.1 # the dropout value\n",
    "n_class = 20\n",
    "\n",
    "test_metrics = []\n",
    "results = []\n",
    "\n",
    "\n",
    "#criterion to use\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=None).cuda()\n",
    "model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, n_class, num_events=500, seq_length=120, dropout=0.5)\n",
    "model.load_state_dict(torch.load('model_weights/month-11_emsize-16_head-1_layers-1_valauc-0.783.pth'))\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "if torch.cuda.device_count()>1:\n",
    "    model = nn.DataParallel(model)\n",
    "test_metric, final_importance_results = TestProcess(model, test_dataloader)\n",
    "\n",
    "final_importance_results.insert(0, whole_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, scores = np.array(final_importance_results[1]), np.array(final_importance_results[-1])\n",
    "import metrics\n",
    "df = metrics.compute_metrics(labels, scores, target_names=None, risk_list=[0.5, 1, 2, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auroc</th>\n",
       "      <th>avgpr</th>\n",
       "      <th>precis_0.5%</th>\n",
       "      <th>recall_0.5%</th>\n",
       "      <th>precis_1%</th>\n",
       "      <th>recall_1%</th>\n",
       "      <th>precis_2%</th>\n",
       "      <th>recall_2%</th>\n",
       "      <th>precis_5%</th>\n",
       "      <th>recall_5%</th>\n",
       "      <th>calib_mean</th>\n",
       "      <th>calib_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.776551</td>\n",
       "      <td>0.121993</td>\n",
       "      <td>0.273311</td>\n",
       "      <td>0.060749</td>\n",
       "      <td>0.247871</td>\n",
       "      <td>0.110188</td>\n",
       "      <td>0.212689</td>\n",
       "      <td>0.189095</td>\n",
       "      <td>0.154299</td>\n",
       "      <td>0.342954</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.020749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.777013</td>\n",
       "      <td>0.099980</td>\n",
       "      <td>0.212620</td>\n",
       "      <td>0.048107</td>\n",
       "      <td>0.187291</td>\n",
       "      <td>0.084753</td>\n",
       "      <td>0.166524</td>\n",
       "      <td>0.150708</td>\n",
       "      <td>0.132292</td>\n",
       "      <td>0.299318</td>\n",
       "      <td>-0.000453</td>\n",
       "      <td>0.020941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.828892</td>\n",
       "      <td>0.125873</td>\n",
       "      <td>0.266622</td>\n",
       "      <td>0.140296</td>\n",
       "      <td>0.211349</td>\n",
       "      <td>0.222423</td>\n",
       "      <td>0.152298</td>\n",
       "      <td>0.320553</td>\n",
       "      <td>0.088309</td>\n",
       "      <td>0.464674</td>\n",
       "      <td>0.004095</td>\n",
       "      <td>0.009494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.695966</td>\n",
       "      <td>0.048408</td>\n",
       "      <td>0.095429</td>\n",
       "      <td>0.023995</td>\n",
       "      <td>0.092887</td>\n",
       "      <td>0.046711</td>\n",
       "      <td>0.085620</td>\n",
       "      <td>0.086112</td>\n",
       "      <td>0.070003</td>\n",
       "      <td>0.176014</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.019167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.695997</td>\n",
       "      <td>0.058119</td>\n",
       "      <td>0.109610</td>\n",
       "      <td>0.022690</td>\n",
       "      <td>0.104125</td>\n",
       "      <td>0.043109</td>\n",
       "      <td>0.096880</td>\n",
       "      <td>0.080218</td>\n",
       "      <td>0.084148</td>\n",
       "      <td>0.174190</td>\n",
       "      <td>-0.008426</td>\n",
       "      <td>0.023129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.705206</td>\n",
       "      <td>0.031312</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.026347</td>\n",
       "      <td>0.060803</td>\n",
       "      <td>0.048060</td>\n",
       "      <td>0.053568</td>\n",
       "      <td>0.084682</td>\n",
       "      <td>0.043077</td>\n",
       "      <td>0.170244</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.012367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.780299</td>\n",
       "      <td>0.058858</td>\n",
       "      <td>0.124147</td>\n",
       "      <td>0.052413</td>\n",
       "      <td>0.111126</td>\n",
       "      <td>0.093831</td>\n",
       "      <td>0.097615</td>\n",
       "      <td>0.164844</td>\n",
       "      <td>0.076037</td>\n",
       "      <td>0.321008</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.011563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.688497</td>\n",
       "      <td>0.036191</td>\n",
       "      <td>0.072464</td>\n",
       "      <td>0.023162</td>\n",
       "      <td>0.066421</td>\n",
       "      <td>0.042462</td>\n",
       "      <td>0.059822</td>\n",
       "      <td>0.076486</td>\n",
       "      <td>0.050926</td>\n",
       "      <td>0.162778</td>\n",
       "      <td>-0.004855</td>\n",
       "      <td>0.015203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.887042</td>\n",
       "      <td>0.228406</td>\n",
       "      <td>0.312553</td>\n",
       "      <td>0.054779</td>\n",
       "      <td>0.308227</td>\n",
       "      <td>0.108042</td>\n",
       "      <td>0.294975</td>\n",
       "      <td>0.206792</td>\n",
       "      <td>0.262817</td>\n",
       "      <td>0.460617</td>\n",
       "      <td>-0.000854</td>\n",
       "      <td>0.023394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.757729</td>\n",
       "      <td>0.028236</td>\n",
       "      <td>0.074961</td>\n",
       "      <td>0.077199</td>\n",
       "      <td>0.053155</td>\n",
       "      <td>0.109483</td>\n",
       "      <td>0.039320</td>\n",
       "      <td>0.161975</td>\n",
       "      <td>0.027983</td>\n",
       "      <td>0.288175</td>\n",
       "      <td>-0.000501</td>\n",
       "      <td>0.004939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.769862</td>\n",
       "      <td>0.012610</td>\n",
       "      <td>0.027560</td>\n",
       "      <td>0.052947</td>\n",
       "      <td>0.025552</td>\n",
       "      <td>0.098184</td>\n",
       "      <td>0.021817</td>\n",
       "      <td>0.167666</td>\n",
       "      <td>0.016036</td>\n",
       "      <td>0.308088</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.002589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.710751</td>\n",
       "      <td>0.016235</td>\n",
       "      <td>0.039911</td>\n",
       "      <td>0.033345</td>\n",
       "      <td>0.034983</td>\n",
       "      <td>0.058455</td>\n",
       "      <td>0.028964</td>\n",
       "      <td>0.096792</td>\n",
       "      <td>0.021864</td>\n",
       "      <td>0.182668</td>\n",
       "      <td>-0.001776</td>\n",
       "      <td>0.005902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.771690</td>\n",
       "      <td>0.012242</td>\n",
       "      <td>0.026087</td>\n",
       "      <td>0.046909</td>\n",
       "      <td>0.023880</td>\n",
       "      <td>0.085879</td>\n",
       "      <td>0.020959</td>\n",
       "      <td>0.150750</td>\n",
       "      <td>0.016246</td>\n",
       "      <td>0.292118</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.002759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.687207</td>\n",
       "      <td>0.012659</td>\n",
       "      <td>0.026533</td>\n",
       "      <td>0.025077</td>\n",
       "      <td>0.026176</td>\n",
       "      <td>0.049479</td>\n",
       "      <td>0.022654</td>\n",
       "      <td>0.085641</td>\n",
       "      <td>0.018185</td>\n",
       "      <td>0.171872</td>\n",
       "      <td>-0.000803</td>\n",
       "      <td>0.005227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.717166</td>\n",
       "      <td>0.008307</td>\n",
       "      <td>0.017436</td>\n",
       "      <td>0.027289</td>\n",
       "      <td>0.015139</td>\n",
       "      <td>0.047390</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.083194</td>\n",
       "      <td>0.010818</td>\n",
       "      <td>0.169319</td>\n",
       "      <td>-0.000081</td>\n",
       "      <td>0.003170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.689320</td>\n",
       "      <td>0.018084</td>\n",
       "      <td>0.035808</td>\n",
       "      <td>0.022520</td>\n",
       "      <td>0.032263</td>\n",
       "      <td>0.040581</td>\n",
       "      <td>0.029978</td>\n",
       "      <td>0.075413</td>\n",
       "      <td>0.025459</td>\n",
       "      <td>0.160109</td>\n",
       "      <td>-0.001972</td>\n",
       "      <td>0.007837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.761062</td>\n",
       "      <td>0.011131</td>\n",
       "      <td>0.028941</td>\n",
       "      <td>0.069568</td>\n",
       "      <td>0.023501</td>\n",
       "      <td>0.112981</td>\n",
       "      <td>0.018874</td>\n",
       "      <td>0.181477</td>\n",
       "      <td>0.012723</td>\n",
       "      <td>0.305821</td>\n",
       "      <td>-0.000880</td>\n",
       "      <td>0.002066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.638901</td>\n",
       "      <td>0.014379</td>\n",
       "      <td>0.016232</td>\n",
       "      <td>0.009496</td>\n",
       "      <td>0.016433</td>\n",
       "      <td>0.019226</td>\n",
       "      <td>0.017347</td>\n",
       "      <td>0.040592</td>\n",
       "      <td>0.018551</td>\n",
       "      <td>0.108523</td>\n",
       "      <td>-0.002212</td>\n",
       "      <td>0.008417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.716872</td>\n",
       "      <td>0.008375</td>\n",
       "      <td>0.018328</td>\n",
       "      <td>0.035101</td>\n",
       "      <td>0.016878</td>\n",
       "      <td>0.064651</td>\n",
       "      <td>0.015407</td>\n",
       "      <td>0.118029</td>\n",
       "      <td>0.012009</td>\n",
       "      <td>0.229994</td>\n",
       "      <td>-0.000209</td>\n",
       "      <td>0.002594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.889735</td>\n",
       "      <td>0.023921</td>\n",
       "      <td>0.041159</td>\n",
       "      <td>0.222785</td>\n",
       "      <td>0.029788</td>\n",
       "      <td>0.322472</td>\n",
       "      <td>0.020903</td>\n",
       "      <td>0.452571</td>\n",
       "      <td>0.011354</td>\n",
       "      <td>0.614531</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       auroc     avgpr  precis_0.5%  recall_0.5%  precis_1%  recall_1%  \\\n",
       "0   0.776551  0.121993     0.273311     0.060749   0.247871   0.110188   \n",
       "1   0.777013  0.099980     0.212620     0.048107   0.187291   0.084753   \n",
       "2   0.828892  0.125873     0.266622     0.140296   0.211349   0.222423   \n",
       "3   0.695966  0.048408     0.095429     0.023995   0.092887   0.046711   \n",
       "4   0.695997  0.058119     0.109610     0.022690   0.104125   0.043109   \n",
       "5   0.705206  0.031312     0.066667     0.026347   0.060803   0.048060   \n",
       "6   0.780299  0.058858     0.124147     0.052413   0.111126   0.093831   \n",
       "7   0.688497  0.036191     0.072464     0.023162   0.066421   0.042462   \n",
       "8   0.887042  0.228406     0.312553     0.054779   0.308227   0.108042   \n",
       "9   0.757729  0.028236     0.074961     0.077199   0.053155   0.109483   \n",
       "10  0.769862  0.012610     0.027560     0.052947   0.025552   0.098184   \n",
       "11  0.710751  0.016235     0.039911     0.033345   0.034983   0.058455   \n",
       "12  0.771690  0.012242     0.026087     0.046909   0.023880   0.085879   \n",
       "13  0.687207  0.012659     0.026533     0.025077   0.026176   0.049479   \n",
       "14  0.717166  0.008307     0.017436     0.027289   0.015139   0.047390   \n",
       "15  0.689320  0.018084     0.035808     0.022520   0.032263   0.040581   \n",
       "16  0.761062  0.011131     0.028941     0.069568   0.023501   0.112981   \n",
       "17  0.638901  0.014379     0.016232     0.009496   0.016433   0.019226   \n",
       "18  0.716872  0.008375     0.018328     0.035101   0.016878   0.064651   \n",
       "19  0.889735  0.023921     0.041159     0.222785   0.029788   0.322472   \n",
       "\n",
       "    precis_2%  recall_2%  precis_5%  recall_5%  calib_mean  calib_mse  \n",
       "0    0.212689   0.189095   0.154299   0.342954    0.000563   0.020749  \n",
       "1    0.166524   0.150708   0.132292   0.299318   -0.000453   0.020941  \n",
       "2    0.152298   0.320553   0.088309   0.464674    0.004095   0.009494  \n",
       "3    0.085620   0.086112   0.070003   0.176014    0.000198   0.019167  \n",
       "4    0.096880   0.080218   0.084148   0.174190   -0.008426   0.023129  \n",
       "5    0.053568   0.084682   0.043077   0.170244    0.000876   0.012367  \n",
       "6    0.097615   0.164844   0.076037   0.321008    0.000014   0.011563  \n",
       "7    0.059822   0.076486   0.050926   0.162778   -0.004855   0.015203  \n",
       "8    0.294975   0.206792   0.262817   0.460617   -0.000854   0.023394  \n",
       "9    0.039320   0.161975   0.027983   0.288175   -0.000501   0.004939  \n",
       "10   0.021817   0.167666   0.016036   0.308088    0.000572   0.002589  \n",
       "11   0.028964   0.096792   0.021864   0.182668   -0.001776   0.005902  \n",
       "12   0.020959   0.150750   0.016246   0.292118    0.000539   0.002759  \n",
       "13   0.022654   0.085641   0.018185   0.171872   -0.000803   0.005227  \n",
       "14   0.013289   0.083194   0.010818   0.169319   -0.000081   0.003170  \n",
       "15   0.029978   0.075413   0.025459   0.160109   -0.001972   0.007837  \n",
       "16   0.018874   0.181477   0.012723   0.305821   -0.000880   0.002066  \n",
       "17   0.017347   0.040592   0.018551   0.108523   -0.002212   0.008417  \n",
       "18   0.015407   0.118029   0.012009   0.229994   -0.000209   0.002594  \n",
       "19   0.020903   0.452571   0.011354   0.614531    0.000490   0.000937  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_feat(events, importance_score, dates, vocab, top=10):\n",
    "    \n",
    "    indices = np.argsort(importance_score)[:,::-1][:,:top]\n",
    "    i = np.arange(indices.shape[0]).reshape(indices.shape[0],1)\n",
    "    top_scores = importance_score[i, indices]\n",
    "    #print(top_scores.shape)\n",
    "    top_scores = np.exp(top_scores)/np.sum(np.exp(top_scores), axis=1, keepdims=True)\n",
    "    #print(np.sum(np.exp(top_scores), axis=1, keepdims=True).shape)\n",
    "    top_events = events[i, indices]\n",
    "    top_dates = dates[i, indices]\n",
    "    f = lambda x: vocab.itos[x]\n",
    "    vfunc = np.vectorize(f)\n",
    "    top_names = vfunc(top_events) \n",
    "    output = np.dstack((top_names, top_scores, top_dates))\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(final_importance_results, target_names, top=10):\n",
    "    patient_id, labels, events, importance_score, probability_score = final_importance_results\n",
    "    probs_df = pd.DataFrame()\n",
    "    probs_df['patient_id'] = patient_id\n",
    "    for i in range(20):\n",
    "        probs_df[target_names[i]] = labels[:, i]\n",
    "        probs_df[target_names[i] + '_Probs'] = probability_score[:, i]\n",
    "    event_score = get_top_feat(events, importance_score, whole_dates, vocab, top=10)\n",
    "    for i in range(top):\n",
    "        probs_df['event_' + str(i+1)] = event_score[:, i, 0]\n",
    "        probs_df['score_' + str(i+1)] = event_score[:, i, 1]\n",
    "        probs_df['dates_' + str(i+1)] = event_score[:, i, 2]\n",
    "    return probs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = create_df(final_importance_results, y_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>d_5990</th>\n",
       "      <th>d_5990_Probs</th>\n",
       "      <th>d_78605</th>\n",
       "      <th>d_78605_Probs</th>\n",
       "      <th>d_486</th>\n",
       "      <th>d_486_Probs</th>\n",
       "      <th>d_78650</th>\n",
       "      <th>d_78650_Probs</th>\n",
       "      <th>d_78079</th>\n",
       "      <th>...</th>\n",
       "      <th>dates_7</th>\n",
       "      <th>event_8</th>\n",
       "      <th>score_8</th>\n",
       "      <th>dates_8</th>\n",
       "      <th>event_9</th>\n",
       "      <th>score_9</th>\n",
       "      <th>dates_9</th>\n",
       "      <th>event_10</th>\n",
       "      <th>score_10</th>\n",
       "      <th>dates_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>d_17362</td>\n",
       "      <td>0.09835929</td>\n",
       "      <td>15</td>\n",
       "      <td>d_17362</td>\n",
       "      <td>0.09835929</td>\n",
       "      <td>15</td>\n",
       "      <td>d_17362</td>\n",
       "      <td>0.09835929</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100000315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018253</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>h_93280</td>\n",
       "      <td>0.099985495</td>\n",
       "      <td>22</td>\n",
       "      <td>d_5950</td>\n",
       "      <td>0.099975646</td>\n",
       "      <td>114</td>\n",
       "      <td>d_5950</td>\n",
       "      <td>0.099975646</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100000379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029747</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>d_1744</td>\n",
       "      <td>0.09993821</td>\n",
       "      <td>56</td>\n",
       "      <td>d_1744</td>\n",
       "      <td>0.09993821</td>\n",
       "      <td>56</td>\n",
       "      <td>h_4177F</td>\n",
       "      <td>0.099926025</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100000437</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>d_V5419</td>\n",
       "      <td>0.09997104</td>\n",
       "      <td>21</td>\n",
       "      <td>d_V5419</td>\n",
       "      <td>0.09997104</td>\n",
       "      <td>21</td>\n",
       "      <td>d_V5419</td>\n",
       "      <td>0.09997104</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100000559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>h_A0428</td>\n",
       "      <td>0.099961355</td>\n",
       "      <td>10</td>\n",
       "      <td>h_A0428</td>\n",
       "      <td>0.099961355</td>\n",
       "      <td>36</td>\n",
       "      <td>h_A0428</td>\n",
       "      <td>0.099961355</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100000905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>d_72210</td>\n",
       "      <td>0.0999083</td>\n",
       "      <td>109</td>\n",
       "      <td>h_82306</td>\n",
       "      <td>0.09987372</td>\n",
       "      <td>58</td>\n",
       "      <td>d_34290</td>\n",
       "      <td>0.09986265</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100001193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>115</td>\n",
       "      <td>d_43310</td>\n",
       "      <td>0.0999918</td>\n",
       "      <td>115</td>\n",
       "      <td>d_25000</td>\n",
       "      <td>0.09996737</td>\n",
       "      <td>56</td>\n",
       "      <td>d_25000</td>\n",
       "      <td>0.09996737</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100001633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74</td>\n",
       "      <td>d_2392</td>\n",
       "      <td>0.09976251</td>\n",
       "      <td>8</td>\n",
       "      <td>d_2392</td>\n",
       "      <td>0.09976251</td>\n",
       "      <td>8</td>\n",
       "      <td>d_2724</td>\n",
       "      <td>0.09969918</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100001759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035086</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009079</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>d_78830</td>\n",
       "      <td>0.099996015</td>\n",
       "      <td>14</td>\n",
       "      <td>d_7917</td>\n",
       "      <td>0.09999229</td>\n",
       "      <td>9</td>\n",
       "      <td>d_7917</td>\n",
       "      <td>0.09999229</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100001871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>d_25000</td>\n",
       "      <td>0.09990656</td>\n",
       "      <td>109</td>\n",
       "      <td>d_25000</td>\n",
       "      <td>0.09990656</td>\n",
       "      <td>109</td>\n",
       "      <td>h_99214</td>\n",
       "      <td>0.09988528</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100001953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>h_74022</td>\n",
       "      <td>0.09999889</td>\n",
       "      <td>92</td>\n",
       "      <td>d_7234</td>\n",
       "      <td>0.099997796</td>\n",
       "      <td>96</td>\n",
       "      <td>h_99283</td>\n",
       "      <td>0.0999965</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100001989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>h_80053</td>\n",
       "      <td>0.0999469</td>\n",
       "      <td>57</td>\n",
       "      <td>d_2689</td>\n",
       "      <td>0.0999423</td>\n",
       "      <td>7</td>\n",
       "      <td>d_25000</td>\n",
       "      <td>0.09994027</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100002065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031369</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.373209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>d_78609</td>\n",
       "      <td>0.099966526</td>\n",
       "      <td>19</td>\n",
       "      <td>d_78609</td>\n",
       "      <td>0.099966526</td>\n",
       "      <td>3</td>\n",
       "      <td>d_78609</td>\n",
       "      <td>0.099966526</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100002283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>d_3569</td>\n",
       "      <td>0.099856995</td>\n",
       "      <td>2</td>\n",
       "      <td>h_36415</td>\n",
       "      <td>0.09985329</td>\n",
       "      <td>36</td>\n",
       "      <td>h_36415</td>\n",
       "      <td>0.09985329</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100002329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>h_83540</td>\n",
       "      <td>0.09995404</td>\n",
       "      <td>8</td>\n",
       "      <td>h_76776</td>\n",
       "      <td>0.09995292</td>\n",
       "      <td>50</td>\n",
       "      <td>d_99681</td>\n",
       "      <td>0.099948764</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100002333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.298968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>d_78820</td>\n",
       "      <td>0.099938355</td>\n",
       "      <td>14</td>\n",
       "      <td>d_78820</td>\n",
       "      <td>0.099938355</td>\n",
       "      <td>14</td>\n",
       "      <td>d_78820</td>\n",
       "      <td>0.099938355</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100002439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>115</td>\n",
       "      <td>h_G0151</td>\n",
       "      <td>0.099655494</td>\n",
       "      <td>108</td>\n",
       "      <td>h_G0154</td>\n",
       "      <td>0.09965148</td>\n",
       "      <td>116</td>\n",
       "      <td>h_G0154</td>\n",
       "      <td>0.09965148</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100002623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>d_78605</td>\n",
       "      <td>0.099920705</td>\n",
       "      <td>50</td>\n",
       "      <td>h_80053</td>\n",
       "      <td>0.09987952</td>\n",
       "      <td>59</td>\n",
       "      <td>h_82306</td>\n",
       "      <td>0.09987877</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100002729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>d_29623</td>\n",
       "      <td>0.099982776</td>\n",
       "      <td>104</td>\n",
       "      <td>d_29623</td>\n",
       "      <td>0.099982776</td>\n",
       "      <td>104</td>\n",
       "      <td>d_29623</td>\n",
       "      <td>0.099982776</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100002745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>h_36415</td>\n",
       "      <td>0.09991741</td>\n",
       "      <td>32</td>\n",
       "      <td>h_36415</td>\n",
       "      <td>0.09991741</td>\n",
       "      <td>81</td>\n",
       "      <td>h_82570</td>\n",
       "      <td>0.09988829</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    patient_id  d_5990  d_5990_Probs  d_78605  d_78605_Probs  d_486  \\\n",
       "0    100000099     0.0      0.072606      0.0       0.005401    0.0   \n",
       "1    100000315     0.0      0.132548      0.0       0.012732    0.0   \n",
       "2    100000379     0.0      0.012923      0.0       0.020842    0.0   \n",
       "3    100000437     0.0      0.006942      0.0       0.001616    0.0   \n",
       "4    100000559     0.0      0.070057      0.0       0.047910    0.0   \n",
       "5    100000905     0.0      0.007223      0.0       0.007878    0.0   \n",
       "6    100001193     0.0      0.005848      0.0       0.003948    0.0   \n",
       "7    100001633     0.0      0.006565      0.0       0.006862    0.0   \n",
       "8    100001759     0.0      0.035086      1.0       0.009079    1.0   \n",
       "9    100001871     0.0      0.011194      0.0       0.009376    0.0   \n",
       "10   100001953     0.0      0.010530      0.0       0.017776    0.0   \n",
       "11   100001989     0.0      0.037946      0.0       0.022414    0.0   \n",
       "12   100002065     0.0      0.031369      1.0       0.373209    0.0   \n",
       "13   100002283     0.0      0.006021      0.0       0.005656    0.0   \n",
       "14   100002329     0.0      0.017346      0.0       0.036580    0.0   \n",
       "15   100002333     0.0      0.298968      0.0       0.030189    0.0   \n",
       "16   100002439     0.0      0.007004      0.0       0.003567    0.0   \n",
       "17   100002623     0.0      0.026502      0.0       0.025648    0.0   \n",
       "18   100002729     0.0      0.012448      0.0       0.011795    0.0   \n",
       "19   100002745     0.0      0.028652      0.0       0.016925    0.0   \n",
       "\n",
       "    d_486_Probs  d_78650  d_78650_Probs  d_78079  ...  dates_7  event_8  \\\n",
       "0      0.015968      0.0       0.007524      0.0  ...       15  d_17362   \n",
       "1      0.013535      0.0       0.018253      1.0  ...       92  h_93280   \n",
       "2      0.009473      0.0       0.029747      0.0  ...       43   d_1744   \n",
       "3      0.000609      0.0       0.003745      0.0  ...       28  d_V5419   \n",
       "4      0.072270      0.0       0.058664      0.0  ...       10  h_A0428   \n",
       "5      0.002185      0.0       0.020066      0.0  ...      109  d_72210   \n",
       "6      0.001426      0.0       0.008430      0.0  ...      115  d_43310   \n",
       "7      0.002416      0.0       0.012752      0.0  ...       74   d_2392   \n",
       "8      0.006181      0.0       0.013610      0.0  ...       53  d_78830   \n",
       "9      0.003273      0.0       0.015286      0.0  ...       40  d_25000   \n",
       "10     0.003926      0.0       0.038164      0.0  ...       92  h_74022   \n",
       "11     0.009478      0.0       0.027383      0.0  ...       57  h_80053   \n",
       "12     0.085594      0.0       0.125317      0.0  ...        4  d_78609   \n",
       "13     0.001595      0.0       0.012909      0.0  ...        2   d_3569   \n",
       "14     0.012139      0.0       0.049644      0.0  ...       84  h_83540   \n",
       "15     0.047613      0.0       0.036637      0.0  ...       42  d_78820   \n",
       "16     0.001789      0.0       0.006329      0.0  ...      115  h_G0151   \n",
       "17     0.013170      0.0       0.025618      0.0  ...       59  d_78605   \n",
       "18     0.004323      0.0       0.017690      0.0  ...       49  d_29623   \n",
       "19     0.008298      0.0       0.021126      0.0  ...        3  h_36415   \n",
       "\n",
       "        score_8  dates_8  event_9      score_9  dates_9  event_10  \\\n",
       "0    0.09835929       15  d_17362   0.09835929       15   d_17362   \n",
       "1   0.099985495       22   d_5950  0.099975646      114    d_5950   \n",
       "2    0.09993821       56   d_1744   0.09993821       56   h_4177F   \n",
       "3    0.09997104       21  d_V5419   0.09997104       21   d_V5419   \n",
       "4   0.099961355       10  h_A0428  0.099961355       36   h_A0428   \n",
       "5     0.0999083      109  h_82306   0.09987372       58   d_34290   \n",
       "6     0.0999918      115  d_25000   0.09996737       56   d_25000   \n",
       "7    0.09976251        8   d_2392   0.09976251        8    d_2724   \n",
       "8   0.099996015       14   d_7917   0.09999229        9    d_7917   \n",
       "9    0.09990656      109  d_25000   0.09990656      109   h_99214   \n",
       "10   0.09999889       92   d_7234  0.099997796       96   h_99283   \n",
       "11    0.0999469       57   d_2689    0.0999423        7   d_25000   \n",
       "12  0.099966526       19  d_78609  0.099966526        3   d_78609   \n",
       "13  0.099856995        2  h_36415   0.09985329       36   h_36415   \n",
       "14   0.09995404        8  h_76776   0.09995292       50   d_99681   \n",
       "15  0.099938355       14  d_78820  0.099938355       14   d_78820   \n",
       "16  0.099655494      108  h_G0154   0.09965148      116   h_G0154   \n",
       "17  0.099920705       50  h_80053   0.09987952       59   h_82306   \n",
       "18  0.099982776      104  d_29623  0.099982776      104   d_29623   \n",
       "19   0.09991741       32  h_36415   0.09991741       81   h_82570   \n",
       "\n",
       "       score_10  dates_10  \n",
       "0    0.09835929        30  \n",
       "1   0.099975646       114  \n",
       "2   0.099926025        17  \n",
       "3    0.09997104        14  \n",
       "4   0.099961355        38  \n",
       "5    0.09986265        44  \n",
       "6    0.09996737        53  \n",
       "7    0.09969918        74  \n",
       "8    0.09999229         9  \n",
       "9    0.09988528       109  \n",
       "10    0.0999965        96  \n",
       "11   0.09994027        63  \n",
       "12  0.099966526         3  \n",
       "13   0.09985329        94  \n",
       "14  0.099948764        51  \n",
       "15  0.099938355        84  \n",
       "16   0.09965148       119  \n",
       "17   0.09987877        59  \n",
       "18  0.099982776        56  \n",
       "19   0.09988829        81  \n",
       "\n",
       "[20 rows x 71 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['patient_id', 'd_5990', 'd_5990_Probs', 'd_78605', 'd_78605_Probs',\n",
       "       'd_486', 'd_486_Probs', 'd_78650', 'd_78650_Probs', 'd_78079',\n",
       "       'd_78079_Probs', 'd_78900', 'd_78900_Probs', 'd_78609', 'd_78609_Probs',\n",
       "       'd_7862', 'd_7862_Probs', 'd_1101', 'd_1101_Probs', 'd_78701',\n",
       "       'd_78701_Probs', 'd_5789', 'd_5789_Probs', 'd_78791', 'd_78791_Probs',\n",
       "       'd_6826', 'd_6826_Probs', 'd_78659', 'd_78659_Probs', 'd_78907',\n",
       "       'd_78907_Probs', 'd_7840', 'd_7840_Probs', 'd_28860', 'd_28860_Probs',\n",
       "       'd_4660', 'd_4660_Probs', 'd_6829', 'd_6829_Probs', 'd_00845',\n",
       "       'd_00845_Probs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns[:41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_df = test_df[test_df.columns[:41]]\n",
    "event_df = test_df[['patient_id'] + list(test_df.columns[41:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>d_5990</th>\n",
       "      <th>d_5990_Probs</th>\n",
       "      <th>d_78605</th>\n",
       "      <th>d_78605_Probs</th>\n",
       "      <th>d_486</th>\n",
       "      <th>d_486_Probs</th>\n",
       "      <th>d_78650</th>\n",
       "      <th>d_78650_Probs</th>\n",
       "      <th>d_78079</th>\n",
       "      <th>...</th>\n",
       "      <th>d_7840_Probs</th>\n",
       "      <th>d_28860</th>\n",
       "      <th>d_28860_Probs</th>\n",
       "      <th>d_4660</th>\n",
       "      <th>d_4660_Probs</th>\n",
       "      <th>d_6829</th>\n",
       "      <th>d_6829_Probs</th>\n",
       "      <th>d_00845</th>\n",
       "      <th>d_00845_Probs</th>\n",
       "      <th>index_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>20120601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100000315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018253</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>20120601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100000379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029747</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>20120601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100000437</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>20120601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100000559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006905</td>\n",
       "      <td>20120601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  d_5990  d_5990_Probs  d_78605  d_78605_Probs  d_486  \\\n",
       "0   100000099     0.0      0.072606      0.0       0.005401    0.0   \n",
       "1   100000315     0.0      0.132548      0.0       0.012732    0.0   \n",
       "2   100000379     0.0      0.012923      0.0       0.020842    0.0   \n",
       "3   100000437     0.0      0.006942      0.0       0.001616    0.0   \n",
       "4   100000559     0.0      0.070057      0.0       0.047910    0.0   \n",
       "\n",
       "   d_486_Probs  d_78650  d_78650_Probs  d_78079  ...  d_7840_Probs  d_28860  \\\n",
       "0     0.015968      0.0       0.007524      0.0  ...      0.002237      0.0   \n",
       "1     0.013535      0.0       0.018253      1.0  ...      0.005328      0.0   \n",
       "2     0.009473      0.0       0.029747      0.0  ...      0.008270      0.0   \n",
       "3     0.000609      0.0       0.003745      0.0  ...      0.000804      0.0   \n",
       "4     0.072270      0.0       0.058664      0.0  ...      0.012962      0.0   \n",
       "\n",
       "   d_28860_Probs  d_4660  d_4660_Probs  d_6829  d_6829_Probs  d_00845  \\\n",
       "0       0.000742     0.0      0.004378     0.0      0.001584      0.0   \n",
       "1       0.001624     0.0      0.007198     0.0      0.004284      0.0   \n",
       "2       0.000843     0.0      0.007195     0.0      0.003700      0.0   \n",
       "3       0.000057     0.0      0.001817     0.0      0.000637      0.0   \n",
       "4       0.005074     0.0      0.004769     0.0      0.023712      0.0   \n",
       "\n",
       "   d_00845_Probs  index_date  \n",
       "0       0.000246    20120601  \n",
       "1       0.001491    20120601  \n",
       "2       0.000365    20120601  \n",
       "3       0.000008    20120601  \n",
       "4       0.006905    20120601  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>event_1</th>\n",
       "      <th>score_1</th>\n",
       "      <th>dates_1</th>\n",
       "      <th>event_2</th>\n",
       "      <th>score_2</th>\n",
       "      <th>dates_2</th>\n",
       "      <th>event_3</th>\n",
       "      <th>score_3</th>\n",
       "      <th>dates_3</th>\n",
       "      <th>...</th>\n",
       "      <th>event_8</th>\n",
       "      <th>score_8</th>\n",
       "      <th>dates_8</th>\n",
       "      <th>event_9</th>\n",
       "      <th>score_9</th>\n",
       "      <th>dates_9</th>\n",
       "      <th>event_10</th>\n",
       "      <th>score_10</th>\n",
       "      <th>dates_10</th>\n",
       "      <th>index_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000099</td>\n",
       "      <td>d_5929</td>\n",
       "      <td>0.100788124</td>\n",
       "      <td>71</td>\n",
       "      <td>d_5929</td>\n",
       "      <td>0.100788124</td>\n",
       "      <td>71</td>\n",
       "      <td>d_5929</td>\n",
       "      <td>0.100788124</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>d_17362</td>\n",
       "      <td>0.09835929</td>\n",
       "      <td>15</td>\n",
       "      <td>d_17362</td>\n",
       "      <td>0.09835929</td>\n",
       "      <td>15</td>\n",
       "      <td>d_17362</td>\n",
       "      <td>0.09835929</td>\n",
       "      <td>30</td>\n",
       "      <td>20120601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100000315</td>\n",
       "      <td>h_87186</td>\n",
       "      <td>0.100095496</td>\n",
       "      <td>92</td>\n",
       "      <td>h_87088</td>\n",
       "      <td>0.09999611</td>\n",
       "      <td>114</td>\n",
       "      <td>h_87088</td>\n",
       "      <td>0.09999611</td>\n",
       "      <td>92</td>\n",
       "      <td>...</td>\n",
       "      <td>h_93280</td>\n",
       "      <td>0.099985495</td>\n",
       "      <td>22</td>\n",
       "      <td>d_5950</td>\n",
       "      <td>0.099975646</td>\n",
       "      <td>114</td>\n",
       "      <td>d_5950</td>\n",
       "      <td>0.099975646</td>\n",
       "      <td>114</td>\n",
       "      <td>20120601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100000379</td>\n",
       "      <td>d_2704</td>\n",
       "      <td>0.10008121</td>\n",
       "      <td>56</td>\n",
       "      <td>d_7010</td>\n",
       "      <td>0.100075185</td>\n",
       "      <td>84</td>\n",
       "      <td>d_7010</td>\n",
       "      <td>0.100075185</td>\n",
       "      <td>84</td>\n",
       "      <td>...</td>\n",
       "      <td>d_1744</td>\n",
       "      <td>0.09993821</td>\n",
       "      <td>56</td>\n",
       "      <td>d_1744</td>\n",
       "      <td>0.09993821</td>\n",
       "      <td>56</td>\n",
       "      <td>h_4177F</td>\n",
       "      <td>0.099926025</td>\n",
       "      <td>17</td>\n",
       "      <td>20120601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100000437</td>\n",
       "      <td>d_81601</td>\n",
       "      <td>0.10011583</td>\n",
       "      <td>42</td>\n",
       "      <td>d_81601</td>\n",
       "      <td>0.10011583</td>\n",
       "      <td>42</td>\n",
       "      <td>d_V5419</td>\n",
       "      <td>0.09997104</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>d_V5419</td>\n",
       "      <td>0.09997104</td>\n",
       "      <td>21</td>\n",
       "      <td>d_V5419</td>\n",
       "      <td>0.09997104</td>\n",
       "      <td>21</td>\n",
       "      <td>d_V5419</td>\n",
       "      <td>0.09997104</td>\n",
       "      <td>14</td>\n",
       "      <td>20120601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100000559</td>\n",
       "      <td>h_90960</td>\n",
       "      <td>0.10008023</td>\n",
       "      <td>0</td>\n",
       "      <td>h_90960</td>\n",
       "      <td>0.10008023</td>\n",
       "      <td>61</td>\n",
       "      <td>h_90960</td>\n",
       "      <td>0.10008023</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>h_A0428</td>\n",
       "      <td>0.099961355</td>\n",
       "      <td>10</td>\n",
       "      <td>h_A0428</td>\n",
       "      <td>0.099961355</td>\n",
       "      <td>36</td>\n",
       "      <td>h_A0428</td>\n",
       "      <td>0.099961355</td>\n",
       "      <td>38</td>\n",
       "      <td>20120601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  event_1      score_1 dates_1  event_2      score_2 dates_2  \\\n",
       "0   100000099   d_5929  0.100788124      71   d_5929  0.100788124      71   \n",
       "1   100000315  h_87186  0.100095496      92  h_87088   0.09999611     114   \n",
       "2   100000379   d_2704   0.10008121      56   d_7010  0.100075185      84   \n",
       "3   100000437  d_81601   0.10011583      42  d_81601   0.10011583      42   \n",
       "4   100000559  h_90960   0.10008023       0  h_90960   0.10008023      61   \n",
       "\n",
       "   event_3      score_3 dates_3  ...  event_8      score_8 dates_8  event_9  \\\n",
       "0   d_5929  0.100788124      85  ...  d_17362   0.09835929      15  d_17362   \n",
       "1  h_87088   0.09999611      92  ...  h_93280  0.099985495      22   d_5950   \n",
       "2   d_7010  0.100075185      84  ...   d_1744   0.09993821      56   d_1744   \n",
       "3  d_V5419   0.09997104      14  ...  d_V5419   0.09997104      21  d_V5419   \n",
       "4  h_90960   0.10008023      31  ...  h_A0428  0.099961355      10  h_A0428   \n",
       "\n",
       "       score_9 dates_9 event_10     score_10 dates_10 index_date  \n",
       "0   0.09835929      15  d_17362   0.09835929       30   20120601  \n",
       "1  0.099975646     114   d_5950  0.099975646      114   20120601  \n",
       "2   0.09993821      56  h_4177F  0.099926025       17   20120601  \n",
       "3   0.09997104      21  d_V5419   0.09997104       14   20120601  \n",
       "4  0.099961355      36  h_A0428  0.099961355       38   20120601  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "event_df['index_date'] = index_dates\n",
    "probability_df['index_date'] = index_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df.to_csv('./test/test_ae_event_importance_withIndex.csv', index=False)\n",
    "probability_df.to_csv('./test/test_ae_probability_withIndex.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: test/test_ae_event_importance_withIndex.csv to s3://cmsai-mrk-amzn/test phase/test_ae_event_importance_withIndex_nan.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp ./test/test_ae_event_importance_withIndex.csv s3://cmsai-mrk-amzn/test\\ phase/test_ae_event_importance_withIndex_nan.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: test/test_ae_probability_withIndex.csv to s3://cmsai-mrk-amzn/test phase/test_ae_probability_withIndex_nan.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp ./test/test_ae_probability_withIndex.csv s3://cmsai-mrk-amzn/test\\ phase/test_ae_probability_withIndex_nan.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./AE_Testing_E2E_full_test_submitted.ipynb to s3://cmsai-mrk-amzn/test phase/AE_Testing_E2E_full_test_submitted.ipynb\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp AE_Testing_E2E_full_test_submitted.ipynb s3://cmsai-mrk-amzn/test\\ phase/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
