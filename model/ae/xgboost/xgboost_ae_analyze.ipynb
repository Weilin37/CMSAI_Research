{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating and Analyzing of XGBoost Trainined Models for Detecting Adverse Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to analyze a trained xgboost models to detect adverse events for given patients based on their historical data.\n",
    "Let's first start to import the packages needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import boto3\n",
    "\n",
    "import shap\n",
    "import tarfile\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "##User defined import\n",
    "import utils\n",
    "from metrics import compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_model_from_s3(s3_model_path, local_model_dir):\n",
    "    \"\"\"Copy model from s3 to local\n",
    "    Args:\n",
    "        s3_model_path(str): S3 path where the model gz is saved\n",
    "    Returns:\n",
    "        Destination model path\n",
    "    \"\"\"\n",
    "    client = boto3.client('s3')\n",
    "    o = urlparse(s3_model_path)\n",
    "    bucket = o.netloc\n",
    "    key = o.path\n",
    "    key = key.lstrip('/')\n",
    "    if not os.path.exists(local_model_dir): \n",
    "        os.makedirs(local_model_dir) \n",
    "    fname = os.path.basename(s3_model_path) \n",
    "    output_path = os.path.join(local_model_dir, fname)\n",
    "    \n",
    "    client.download_file(bucket, key, output_path)\n",
    "    \n",
    "    return output_path\n",
    "   \n",
    "\n",
    "def load_model(gz_model_path): \n",
    "    \"\"\"\n",
    "    Loads xgboost trained model from disk\n",
    "    Args:\n",
    "        gz_model_path(str): Compressed Model path\n",
    "    Returns:\n",
    "        xgboost: Xgboost model object\n",
    "    \"\"\"\n",
    "    model_dir = os.path.dirname(gz_model_path)\n",
    "    model_path = os.path.join(model_dir, 'xgboost-model')\n",
    "\n",
    "    tar = tarfile.open(gz_model_path, \"r:gz\")\n",
    "    tar.extractall(model_dir)\n",
    "    tar.close()\n",
    "    \n",
    "    #Load Model\n",
    "    model = pickle.load(open(model_path, \"rb\"))\n",
    "    \n",
    "    #Remove the local copy of the model files\n",
    "    shutil.rmtree(model_dir)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_labels_scores(df_preds_labels, target_names=None):\n",
    "    \"\"\"Get labels and scores/predictions to compute model metrics\n",
    "    Args:\n",
    "        df_preds_labels(pd.DataFrame): Dataframe of predictions & true labels\n",
    "        target_names(list): List of target events\n",
    "    Returns:\n",
    "        Tuple of labels(np.array), scores(np.array) and Event names(list)\n",
    "    \"\"\"\n",
    "    labels = None\n",
    "    scores = None\n",
    "    if target_names is None:\n",
    "        cols = df_preds_labels.columns.tolist()\n",
    "        label_names = [col for col in cols if not col.endswith('_')]\n",
    "        label_names = [name for name in label_names if not name.endswith('probs')]\n",
    "        pred_names = [col for col in cols if col.endswith('probs')]\n",
    "    else:\n",
    "        label_names = target_names\n",
    "        pred_names = [name+'_probs' for name in target_names]\n",
    "    \n",
    "    labels = df_preds_labels[label_names].values\n",
    "    scores = df_preds_labels[pred_names].values\n",
    "\n",
    "    return labels, scores, label_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSED_DATA_DIR = '/home/ec2-user/SageMaker/CMSAI/modeling/tes/data/final-global/ae/1000/preprocessed'\n",
    "SPLIT = 'val'\n",
    "NUM_FEATURES = 100\n",
    "DATA_PATH = os.path.join(PREPROCESSED_DATA_DIR, SPLIT+'.csv')\n",
    "\n",
    "TRAIN_DATA_DIR = '/home/ec2-user/SageMaker/CMSAI/modeling/tes/data/final-global/ae/1000/training/'\n",
    "MODEL_DIR = '/home/ec2-user/SageMaker/CMSAI/modeling/tes/data/final-global/ae/1000/model/'\n",
    "\n",
    "TRAIN_RESULTS_PATH = os.path.join(TRAIN_DATA_DIR, str(NUM_FEATURES), 'train_results.csv')\n",
    "FINAL_RESULTS_DIR = os.path.join(TRAIN_DATA_DIR, str(NUM_FEATURES), 'final_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will add all the values/paths needed to train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>num_features</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>best_model_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d_5990</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8034</td>\n",
       "      <td>s3://cmsai-mrk-amzn/CSVModelInputs/Tes/models/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d_78605</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8160</td>\n",
       "      <td>s3://cmsai-mrk-amzn/CSVModelInputs/Tes/models/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d_486</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8641</td>\n",
       "      <td>s3://cmsai-mrk-amzn/CSVModelInputs/Tes/models/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d_78650</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7395</td>\n",
       "      <td>s3://cmsai-mrk-amzn/CSVModelInputs/Tes/models/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d_78079</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7415</td>\n",
       "      <td>s3://cmsai-mrk-amzn/CSVModelInputs/Tes/models/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     class  num_features  val_auc  \\\n",
       "0   d_5990           100   0.8034   \n",
       "1  d_78605           100   0.8160   \n",
       "2    d_486           100   0.8641   \n",
       "3  d_78650           100   0.7395   \n",
       "4  d_78079           100   0.7415   \n",
       "\n",
       "                                     best_model_path  \n",
       "0  s3://cmsai-mrk-amzn/CSVModelInputs/Tes/models/...  \n",
       "1  s3://cmsai-mrk-amzn/CSVModelInputs/Tes/models/...  \n",
       "2  s3://cmsai-mrk-amzn/CSVModelInputs/Tes/models/...  \n",
       "3  s3://cmsai-mrk-amzn/CSVModelInputs/Tes/models/...  \n",
       "4  s3://cmsai-mrk-amzn/CSVModelInputs/Tes/models/...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.read_csv(TRAIN_RESULTS_PATH)\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_vis = df_results.pivot(index='num_features', columns='class', values='val_auc')\n",
    "# df_vis.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>num_features</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>best_model_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d_5990</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8034</td>\n",
       "      <td>s3://cmsai-mrk-amzn/CSVModelInputs/Tes/models/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d_78605</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8160</td>\n",
       "      <td>s3://cmsai-mrk-amzn/CSVModelInputs/Tes/models/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d_486</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8641</td>\n",
       "      <td>s3://cmsai-mrk-amzn/CSVModelInputs/Tes/models/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d_78650</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7395</td>\n",
       "      <td>s3://cmsai-mrk-amzn/CSVModelInputs/Tes/models/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d_78079</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7415</td>\n",
       "      <td>s3://cmsai-mrk-amzn/CSVModelInputs/Tes/models/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     class  num_features  val_auc  \\\n",
       "0   d_5990           100   0.8034   \n",
       "1  d_78605           100   0.8160   \n",
       "2    d_486           100   0.8641   \n",
       "3  d_78650           100   0.7395   \n",
       "4  d_78079           100   0.7415   \n",
       "\n",
       "                                     best_model_path  \n",
       "0  s3://cmsai-mrk-amzn/CSVModelInputs/Tes/models/...  \n",
       "1  s3://cmsai-mrk-amzn/CSVModelInputs/Tes/models/...  \n",
       "2  s3://cmsai-mrk-amzn/CSVModelInputs/Tes/models/...  \n",
       "3  s3://cmsai-mrk-amzn/CSVModelInputs/Tes/models/...  \n",
       "4  s3://cmsai-mrk-amzn/CSVModelInputs/Tes/models/...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get models having the best performance for each target variable\n",
    "idx = df_results.groupby('class')['val_auc'].transform(max) ==df_results['val_auc']\n",
    "df_best = df_results[idx]\n",
    "print(df_best.shape)\n",
    "df_best.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_models = [['d_5990', 100, 0.7, 's3://cmsai-mrk-amzn/CSVModelInputs/Tes/models/ae/final/month-0/xgboost/2020-11-10-20-48-57/100/d_5990/output/sagemaker-xgboost-201110-2049-020-212dc74f/output/model.tar.gz'],\n",
    "#                ['d_78605', 100, 0.6, 's3://cmsai-mrk-amzn/CSVModelInputs/Tes/models/ae/final/month-0/xgboost/2020-11-10-20-48-57/100/d_5990/output/sagemaker-xgboost-201110-2049-016-3e3ab8f4/output/model.tar.gz']]\n",
    "# columns = ['class', 'num_features', 'val_auc', 'best_model_path']\n",
    "# df_best = pd.DataFrame(best_models, columns=columns)\n",
    "# print(df_best.shape)\n",
    "# df_best.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1474322, 320)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h_99213</th>\n",
       "      <th>h_99214</th>\n",
       "      <th>h_36415</th>\n",
       "      <th>d_25000</th>\n",
       "      <th>p_D1E</th>\n",
       "      <th>d_4019</th>\n",
       "      <th>h_85025</th>\n",
       "      <th>h_80053</th>\n",
       "      <th>h_97110</th>\n",
       "      <th>d_4011</th>\n",
       "      <th>...</th>\n",
       "      <th>d_5789</th>\n",
       "      <th>d_78791</th>\n",
       "      <th>d_6826</th>\n",
       "      <th>d_78659</th>\n",
       "      <th>d_78907</th>\n",
       "      <th>d_7840</th>\n",
       "      <th>d_28860</th>\n",
       "      <th>d_4660</th>\n",
       "      <th>d_6829</th>\n",
       "      <th>d_00845</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 320 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   h_99213  h_99214  h_36415  d_25000  p_D1E  d_4019  h_85025  h_80053  \\\n",
       "0        1        1        0        0      0       0        0        0   \n",
       "1        0        0        0        0      1       0        0        0   \n",
       "2        0        0        1        0      0       1        0        0   \n",
       "3        1        0        0        0      0       0        0        0   \n",
       "4        1        1        0        0      0       0        0        0   \n",
       "\n",
       "   h_97110  d_4011  ...  d_5789  d_78791  d_6826  d_78659  d_78907  d_7840  \\\n",
       "0        0       1  ...       0        0       0        0        0       0   \n",
       "1        0       0  ...       0        0       0        0        0       0   \n",
       "2        0       0  ...       0        0       0        0        0       0   \n",
       "3        0       0  ...       0        1       1        0        0       0   \n",
       "4        0       0  ...       0        0       0        0        0       0   \n",
       "\n",
       "   d_28860  d_4660  d_6829  d_00845  \n",
       "0        0       1       0        0  \n",
       "1        0       0       0        0  \n",
       "2        0       0       0        0  \n",
       "3        0       0       0        0  \n",
       "4        0       0       0        0  \n",
       "\n",
       "[5 rows x 320 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv(DATA_PATH)\n",
    "print(df_data.shape)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_predictions(row, df_data, local_model_dir):\n",
    "    \"\"\"Process the predictions and performance for best model for each class.\n",
    "    df_data first column is labels and others are features\n",
    "    \"\"\"\n",
    "    best_model_path = row['best_model_path']\n",
    "    target = row['class']\n",
    "    num_features = row['num_features']\n",
    "    \n",
    "    #Copy the best model from s3 to local\n",
    "    output_path = copy_model_from_s3(best_model_path, local_model_dir)\n",
    "\n",
    "    #Load the copied model\n",
    "    model = load_model(output_path)\n",
    "    \n",
    "    preds = []\n",
    "    features = df_data.columns.tolist()[:num_features]\n",
    "    #Predict for data and save in pd Dataframe\n",
    "    probs = model.predict(xgb.DMatrix(df_data[features].values, df_data[target].values))\n",
    "    #probs = model.predict(xgb.DMatrix(df_data.iloc[:, :num_features], df_data[target].values, feature_names=feature_names))\n",
    "    preds.append(df_data[target].tolist())\n",
    "    preds.append((probs>=0.5).astype(int).tolist())\n",
    "    preds.append(probs.tolist())\n",
    "    \n",
    "    columns = [target, target+'_', target+'_probs']\n",
    "    return preds, columns\n",
    "\n",
    "\n",
    "def get_all_predictions(df_best_models, df_data, local_model_dir):\n",
    "    \"\"\"Get predictions from each of the best models of each target variable.\"\"\"\n",
    "    num_rows = df_best_models.shape[0]\n",
    "    all_columns = []\n",
    "    all_preds = []\n",
    "    for i in range(num_rows):\n",
    "        row = df_best_models.iloc[i, :]\n",
    "        preds, columns = get_model_predictions(row, df_data, local_model_dir)\n",
    "        all_preds += preds\n",
    "        all_columns += columns\n",
    "        \n",
    "    df_preds = pd.DataFrame(np.array(all_preds).T, columns=all_columns)\n",
    "    return df_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate for a sample model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = df_best.iloc[0, 0]\n",
    "# num_features = df_best.iloc[0,1]\n",
    "# best_model_path = df_best.iloc[0, 3]\n",
    "\n",
    "# #Copy the best model from s3 to local\n",
    "# output_path = copy_model_from_s3(best_model_path, MODEL_DIR)\n",
    "# #Load the copied model\n",
    "# model = load_model(output_path)\n",
    "# #model.feature_names\n",
    "\n",
    "# #Evaluate model on data\n",
    "# feature_names = df_data.columns.tolist()[:num_features]\n",
    "# auc = model.eval(xgb.DMatrix(df_data[feature_names].values, df_data[target].values))\n",
    "# print('AUC: - {}'.format(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = get_all_predictions(df_best, df_data, MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_preds.shape)\n",
    "df_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_labels, np_scores, _ = get_labels_scores(df_preds)\n",
    "target_names = df_best['class'].tolist()\n",
    "df_metrics = compute_metrics(np_labels, np_scores, target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Labels Shape: {}, Scores Shape: {}'.format(np_labels.shape, np_scores.shape))\n",
    "df_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(df_metrics.mean()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn = df_metrics.min()\n",
    "mx = df_metrics.max()\n",
    "avg = df_metrics.mean()\n",
    "\n",
    "df_metrics.loc['Min'] = mn\n",
    "df_metrics.loc['Max'] = mx\n",
    "df_metrics.loc['Average'] = avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = df_data.columns.tolist()[:NUM_FEATURES]\n",
    "if not os.path.exists(FINAL_RESULTS_DIR):\n",
    "    os.makedirs(FINAL_RESULTS_DIR)\n",
    "    \n",
    "#Save the features used\n",
    "features_list_path = os.path.join(FINAL_RESULTS_DIR, 'features.txt')\n",
    "with open(features_list_path, 'w') as fp:\n",
    "    fp.write('\\n'.join(feature_names))\n",
    "\n",
    "#Save the final metrics results\n",
    "final_results_path = os.path.join(FINAL_RESULTS_DIR, SPLIT+'_metrics.csv')\n",
    "df_metrics.to_csv(final_results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainability and Visualization using SHAP (SHapley Additive exPlanations)\n",
    "\n",
    "*Source: https://github.com/slundberg/shap*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# load JS visualization code to notebook\n",
    "#shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing for val data...\n",
      "Computing SHAP Results for Target=d_5990...\n",
      "Computing SHAP Results for Target=d_78605...\n",
      "Computing SHAP Results for Target=d_486...\n",
      "Computing SHAP Results for Target=d_78650...\n"
     ]
    }
   ],
   "source": [
    "print('Processing for {} data...'.format(SPLIT))\n",
    "feature_names = df_data.columns.tolist()[:NUM_FEATURES]\n",
    "X = df_data[feature_names]\n",
    "\n",
    "#Create a new shap dir if not available\n",
    "shap_dir = os.path.join(FINAL_RESULTS_DIR, 'shap_'+SPLIT)\n",
    "if not os.path.exists(shap_dir):\n",
    "    os.makedirs(shap_dir)\n",
    "    \n",
    "num_rows = df_best.shape[0]\n",
    "for i in range(num_rows):\n",
    "    target = df_best.iloc[i, 0]\n",
    "    num_features = df_best.iloc[i, 1]\n",
    "    best_model_path = df_best.iloc[i, 3]\n",
    "\n",
    "    y = df_data[target]\n",
    "\n",
    "    #Copy the best model from s3 to local\n",
    "    output_path = copy_model_from_s3(best_model_path, MODEL_DIR)\n",
    "    #Load the copied model\n",
    "    model = load_model(output_path)\n",
    "    \n",
    "    # explain the model's predictions using SHAP\n",
    "    # (same syntax works for LightGBM, CatBoost, scikit-learn and spark models)\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X)\n",
    "    \n",
    "    print('Computing SHAP Results for Target={}...'.format(target))\n",
    "    \n",
    "#     vis_path = os.path.join(shap_dir, target+'_shap_values.pkl')\n",
    "#     with open(vis_path, 'wb') as fp:\n",
    "#         pickle.dump(shap_values, fp)\n",
    "        \n",
    "    # visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)\n",
    "    vis_path = os.path.join(shap_dir, target+'_per_patient_shap.png')\n",
    "    shap.force_plot(explainer.expected_value, shap_values[0,:], X.iloc[0,:], matplotlib=True, show=False)\n",
    "    plt.savefig(vis_path, bbox_inches='tight')\n",
    "    plt.close(\"all\")\n",
    "    \n",
    "    # visualize the training set predictions\n",
    "    #shap.force_plot(explainer.expected_value, shap_values, X) ## Out-of-memory Error\n",
    "    \n",
    "    # create a dependence plot to show the effect of a single feature across the whole dataset\n",
    "    vis_path = os.path.join(shap_dir, target+'_per_feature_shap.png')\n",
    "    shap.dependence_plot(feature_names[0], shap_values, X, show=False)\n",
    "    plt.savefig(vis_path, bbox_inches='tight')\n",
    "    plt.close(\"all\")\n",
    "    \n",
    "    # summarize the effects of all the features\n",
    "    shap.summary_plot(shap_values, X, show=False)\n",
    "    vis_path = os.path.join(shap_dir, target+'_all_features_shap.png')\n",
    "    plt.savefig(vis_path, bbox_inches='tight')\n",
    "    plt.close(\"all\")\n",
    "    \n",
    "    #Compute the mean absolute value of the SHAP values for each feature to get a standard bar plot\n",
    "    shap.summary_plot(shap_values, X, plot_type=\"bar\", show=False)\n",
    "    vis_path = os.path.join(shap_dir, target+'_all_features_importance.png')\n",
    "    plt.savefig(vis_path, bbox_inches='tight')\n",
    "    plt.close(\"all\")\n",
    "    \n",
    "print('Shap Values and Visualizations Successfully Saved to {}!'.format(shap_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-python3",
   "language": "python",
   "name": "venv-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
