{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch transformers\n",
    "!pip install pandas --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mengwei/.conda/envs/Python3-mengwei/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# import section\n",
    "import time, datetime, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import(\n",
    "    DataLoader,\n",
    "    RandomSampler,\n",
    "    SequentialSampler,\n",
    "    TensorDataset,\n",
    "    random_split\n",
    ")\n",
    "import transformers\n",
    "from transformers import(\n",
    "    LongformerTokenizer,\n",
    "    LongformerForSequenceClassification,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    AdamW\n",
    ")\n",
    "from nltk.metrics import ConfusionMatrix # Looks better than the sklearn CM\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import boto3\n",
    "from boto3 import client\n",
    "import pandas as pd \n",
    "from io import StringIO \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        device = torch.device(\"cuda\") # cuda:0 for multi-gpu\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Equipment', 'Fitness for Duty', 'Hazard Identified / Not Eliminated or Controlled', 'Hazard not Identified', 'NA', 'OTHER Root Cause', 'Personal Protective Equipment (PPE)', 'Poor Design - Equipment / Work Area', 'Poor Design - Work Process', 'Poor Housekeeping', 'To Be Determined (Temporary Placeholder Selection)', 'Training', 'Unsafe Practices or Unsafe Behavior']\n",
      "Label                                               Target\n",
      "Equipment                                           0         817\n",
      "Fitness for Duty                                    1          15\n",
      "Hazard Identified / Not Eliminated or Controlled    2         209\n",
      "Hazard not Identified                               3         342\n",
      "NA                                                  4         773\n",
      "OTHER Root Cause                                    5         318\n",
      "Personal Protective Equipment (PPE)                 6         104\n",
      "Poor Design - Equipment / Work Area                 7         489\n",
      "Poor Design - Work Process                          8         413\n",
      "Poor Housekeeping                                   9          82\n",
      "To Be Determined (Temporary Placeholder Selection)  10         58\n",
      "Training                                            11        344\n",
      "Unsafe Practices or Unsafe Behavior                 12        781\n",
      "Name: Target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### LOAD DATA ###\n",
    "\n",
    "# Make s3 bucket\n",
    "s3 = boto3.client('s3')\n",
    "# Read raw data and labels\n",
    "data = s3.get_object(Bucket='wp-safety-incidents', Key='Data_2018_to_MAY_2020_UTF.csv')\n",
    "labels = s3.get_object(Bucket='wp-safety-incidents', Key='July_19_August_20_Categorization.csv')\n",
    "# Convert to dataframe\n",
    "dffinal  = pd.read_csv(data['Body'], delimiter = ',')\n",
    "\n",
    "# Get all labels\n",
    "labels = []\n",
    "\n",
    "# Loop through dataframe and assign numbers to labels\n",
    "targetList = []\n",
    "textList = []\n",
    "labelList = []\n",
    "for index, row in dffinal.iterrows():\n",
    "    temp_labels = row['Root Cause'].split(',')\n",
    "    for l in temp_labels:\n",
    "        if l.strip() == '':\n",
    "            labels.append('NA')\n",
    "        else:\n",
    "            labels.append(l.strip())\n",
    "        \n",
    "labels = list(set(labels))\n",
    "labels.sort()\n",
    "print(labels)\n",
    "for index, row in dffinal.iterrows():\n",
    "    temp_labels = row['Root Cause'].split(', ')\n",
    "    for l in temp_labels:\n",
    "        textList.append(row['Event Title'] + ': ' + row['Brief Event Description'])\n",
    "        if l.strip() == '':\n",
    "            targetList.append(labels.index('NA'))\n",
    "            labelList.append('NA')\n",
    "        else:\n",
    "            targetList.append(labels.index(l.strip()))\n",
    "            labelList.append(l.strip())\n",
    "        \n",
    "#Convert to training format\n",
    "df = pd.DataFrame()\n",
    "df['Text'] = textList\n",
    "df['Target'] = targetList\n",
    "df['Label'] = labelList\n",
    "df.to_pickle('df_root_causes.pkl')\n",
    "print(df.groupby(['Label','Target'])['Target'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label                                               Target\n",
      "Equipment                                           1         817\n",
      "Fitness for Duty                                    0          15\n",
      "Hazard Identified / Not Eliminated or Controlled    0         209\n",
      "Hazard not Identified                               0         342\n",
      "NA                                                  0         773\n",
      "OTHER Root Cause                                    0         318\n",
      "Personal Protective Equipment (PPE)                 0         104\n",
      "Poor Design - Equipment / Work Area                 0         489\n",
      "Poor Design - Work Process                          0         413\n",
      "Poor Housekeeping                                   0          82\n",
      "To Be Determined (Temporary Placeholder Selection)  0          58\n",
      "Training                                            0         344\n",
      "Unsafe Practices or Unsafe Behavior                 0         781\n",
      "Name: Target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "target = 0\n",
    "df.loc[df['Target'] == target, 'Target'] = -1\n",
    "df.loc[df['Target'] >= 0, 'Target'] = 0\n",
    "df.loc[df['Target'] == -1, 'Target'] = 1\n",
    "df.to_pickle('df_root_causes_'+str(target)+'.pkl')\n",
    "print(df.groupby(['Label','Target'])['Target'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stat(predictions, actual) :\n",
    "    #Flatten predictions array\n",
    "    preds = [np.argmax(subarr) for arr in predictions for subarr in arr]\n",
    "    true_labels_1d = []\n",
    "\n",
    "    #Flatten true_labels array\n",
    "    for arr in actual:\n",
    "        true_labels_1d.extend(arr.tolist())\n",
    "\n",
    "    #Print confusion matrixs and measures\n",
    "    cm = ConfusionMatrix(true_labels_1d, preds)\n",
    "    class_rep = classification_report(true_labels_1d, preds)\n",
    "    print(cm)\n",
    "    print(class_rep)\n",
    "    return(preds, true_labels_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
    "# Max is 512 if using BERT-based models, higher for longformer (2000+)\n",
    "def toke_and_enc(sentences, max_len):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for sent in sentences:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            sent,\n",
    "                            add_special_tokens = True,\n",
    "                            max_length = max_len,\n",
    "                            pad_to_max_length = True,\n",
    "                            return_attention_mask = True,\n",
    "                            return_tensors = 'pt',\n",
    "                            truncation = True\n",
    "                       )\n",
    "        \n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    \n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(train_dataset, batch_size=16) :\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            sampler = RandomSampler(train_dataset),\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "\n",
    "    return train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_dataset, num_labels, epochs = 4, batch_size = 64) : \n",
    "    train_dataloader = create_data_loader(train_dataset, batch_size = batch_size)\n",
    "\n",
    "    #Change the model name and num_labels depending on the task.\n",
    "    model = LongformerForSequenceClassification.from_pretrained('allenai/longformer-base-4096',\n",
    "                                                                gradient_checkpointing=True, # New to v3 - doesn't work with DataParallel\n",
    "                                                                num_labels=num_labels)\n",
    "    model.to(device)\n",
    "    optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5,\n",
    "                  eps = 1e-8\n",
    "                )\n",
    "    \n",
    "\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "\n",
    "\n",
    "    for epoch_i in range(0, epochs):\n",
    "\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "\n",
    "        total_train_loss = 0\n",
    "   \n",
    "        model.train()\n",
    "        print(\"here\")\n",
    "\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            print('.', end =\"\")\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "\n",
    "            model.zero_grad()        \n",
    "\n",
    "            loss, logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask,  labels=b_labels)\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_dataset, model, batch_size = 64) : \n",
    "    \n",
    "    test_sampler = SequentialSampler(test_dataset)\n",
    "\n",
    "    test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=batch_size)\n",
    "   \n",
    "    print('here')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    predictions , true_labels = [], []\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        print(\".\", end =\" \")\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "  \n",
    "        with torch.no_grad():\n",
    "              outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "\n",
    "        logits = outputs[0]\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "        predictions.append(logits)\n",
    "        true_labels.append(label_ids)\n",
    "\n",
    "    print('DONE.')\n",
    "    return(predictions, true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,796 training samples\n",
      "  949 test samples\n",
      "Max sentence length:  1267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mengwei/.conda/envs/Python3-mengwei/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1767: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Epoch 1 / 4 ========\n",
      "here\n",
      "....."
     ]
    }
   ],
   "source": [
    "# Divide the dataset by randomly selecting samples.\n",
    "dftrain=df.sample(frac=0.8)\n",
    "dftest=df.drop(dftrain.index)\n",
    "print('{:>5,} training samples'.format(len(dftrain)))\n",
    "print('{:>5,} test samples'.format(len(dftest)))\n",
    "\n",
    "# set tokenizer\n",
    "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
    "\n",
    "max_len = 0\n",
    "for text in df['Text'].values:\n",
    "    len_txt = len(tokenizer.encode(text, add_special_tokens=True))\n",
    "    max_len = max(max_len, len_txt)\n",
    "print('Max sentence length: ', max_len)\n",
    "\n",
    "# construct the input for the training phase\n",
    "text_train = dftrain['Text'].values # Use appropriate column names\n",
    "labels_train = dftrain['Target'].values\n",
    "Input_ids_train, Attention_masks_train = toke_and_enc(text_train, max_len)\n",
    "labels_train = torch.tensor(labels_train)\n",
    "Train_dataset = TensorDataset(Input_ids_train, Attention_masks_train, labels_train)\n",
    "model_train = train_model(Train_dataset, num_labels = 2)\n",
    "# Save model (optional)\n",
    "model_train.save_pretrained('model_'+str(target)) # Uncomment to save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model on the training data set to collect stat and output\n",
    "print('Training result')\n",
    "trainpred, trainactual = test_model(Train_dataset, model_train)\n",
    "train_pred, train_actual  = calculate_stat(trainpred, trainactual)\n",
    "dftrain['Mpred'] = train_pred\n",
    "dftrain['Mactual'] = train_actual\n",
    "dftrain.to_csv('outtrain_'+str(target)+'.csv', encoding='utf-8')\n",
    "print()\n",
    "\n",
    "# Run the model on the test data set to collect stat and output\n",
    "print('Testing result')\n",
    "text_test = dftest['Text'].values\n",
    "labels_test = dftest['Target'].values\n",
    "Input_ids_test, Attention_masks_test = toke_and_enc(text_test, max_len)\n",
    "labels_test = torch.tensor(labels_test)\n",
    "Test_dataset = TensorDataset(Input_ids_test, Attention_masks_test, labels_test)\n",
    "testpred, testactual = test_model(Test_dataset, model_train)\n",
    "test_pred, test_actual  = calculate_stat(testpred, testactual)\n",
    "dftest['Mpred'] = test_pred\n",
    "dftest['Mactual'] = test_actual\n",
    "dftest.to_csv('outtest_'+str(target)+'.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (mengwei)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
