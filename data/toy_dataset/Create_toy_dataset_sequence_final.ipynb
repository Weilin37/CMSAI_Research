{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic dataset generation -- Sequence based\n",
    "**Author: Lin Lee Cheong <br>\n",
    "Updated by: Tesfagabir Meharizghi<br>\n",
    "Date created: 12/12/ 2020 <br>\n",
    "Date updated: 02/04/2021 <br>**\n",
    "\n",
    "Goal of this synthetic dataset is to create datasets to help understand how different relationships between tokens affect attention, SHAP and other interpretability factors.\n",
    "- length of events (30, 300)\n",
    "- spacing between 2+ coupled events, i.e. order of sequence matters\n",
    "- amount of noise, i.e. performance vs interpretability\n",
    "- vocabulary space\n",
    "\n",
    "### Sequence dataset\n",
    "\n",
    "Positive label is driven by a sequence of tokens\n",
    "- Positive set sequence and their probability\n",
    "\n",
    "Unhelper(U) -> Helper(H) -> Adverse(A) ==> 99%<br>\n",
    "Unhelper(U) -> Adverse(A) -> Helper(H) ==> 80%<br>\n",
    "Helper(H) -> Unhelper(H) -> Adverse(A) ==> 60%<br>\n",
    "Adverse(A) -> Unhelper(H) -> Helper(H) ==> 40%<br>\n",
    "Helper(H) -> Adverse(A) -> Unhelper(U) ==> 20%<br>\n",
    "Adverse(A) -> Helper(H) -> Unhelper(U) ==> 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lab_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext lab_black\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext lab_black\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import string\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_NAMES_FP = \"./tokens_v2.yaml\"\n",
    "\n",
    "SEQ_LEN = 300\n",
    "\n",
    "TRAIN_FP = \"data/seq_final_v2/{}/train.csv\".format(SEQ_LEN)\n",
    "VAL_FP = \"data/seq_final_v2/{}/val.csv\".format(SEQ_LEN)\n",
    "TEST_FP = \"data/seq_final_v2/{}/test.csv\".format(SEQ_LEN)\n",
    "\n",
    "UID_COLNAME = \"patient_id\"\n",
    "\n",
    "TRAIN_NROWS = 3000  # 18000\n",
    "VAL_NROWS = 1000  # 6000\n",
    "TEST_NROWS = 1000  # 6000\n",
    "\n",
    "UID_LEN = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adverse_tokens: 10 tokens\n",
      "adverse_helper_tokens: 10 tokens\n",
      "adverse_unhelper_tokens: 10 tokens\n",
      "noise_tokens: 15 tokens\n"
     ]
    }
   ],
   "source": [
    "# Load tokens from yaml file path\n",
    "tokens = load_tokens(TOKEN_NAMES_FP)\n",
    "for key in tokens.keys():\n",
    "    print(f\"{key}: {len(tokens[key])} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adverse_tokens\n",
      "['Acute_Myocardial_Infarction_A', 'hypertension_A', 'arrhythmia_A', 'congestive_heart_failure_A', 'heart_valve_failure_A', 'pulmonary_embolism_A', 'ventricular_aneurysm_A', 'ventricular_hypertrophy_A', 'cardiomyopathy_A', 'Chronic_Obstructive_Pulmonary_Disease_A']\n",
      "--------------------------------------------------\n",
      "adverse_helper_tokens\n",
      "['sleep_apnea_H', 'pneumonia_H', 'coronary_artery_disease_H', 'edema_H', 'troponin_H', 'Brain_Natriuretic_Peptide_H', 'alchoholism_H', 'metabolic_disorder_H', 'elevated_creatinine_H', 'electrolyte_imbalance_H']\n",
      "--------------------------------------------------\n",
      "adverse_unhelper_tokens\n",
      "['percutaneous_coronary_intervention_U (PCI_U)', 'electrical_cardioversion_U', 'catheter_ablation_U', 'pacemaker_U', 'pacemaker_U', 'sleep_apnea_treatment_U', 'ACE_inhibitors_U', 'ARB_U', 'diuretics_U', 'beta_blockers_U']\n",
      "--------------------------------------------------\n",
      "noise_tokens\n",
      "['eye_exam_N', 'annual_physical_N', 'hay_fever_N', 'headache_N', 'foot_pain_N', 'backache_N', 'cold_sore_N', 'myopia_N', 'cut_finger_N', 'ankle_sprain_N', 'ACL_tear_N', 'quad_injury_N', 'dental_exam_N', 'ingrown_nail_N', 'peanut_allergy_N']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for key, tok in tokens.items():\n",
    "    print(key)\n",
    "    print(tok)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#pos: 9000.0, #neg: 9000.0\n"
     ]
    }
   ],
   "source": [
    "x = TRAIN_NROWS\n",
    "total = x * 6\n",
    "pos_lab = x * 0.99 + x * 0.8 + x * 0.6 + x * 0.4 + x * 0.2 + x * 0.01\n",
    "neg_lab = total - pos_lab\n",
    "print(f\"#pos: {pos_lab}, #neg: {neg_lab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key--> sequence of adverse(A), helper(H), and unhelper(U)\n",
    "# tuple --> (probability of positive label, number of rows)\n",
    "train_count_dict = {\n",
    "    \"UHA\": (0.99, TRAIN_NROWS),\n",
    "    \"UAH\": (0.80, TRAIN_NROWS),\n",
    "    \"HUA\": (0.60, TRAIN_NROWS),\n",
    "    \"AUH\": (0.40, TRAIN_NROWS),\n",
    "    \"HAU\": (0.20, TRAIN_NROWS),\n",
    "    \"AHU\": (0.01, TRAIN_NROWS),\n",
    "}\n",
    "\n",
    "val_count_dict = {\n",
    "    \"UHA\": (0.99, VAL_NROWS),\n",
    "    \"UAH\": (0.80, VAL_NROWS),\n",
    "    \"HUA\": (0.60, VAL_NROWS),\n",
    "    \"AUH\": (0.40, VAL_NROWS),\n",
    "    \"HAU\": (0.20, VAL_NROWS),\n",
    "    \"AHU\": (0.01, VAL_NROWS),\n",
    "}\n",
    "\n",
    "test_count_dict = {\n",
    "    \"UHA\": (0.99, TEST_NROWS),\n",
    "    \"UAH\": (0.80, TEST_NROWS),\n",
    "    \"HUA\": (0.60, TEST_NROWS),\n",
    "    \"AUH\": (0.40, TEST_NROWS),\n",
    "    \"HAU\": (0.20, TEST_NROWS),\n",
    "    \"AHU\": (0.01, TEST_NROWS),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mappings of the token groups with the abbreviation\n",
    "token_mappings = {\n",
    "    \"A\": \"adverse_tokens\",\n",
    "    \"H\": \"adverse_helper_tokens\",\n",
    "    \"U\": \"adverse_unhelper_tokens\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token abbreviations and token groups\n",
    "token_mappings = {\n",
    "    \"A\": \"adverse_tokens\",\n",
    "    \"H\": \"adverse_helper_tokens\",\n",
    "    \"U\": \"adverse_unhelper_tokens\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_sequence_seq_v2(seq_len, label, tokens, proba, token_mappings, seq_tokens):\n",
    "    \"\"\"creates sequence + label (at the end of list) with specific orderings.\n",
    "    returns list of list\"\"\"\n",
    "    n_seq_tokens = len(seq_tokens)\n",
    "    n_noise = (\n",
    "        np.max(\n",
    "            (\n",
    "                10,\n",
    "                random.choices(range(n_seq_tokens, seq_len), k=1)[0],\n",
    "            )\n",
    "        )\n",
    "        - (n_seq_tokens)\n",
    "    )\n",
    "    sel_positions = sorted(random.sample(range(n_noise), k=n_seq_tokens))\n",
    "    sel_tokens = []\n",
    "    for key in seq_tokens:\n",
    "        key_mapping = token_mappings[key]\n",
    "        sel_tokens.append(random.choices(tokens[key_mapping])[0])\n",
    "    sel_tokens = list(zip(sel_positions, sel_tokens))\n",
    "    sel_noise = get_tokens(seq_len, tokens, \"noise_tokens\", n_noise)\n",
    "\n",
    "    for idx, event in sel_tokens:\n",
    "        sel_noise.insert(idx, event)\n",
    "\n",
    "    sel_noise = [\"<pad>\"] * (seq_len - len(sel_noise)) + sel_noise\n",
    "    # sel_noise.reverse()\n",
    "    sim_lab = get_label(proba, target=label)\n",
    "\n",
    "    sequence = sel_noise + [sim_lab]\n",
    "\n",
    "    return sequence\n",
    "\n",
    "\n",
    "def get_sequences_v2(\n",
    "    seq_len,\n",
    "    label,\n",
    "    uid_len,\n",
    "    uid_colname,\n",
    "    tokens,\n",
    "    proba,\n",
    "    token_mappings,\n",
    "    seq_tokens,\n",
    "    n_seq,\n",
    "):\n",
    "    \"\"\"Get multiple sequences.\"\"\"\n",
    "\n",
    "    sequences = [\n",
    "        get_a_sequence_seq_v2(seq_len, label, tokens, proba, token_mappings, seq_tokens)\n",
    "        + [get_uid(uid_len)]\n",
    "        for _ in range(n_seq)\n",
    "    ]\n",
    "    print(f\"seq based events generated\")\n",
    "\n",
    "    seq_df = pd.DataFrame(sequences)\n",
    "    seq_df.columns = [str(x) for x in range(seq_len - 1, -1, -1)] + [\n",
    "        \"label\",\n",
    "        uid_colname,\n",
    "    ]\n",
    "\n",
    "    return seq_df\n",
    "\n",
    "\n",
    "def get_sequence_dataset(\n",
    "    seq_len, uid_len, uid_colname, count_dict, tokens, token_mappings\n",
    "):\n",
    "    \"\"\"Generate a simple toy dataset.\n",
    "\n",
    "    Arg:\n",
    "    -----\n",
    "        seq_len (int) : length of the generated sequence\n",
    "        uid_len (int) : length of uid token\n",
    "        uid_colname (str) : name of uid column, usually patient_id\n",
    "        count_dict (dict) : dictionary of various sequence types.\n",
    "            6 different types are allowed:\n",
    "                n_ppp_adverse, n_pp_adverse, n_p_adverse\n",
    "                n_nnn_adverse, n_nn_adverse, n_n_adverse\n",
    "        tokens (dict) : dictionary of the various token types\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        dataset (dataframe) : dataframe containing all the\n",
    "                              generated dataset, randomly mixed\n",
    "\n",
    "    \"\"\"\n",
    "    label = 1\n",
    "    cat_lst = []\n",
    "    for seq_tokens, (proba, n_seq) in count_dict.items():\n",
    "        df = get_sequences_v2(\n",
    "            seq_len,\n",
    "            label,\n",
    "            uid_len,\n",
    "            uid_colname,\n",
    "            tokens,\n",
    "            proba,\n",
    "            token_mappings,\n",
    "            seq_tokens,\n",
    "            n_seq,\n",
    "        )\n",
    "\n",
    "        df[\"seq_event\"] = seq_tokens\n",
    "        cat_lst.append(df.copy())\n",
    "    dataset = pd.concat(cat_lst, axis=0)\n",
    "    dataset.reset_index(inplace=True)\n",
    "    indexes = [idx for idx in range(dataset.shape[0])]\n",
    "    random.shuffle(indexes)\n",
    "    dataset = dataset.iloc[indexes, :]\n",
    "    # dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    print(f\"dataset: {dataset.shape}\")\n",
    "    print(f\"ratio:\\n{dataset.label.value_counts(normalize=True)}\\n\")\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq based events generated\n",
      "seq based events generated\n",
      "seq based events generated\n",
      "seq based events generated\n",
      "seq based events generated\n",
      "seq based events generated\n",
      "dataset: (18000, 304)\n",
      "ratio:\n",
      "0    0.502556\n",
      "1    0.497444\n",
      "Name: label, dtype: float64\n",
      "\n",
      "seq based events generated\n",
      "seq based events generated\n",
      "seq based events generated\n",
      "seq based events generated\n",
      "seq based events generated\n",
      "seq based events generated\n",
      "dataset: (6000, 304)\n",
      "ratio:\n",
      "0    0.502667\n",
      "1    0.497333\n",
      "Name: label, dtype: float64\n",
      "\n",
      "seq based events generated\n",
      "seq based events generated\n",
      "seq based events generated\n",
      "seq based events generated\n",
      "seq based events generated\n",
      "seq based events generated\n",
      "dataset: (6000, 304)\n",
      "ratio:\n",
      "0    0.500333\n",
      "1    0.499667\n",
      "Name: label, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train = get_sequence_dataset(\n",
    "    seq_len=SEQ_LEN,\n",
    "    uid_len=UID_LEN,\n",
    "    uid_colname=UID_COLNAME,\n",
    "    count_dict=train_count_dict,\n",
    "    tokens=tokens,\n",
    "    token_mappings=token_mappings,\n",
    ")\n",
    "\n",
    "df_val = get_sequence_dataset(\n",
    "    seq_len=SEQ_LEN,\n",
    "    uid_len=UID_LEN,\n",
    "    uid_colname=UID_COLNAME,\n",
    "    count_dict=val_count_dict,\n",
    "    tokens=tokens,\n",
    "    token_mappings=token_mappings,\n",
    ")\n",
    "\n",
    "df_test = get_sequence_dataset(\n",
    "    seq_len=SEQ_LEN,\n",
    "    uid_len=UID_LEN,\n",
    "    uid_colname=UID_COLNAME,\n",
    "    count_dict=test_count_dict,\n",
    "    tokens=tokens,\n",
    "    token_mappings=token_mappings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 304)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>299</th>\n",
       "      <th>298</th>\n",
       "      <th>297</th>\n",
       "      <th>296</th>\n",
       "      <th>295</th>\n",
       "      <th>294</th>\n",
       "      <th>293</th>\n",
       "      <th>292</th>\n",
       "      <th>291</th>\n",
       "      <th>...</th>\n",
       "      <th>6</th>\n",
       "      <th>5</th>\n",
       "      <th>4</th>\n",
       "      <th>3</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>label</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>seq_event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11750</th>\n",
       "      <td>2750</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>foot_pain_N</td>\n",
       "      <td>ACL_tear_N</td>\n",
       "      <td>backache_N</td>\n",
       "      <td>backache_N</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>annual_physical_N</td>\n",
       "      <td>0</td>\n",
       "      <td>WZ43OZQ4CU</td>\n",
       "      <td>AUH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6377</th>\n",
       "      <td>377</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>pacemaker_U</td>\n",
       "      <td>pulmonary_embolism_A</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>ankle_sprain_N</td>\n",
       "      <td>backache_N</td>\n",
       "      <td>headache_N</td>\n",
       "      <td>0</td>\n",
       "      <td>LEJOOHMUV9</td>\n",
       "      <td>HUA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14948</th>\n",
       "      <td>2948</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>cut_finger_N</td>\n",
       "      <td>eye_exam_N</td>\n",
       "      <td>annual_physical_N</td>\n",
       "      <td>ACL_tear_N</td>\n",
       "      <td>myopia_N</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>quad_injury_N</td>\n",
       "      <td>0</td>\n",
       "      <td>BL7L1RRQTH</td>\n",
       "      <td>HAU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17150</th>\n",
       "      <td>2150</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>hay_fever_N</td>\n",
       "      <td>ankle_sprain_N</td>\n",
       "      <td>annual_physical_N</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>ACL_tear_N</td>\n",
       "      <td>backache_N</td>\n",
       "      <td>0</td>\n",
       "      <td>03K19M3DRP</td>\n",
       "      <td>AHU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717</th>\n",
       "      <td>717</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>peanut_allergy_N</td>\n",
       "      <td>ankle_sprain_N</td>\n",
       "      <td>ankle_sprain_N</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>myopia_N</td>\n",
       "      <td>peanut_allergy_N</td>\n",
       "      <td>quad_injury_N</td>\n",
       "      <td>0</td>\n",
       "      <td>QAG79HLPXH</td>\n",
       "      <td>UAH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index    299    298    297    296    295    294    293    292    291  \\\n",
       "11750   2750  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>   \n",
       "6377     377  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>   \n",
       "14948   2948  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>   \n",
       "17150   2150  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>   \n",
       "3717     717  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>   \n",
       "\n",
       "       ...                 6                     5                  4  \\\n",
       "11750  ...    ingrown_nail_N           foot_pain_N         ACL_tear_N   \n",
       "6377   ...       pacemaker_U  pulmonary_embolism_A     ingrown_nail_N   \n",
       "14948  ...      cut_finger_N            eye_exam_N  annual_physical_N   \n",
       "17150  ...    ingrown_nail_N           hay_fever_N     ankle_sprain_N   \n",
       "3717   ...  peanut_allergy_N        ankle_sprain_N     ankle_sprain_N   \n",
       "\n",
       "                       3               2                 1                  0  \\\n",
       "11750         backache_N      backache_N    ingrown_nail_N  annual_physical_N   \n",
       "6377      ingrown_nail_N  ankle_sprain_N        backache_N         headache_N   \n",
       "14948         ACL_tear_N        myopia_N    ingrown_nail_N      quad_injury_N   \n",
       "17150  annual_physical_N  ingrown_nail_N        ACL_tear_N         backache_N   \n",
       "3717      ingrown_nail_N        myopia_N  peanut_allergy_N      quad_injury_N   \n",
       "\n",
       "      label  patient_id seq_event  \n",
       "11750     0  WZ43OZQ4CU       AUH  \n",
       "6377      0  LEJOOHMUV9       HUA  \n",
       "14948     0  BL7L1RRQTH       HAU  \n",
       "17150     0  03K19M3DRP       AHU  \n",
       "3717      0  QAG79HLPXH       UAH  \n",
       "\n",
       "[5 rows x 304 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2959\n",
       "0      41\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train[\"seq_event\"] == \"UHA\"][\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                 661\n",
       "299                 <pad>\n",
       "298                 <pad>\n",
       "297                 <pad>\n",
       "296                 <pad>\n",
       "                 ...     \n",
       "1             hay_fever_N\n",
       "0              ACL_tear_N\n",
       "label                   1\n",
       "patient_id     7IP3BT44VF\n",
       "seq_event             UHA\n",
       "Name: 661, Length: 304, dtype: object"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train[\"seq_event\"] == \"UHA\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AHU    3000\n",
       "UAH    3000\n",
       "UHA    3000\n",
       "AUH    3000\n",
       "HAU    3000\n",
       "HUA    3000\n",
       "Name: seq_event, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.seq_event.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv(df_train, TRAIN_FP)\n",
    "save_csv(df_val, VAL_FP)\n",
    "save_csv(df_test, TEST_FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 304)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>299</th>\n",
       "      <th>298</th>\n",
       "      <th>297</th>\n",
       "      <th>296</th>\n",
       "      <th>295</th>\n",
       "      <th>294</th>\n",
       "      <th>293</th>\n",
       "      <th>292</th>\n",
       "      <th>291</th>\n",
       "      <th>...</th>\n",
       "      <th>6</th>\n",
       "      <th>5</th>\n",
       "      <th>4</th>\n",
       "      <th>3</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>label</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>seq_event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2750</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>foot_pain_N</td>\n",
       "      <td>ACL_tear_N</td>\n",
       "      <td>backache_N</td>\n",
       "      <td>backache_N</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>annual_physical_N</td>\n",
       "      <td>0</td>\n",
       "      <td>WZ43OZQ4CU</td>\n",
       "      <td>AUH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>377</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>pacemaker_U</td>\n",
       "      <td>pulmonary_embolism_A</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>ankle_sprain_N</td>\n",
       "      <td>backache_N</td>\n",
       "      <td>headache_N</td>\n",
       "      <td>0</td>\n",
       "      <td>LEJOOHMUV9</td>\n",
       "      <td>HUA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2948</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>cut_finger_N</td>\n",
       "      <td>eye_exam_N</td>\n",
       "      <td>annual_physical_N</td>\n",
       "      <td>ACL_tear_N</td>\n",
       "      <td>myopia_N</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>quad_injury_N</td>\n",
       "      <td>0</td>\n",
       "      <td>BL7L1RRQTH</td>\n",
       "      <td>HAU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2150</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>hay_fever_N</td>\n",
       "      <td>ankle_sprain_N</td>\n",
       "      <td>annual_physical_N</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>ACL_tear_N</td>\n",
       "      <td>backache_N</td>\n",
       "      <td>0</td>\n",
       "      <td>03K19M3DRP</td>\n",
       "      <td>AHU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>717</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>peanut_allergy_N</td>\n",
       "      <td>ankle_sprain_N</td>\n",
       "      <td>ankle_sprain_N</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>myopia_N</td>\n",
       "      <td>peanut_allergy_N</td>\n",
       "      <td>quad_injury_N</td>\n",
       "      <td>0</td>\n",
       "      <td>QAG79HLPXH</td>\n",
       "      <td>UAH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    299    298    297    296    295    294    293    292    291  ...  \\\n",
       "0   2750  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  ...   \n",
       "1    377  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  ...   \n",
       "2   2948  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  ...   \n",
       "3   2150  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  ...   \n",
       "4    717  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  ...   \n",
       "\n",
       "                  6                     5                  4  \\\n",
       "0    ingrown_nail_N           foot_pain_N         ACL_tear_N   \n",
       "1       pacemaker_U  pulmonary_embolism_A     ingrown_nail_N   \n",
       "2      cut_finger_N            eye_exam_N  annual_physical_N   \n",
       "3    ingrown_nail_N           hay_fever_N     ankle_sprain_N   \n",
       "4  peanut_allergy_N        ankle_sprain_N     ankle_sprain_N   \n",
       "\n",
       "                   3               2                 1                  0  \\\n",
       "0         backache_N      backache_N    ingrown_nail_N  annual_physical_N   \n",
       "1     ingrown_nail_N  ankle_sprain_N        backache_N         headache_N   \n",
       "2         ACL_tear_N        myopia_N    ingrown_nail_N      quad_injury_N   \n",
       "3  annual_physical_N  ingrown_nail_N        ACL_tear_N         backache_N   \n",
       "4     ingrown_nail_N        myopia_N  peanut_allergy_N      quad_injury_N   \n",
       "\n",
       "  label  patient_id seq_event  \n",
       "0     0  WZ43OZQ4CU       AUH  \n",
       "1     0  LEJOOHMUV9       HUA  \n",
       "2     0  BL7L1RRQTH       HAU  \n",
       "3     0  03K19M3DRP       AHU  \n",
       "4     0  QAG79HLPXH       UAH  \n",
       "\n",
       "[5 rows x 304 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(TRAIN_FP)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.502556\n",
       "1    0.497444\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
