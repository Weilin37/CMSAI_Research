{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic dataset generation -- Sequence based\n",
    "**Author: Lin Lee Cheong <br>\n",
    "Updated by: Tesfagabir Meharizghi<br>\n",
    "Date created: 12/12/ 2020 <br>\n",
    "Date updated: 02/18/2021 <br>**\n",
    "\n",
    "Goal of this synthetic dataset is to create datasets to help understand how different relationships between tokens affect attention, SHAP and other interpretability factors.\n",
    "- length of events (30, 300)\n",
    "- spacing between 2+ coupled events, i.e. order of sequence matters\n",
    "- amount of noise, i.e. performance vs interpretability\n",
    "- vocabulary space\n",
    "\n",
    "### Sequence dataset\n",
    "\n",
    "Positive label is driven by a sequence of tokens\n",
    "- Positive label probability is driven by the following formula\n",
    "``` min(1.0, math.exp(-(a * ta)) + math.exp(-(h * th)) - math.exp(-(u * tu))) ```\n",
    "Where:\n",
    "- `a` is a constant related to `_A` events. It is the inverse of the contribution of `_A` events for positive label\n",
    "- `h` is a constant related to `_H` events. It is the inverse of the contribution of `_H` events for positive label\n",
    "- `u` is a constant related to `_U` events. It is the inverse of the contribution of `_U` events for positive label\n",
    "\n",
    "- `ta` is the absolute position of the `_A` event in the sequence from the end.\n",
    "- `th` is the absolute position of the `_H` event in the sequence from the end.\n",
    "- `tu` is the absolute position of the `_U` event in the sequence from the end.\n",
    "\n",
    "Note:\n",
    "- All patients have one `_A`, one `_H` and one `_U` events each.\n",
    "- since `_U` events have opposite effect to the adverse event, their contribution is subtracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lab_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext lab_black\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext lab_black\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import string\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_NAMES_FP = \"./tokens_v2.yaml\"\n",
    "\n",
    "SEQ_LEN = 300\n",
    "\n",
    "TRAIN_FP = \"data/seq_final_v3/{}/train.csv\".format(SEQ_LEN)\n",
    "VAL_FP = \"data/seq_final_v3/{}/val.csv\".format(SEQ_LEN)\n",
    "TEST_FP = \"data/seq_final_v3/{}/test.csv\".format(SEQ_LEN)\n",
    "\n",
    "UID_COLNAME = \"patient_id\"\n",
    "\n",
    "TRAIN_NROWS = 4000\n",
    "VAL_NROWS = 2000\n",
    "TEST_NROWS = 2000\n",
    "\n",
    "UID_LEN = 10\n",
    "\n",
    "# Total patients in the each split (will be balanced)\n",
    "TOTAL_TRAIN = 18000\n",
    "TOTAL_VAL = 6000\n",
    "TOTAL_TEST = 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adverse_tokens: 10 tokens\n",
      "adverse_helper_tokens: 10 tokens\n",
      "adverse_unhelper_tokens: 10 tokens\n",
      "noise_tokens: 15 tokens\n"
     ]
    }
   ],
   "source": [
    "# Load tokens from yaml file path\n",
    "tokens = load_tokens(TOKEN_NAMES_FP)\n",
    "for key in tokens.keys():\n",
    "    print(f\"{key}: {len(tokens[key])} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adverse_tokens\n",
      "['Acute_Myocardial_Infarction_A', 'hypertension_A', 'arrhythmia_A', 'congestive_heart_failure_A', 'heart_valve_failure_A', 'pulmonary_embolism_A', 'ventricular_aneurysm_A', 'ventricular_hypertrophy_A', 'cardiomyopathy_A', 'Chronic_Obstructive_Pulmonary_Disease_A']\n",
      "--------------------------------------------------\n",
      "adverse_helper_tokens\n",
      "['sleep_apnea_H', 'pneumonia_H', 'coronary_artery_disease_H', 'edema_H', 'troponin_H', 'Brain_Natriuretic_Peptide_H', 'alchoholism_H', 'metabolic_disorder_H', 'elevated_creatinine_H', 'electrolyte_imbalance_H']\n",
      "--------------------------------------------------\n",
      "adverse_unhelper_tokens\n",
      "['Percutaneous_Coronary_Intervention_U', 'electrical_cardioversion_U', 'catheter_ablation_U', 'pacemaker_U', 'cardiac_rehab_U', 'sleep_apnea_treatment_U', 'ACE_inhibitors_U', 'ARB_U', 'diuretics_U', 'beta_blockers_U']\n",
      "--------------------------------------------------\n",
      "noise_tokens\n",
      "['eye_exam_N', 'annual_physical_N', 'hay_fever_N', 'headache_N', 'foot_pain_N', 'backache_N', 'cold_sore_N', 'myopia_N', 'cut_finger_N', 'ankle_sprain_N', 'ACL_tear_N', 'quad_injury_N', 'dental_exam_N', 'ingrown_nail_N', 'peanut_allergy_N']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for key, tok in tokens.items():\n",
    "    print(key)\n",
    "    print(tok)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = TRAIN_NROWS\n",
    "# total = x * 6\n",
    "# pos_lab = x * 0.99 + x * 0.8 + x * 0.6 + x * 0.4 + x * 0.2 + x * 0.01\n",
    "# neg_lab = total - pos_lab\n",
    "# print(f\"#pos: {pos_lab}, #neg: {neg_lab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key--> sequence of adverse(A), helper(H), and unhelper(U)\n",
    "# tuple --> (probability of positive label, number of rows)\n",
    "train_count_dict = {\n",
    "    \"UHA\": TRAIN_NROWS,\n",
    "    \"UAH\": TRAIN_NROWS,\n",
    "    \"HUA\": TRAIN_NROWS,\n",
    "    \"AUH\": TRAIN_NROWS,\n",
    "    \"HAU\": TRAIN_NROWS,\n",
    "    \"AHU\": TRAIN_NROWS,\n",
    "}\n",
    "\n",
    "val_count_dict = {\n",
    "    \"UHA\": VAL_NROWS,\n",
    "    \"UAH\": VAL_NROWS,\n",
    "    \"HUA\": VAL_NROWS,\n",
    "    \"AUH\": VAL_NROWS,\n",
    "    \"HAU\": VAL_NROWS,\n",
    "    \"AHU\": VAL_NROWS,\n",
    "}\n",
    "\n",
    "test_count_dict = {\n",
    "    \"UHA\": TEST_NROWS,\n",
    "    \"UAH\": TEST_NROWS,\n",
    "    \"HUA\": TEST_NROWS,\n",
    "    \"AUH\": TEST_NROWS,\n",
    "    \"HAU\": TEST_NROWS,\n",
    "    \"AHU\": TEST_NROWS,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mappings of the token groups with the abbreviation\n",
    "token_mappings = {\n",
    "    \"A\": \"adverse_tokens\",\n",
    "    \"H\": \"adverse_helper_tokens\",\n",
    "    \"U\": \"adverse_unhelper_tokens\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(df0, label, total):\n",
    "    \"\"\"Downsample the dataset to make it balanced class.\"\"\"\n",
    "    df = df0.copy()\n",
    "    df_c0 = df[df[label] == 0]\n",
    "    df_c1 = df[df[label] == 1]\n",
    "\n",
    "    df_c0 = df_c0.sample(int(total / 2))\n",
    "    df_c1 = df_c1.sample(int(total / 2))\n",
    "\n",
    "    df = pd.concat([df_c0, df_c1], axis=0)\n",
    "    df = df.sample(frac=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_proba(seq, base_seq_len=30):\n",
    "    \"\"\"Get probability of being positive label for a sequence.\"\"\"\n",
    "\n",
    "    def get_position(seq, substring, base_seq_len):\n",
    "        \"\"\"Get position of event with substring from end of sequence\"\"\"\n",
    "        pos = -1\n",
    "        for i, event in enumerate(seq):\n",
    "            if event.endswith(substring):\n",
    "                pos = i\n",
    "                break\n",
    "        if pos == -1:\n",
    "            raise ValueError(f\"Error! {substring} not found!\")\n",
    "\n",
    "        pos = len(seq) - pos - 1\n",
    "        return pos\n",
    "\n",
    "        a = 0.1  # Constant for Adverse\n",
    "        h = 0.5  # Constant for helper\n",
    "        u = 0.95  # Constant for unhelper\n",
    "\n",
    "    #     a = 0.03  # Constant for Adverse\n",
    "    #     h = 0.05  # Constant for helper\n",
    "    #     u = 0.09  # Constant for unhelper\n",
    "\n",
    "    seq_len = len(seq)\n",
    "    multiplier = float(base_seq_len) / seq_len\n",
    "    ta = get_position(seq, \"_A\", base_seq_len) * multiplier\n",
    "    th = get_position(seq, \"_H\", base_seq_len) * multiplier\n",
    "    tu = get_position(seq, \"_U\", base_seq_len) * multiplier\n",
    "\n",
    "    prob = min(1.0, math.exp(-(a * ta)) + math.exp(-(h * th)) - math.exp(-(u * tu)))\n",
    "    prob = round(prob, 4)\n",
    "    return prob\n",
    "\n",
    "\n",
    "def get_a_sequence_seq_v2(seq_len, label, tokens, token_mappings, seq_tokens):\n",
    "    \"\"\"creates sequence + label (at the end of list) with specific orderings.\n",
    "    returns list of list\"\"\"\n",
    "    n_seq_tokens = len(seq_tokens)\n",
    "    n_noise = (\n",
    "        np.max(\n",
    "            (\n",
    "                10,\n",
    "                random.choices(range(n_seq_tokens, seq_len), k=1)[0],\n",
    "            )\n",
    "        )\n",
    "        - (n_seq_tokens)\n",
    "    )\n",
    "    sel_positions = sorted(random.sample(range(n_noise), k=n_seq_tokens))\n",
    "    sel_tokens = []\n",
    "    for key in seq_tokens:\n",
    "        key_mapping = token_mappings[key]\n",
    "        sel_tokens.append(random.choices(tokens[key_mapping])[0])\n",
    "    sel_tokens = list(zip(sel_positions, sel_tokens))\n",
    "    sel_noise = get_tokens(seq_len, tokens, \"noise_tokens\", n_noise)\n",
    "\n",
    "    for idx, event in sel_tokens:\n",
    "        sel_noise.insert(idx, event)\n",
    "\n",
    "    sel_noise = [\"<pad>\"] * (seq_len - len(sel_noise)) + sel_noise\n",
    "\n",
    "    # Get probability of being positive label\n",
    "    proba = get_proba(sel_noise)\n",
    "    # sel_noise.reverse()\n",
    "    sim_lab = get_label(proba, target=label)\n",
    "\n",
    "    sequence = sel_noise + [proba] + [sim_lab]\n",
    "\n",
    "    return sequence\n",
    "\n",
    "\n",
    "def get_sequences_v2(\n",
    "    seq_len,\n",
    "    label,\n",
    "    uid_len,\n",
    "    uid_colname,\n",
    "    tokens,\n",
    "    token_mappings,\n",
    "    seq_tokens,\n",
    "    n_seq,\n",
    "):\n",
    "    \"\"\"Get multiple sequences.\"\"\"\n",
    "\n",
    "    sequences = [\n",
    "        get_a_sequence_seq_v2(seq_len, label, tokens, token_mappings, seq_tokens)\n",
    "        + [get_uid(uid_len)]\n",
    "        for _ in range(n_seq)\n",
    "    ]\n",
    "    # print(f\"seq based events generated\")\n",
    "\n",
    "    seq_df = pd.DataFrame(sequences)\n",
    "    seq_df.columns = [str(x) for x in range(seq_len - 1, -1, -1)] + [\n",
    "        \"proba\",\n",
    "        \"label\",\n",
    "        uid_colname,\n",
    "    ]\n",
    "\n",
    "    return seq_df\n",
    "\n",
    "\n",
    "def get_sequence_dataset(\n",
    "    seq_len, uid_len, uid_colname, count_dict, tokens, token_mappings, total_rows\n",
    "):\n",
    "    \"\"\"Generate a simple toy dataset.\n",
    "\n",
    "    Arg:\n",
    "    -----\n",
    "        seq_len (int) : length of the generated sequence\n",
    "        uid_len (int) : length of uid token\n",
    "        uid_colname (str) : name of uid column, usually patient_id\n",
    "        count_dict (dict) : dictionary of various sequence types.\n",
    "            6 different types are allowed:\n",
    "                n_ppp_adverse, n_pp_adverse, n_p_adverse\n",
    "                n_nnn_adverse, n_nn_adverse, n_n_adverse\n",
    "        tokens (dict) : dictionary of the various token types\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        dataset (dataframe) : dataframe containing all the\n",
    "                              generated dataset, randomly mixed\n",
    "\n",
    "    \"\"\"\n",
    "    label = 1\n",
    "    cat_lst = []\n",
    "    for seq_tokens, n_seq in count_dict.items():\n",
    "        df = get_sequences_v2(\n",
    "            seq_len,\n",
    "            label,\n",
    "            uid_len,\n",
    "            uid_colname,\n",
    "            tokens,\n",
    "            token_mappings,\n",
    "            seq_tokens,\n",
    "            n_seq,\n",
    "        )\n",
    "\n",
    "        df[\"seq_event\"] = seq_tokens\n",
    "        cat_lst.append(df.copy())\n",
    "    dataset = pd.concat(cat_lst, axis=0)\n",
    "    dataset.reset_index(inplace=True)\n",
    "    indexes = [idx for idx in range(dataset.shape[0])]\n",
    "    random.shuffle(indexes)\n",
    "    dataset = dataset.iloc[indexes, :]\n",
    "    # dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    dataset = downsample(dataset, \"label\", total_rows)\n",
    "    print(f\"dataset: {dataset.shape}\")\n",
    "    print(f\"ratio:\\n{dataset.label.value_counts(normalize=True)}\\n\")\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Imbalance for seq_len=300...\n",
      "dataset: (18000, 305)\n",
      "ratio:\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: label, dtype: float64\n",
      "\n",
      "Val Data Imbalance for seq_len=300...\n",
      "dataset: (6000, 305)\n",
      "ratio:\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: label, dtype: float64\n",
      "\n",
      "Test Data Imbalance for seq_len=300...\n",
      "dataset: (6000, 305)\n",
      "ratio:\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: label, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Data Imbalance for seq_len={SEQ_LEN}...\")\n",
    "df_train = get_sequence_dataset(\n",
    "    seq_len=SEQ_LEN,\n",
    "    uid_len=UID_LEN,\n",
    "    uid_colname=UID_COLNAME,\n",
    "    count_dict=train_count_dict,\n",
    "    tokens=tokens,\n",
    "    token_mappings=token_mappings,\n",
    "    total_rows=TOTAL_TRAIN,\n",
    ")\n",
    "\n",
    "print(f\"Val Data Imbalance for seq_len={SEQ_LEN}...\")\n",
    "df_val = get_sequence_dataset(\n",
    "    seq_len=SEQ_LEN,\n",
    "    uid_len=UID_LEN,\n",
    "    uid_colname=UID_COLNAME,\n",
    "    count_dict=val_count_dict,\n",
    "    tokens=tokens,\n",
    "    token_mappings=token_mappings,\n",
    "    total_rows=TOTAL_VAL,\n",
    ")\n",
    "\n",
    "print(f\"Test Data Imbalance for seq_len={SEQ_LEN}...\")\n",
    "df_test = get_sequence_dataset(\n",
    "    seq_len=SEQ_LEN,\n",
    "    uid_len=UID_LEN,\n",
    "    uid_colname=UID_COLNAME,\n",
    "    count_dict=test_count_dict,\n",
    "    tokens=tokens,\n",
    "    token_mappings=token_mappings,\n",
    "    total_rows=TOTAL_TEST,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 305)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>299</th>\n",
       "      <th>298</th>\n",
       "      <th>297</th>\n",
       "      <th>296</th>\n",
       "      <th>295</th>\n",
       "      <th>294</th>\n",
       "      <th>293</th>\n",
       "      <th>292</th>\n",
       "      <th>291</th>\n",
       "      <th>...</th>\n",
       "      <th>5</th>\n",
       "      <th>4</th>\n",
       "      <th>3</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>proba</th>\n",
       "      <th>label</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>seq_event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8126</th>\n",
       "      <td>126</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>hay_fever_N</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>headache_N</td>\n",
       "      <td>annual_physical_N</td>\n",
       "      <td>quad_injury_N</td>\n",
       "      <td>myopia_N</td>\n",
       "      <td>0.7710</td>\n",
       "      <td>0</td>\n",
       "      <td>0KK1UGRDLC</td>\n",
       "      <td>HUA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17036</th>\n",
       "      <td>1036</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>headache_N</td>\n",
       "      <td>cold_sore_N</td>\n",
       "      <td>annual_physical_N</td>\n",
       "      <td>eye_exam_N</td>\n",
       "      <td>backache_N</td>\n",
       "      <td>quad_injury_N</td>\n",
       "      <td>0.6367</td>\n",
       "      <td>0</td>\n",
       "      <td>MIU7M8JI0L</td>\n",
       "      <td>HAU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3286</th>\n",
       "      <td>3286</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>cut_finger_N</td>\n",
       "      <td>ACL_tear_N</td>\n",
       "      <td>cold_sore_N</td>\n",
       "      <td>headache_N</td>\n",
       "      <td>cold_sore_N</td>\n",
       "      <td>backache_N</td>\n",
       "      <td>...</td>\n",
       "      <td>foot_pain_N</td>\n",
       "      <td>headache_N</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>hay_fever_N</td>\n",
       "      <td>cut_finger_N</td>\n",
       "      <td>cut_finger_N</td>\n",
       "      <td>0.2039</td>\n",
       "      <td>0</td>\n",
       "      <td>WFGDTDTDY5</td>\n",
       "      <td>UHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>418</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>hay_fever_N</td>\n",
       "      <td>eye_exam_N</td>\n",
       "      <td>myopia_N</td>\n",
       "      <td>quad_injury_N</td>\n",
       "      <td>ankle_sprain_N</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>C4T1HF7ISF</td>\n",
       "      <td>UHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13981</th>\n",
       "      <td>1981</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>ACL_tear_N</td>\n",
       "      <td>cut_finger_N</td>\n",
       "      <td>cut_finger_N</td>\n",
       "      <td>hay_fever_N</td>\n",
       "      <td>backache_N</td>\n",
       "      <td>eye_exam_N</td>\n",
       "      <td>0.3799</td>\n",
       "      <td>0</td>\n",
       "      <td>AL3WPUN3O9</td>\n",
       "      <td>AUH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index    299    298    297           296         295          294  \\\n",
       "8126     126  <pad>  <pad>  <pad>         <pad>       <pad>        <pad>   \n",
       "17036   1036  <pad>  <pad>  <pad>         <pad>       <pad>        <pad>   \n",
       "3286    3286  <pad>  <pad>  <pad>  cut_finger_N  ACL_tear_N  cold_sore_N   \n",
       "418      418  <pad>  <pad>  <pad>         <pad>       <pad>        <pad>   \n",
       "13981   1981  <pad>  <pad>  <pad>         <pad>       <pad>        <pad>   \n",
       "\n",
       "              293          292         291  ...               5  \\\n",
       "8126        <pad>        <pad>       <pad>  ...     hay_fever_N   \n",
       "17036       <pad>        <pad>       <pad>  ...      headache_N   \n",
       "3286   headache_N  cold_sore_N  backache_N  ...     foot_pain_N   \n",
       "418         <pad>        <pad>       <pad>  ...  ingrown_nail_N   \n",
       "13981       <pad>        <pad>       <pad>  ...      ACL_tear_N   \n",
       "\n",
       "                    4                  3                  2              1  \\\n",
       "8126   ingrown_nail_N         headache_N  annual_physical_N  quad_injury_N   \n",
       "17036     cold_sore_N  annual_physical_N         eye_exam_N     backache_N   \n",
       "3286       headache_N     ingrown_nail_N        hay_fever_N   cut_finger_N   \n",
       "418       hay_fever_N         eye_exam_N           myopia_N  quad_injury_N   \n",
       "13981    cut_finger_N       cut_finger_N        hay_fever_N     backache_N   \n",
       "\n",
       "                    0   proba label  patient_id seq_event  \n",
       "8126         myopia_N  0.7710     0  0KK1UGRDLC       HUA  \n",
       "17036   quad_injury_N  0.6367     0  MIU7M8JI0L       HAU  \n",
       "3286     cut_finger_N  0.2039     0  WFGDTDTDY5       UHA  \n",
       "418    ankle_sprain_N  1.0000     1  C4T1HF7ISF       UHA  \n",
       "13981      eye_exam_N  0.3799     0  AL3WPUN3O9       AUH  \n",
       "\n",
       "[5 rows x 305 columns]"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "# df_train.sort_values(\"proba\")[::-1]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1907\n",
       "0     869\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train[\"seq_event\"] == \"UHA\"][\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train[df_train[\"seq_event\"] == \"UHA\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AHU    3290\n",
       "HAU    3238\n",
       "AUH    2981\n",
       "HUA    2865\n",
       "UAH    2850\n",
       "UHA    2776\n",
       "Name: seq_event, dtype: int64"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.seq_event.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv(df_train, TRAIN_FP)\n",
    "save_csv(df_val, VAL_FP)\n",
    "save_csv(df_test, TEST_FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 305)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>299</th>\n",
       "      <th>298</th>\n",
       "      <th>297</th>\n",
       "      <th>296</th>\n",
       "      <th>295</th>\n",
       "      <th>294</th>\n",
       "      <th>293</th>\n",
       "      <th>292</th>\n",
       "      <th>291</th>\n",
       "      <th>...</th>\n",
       "      <th>5</th>\n",
       "      <th>4</th>\n",
       "      <th>3</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>proba</th>\n",
       "      <th>label</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>seq_event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>hay_fever_N</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>headache_N</td>\n",
       "      <td>annual_physical_N</td>\n",
       "      <td>quad_injury_N</td>\n",
       "      <td>myopia_N</td>\n",
       "      <td>0.7710</td>\n",
       "      <td>0</td>\n",
       "      <td>0KK1UGRDLC</td>\n",
       "      <td>HUA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1036</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>headache_N</td>\n",
       "      <td>cold_sore_N</td>\n",
       "      <td>annual_physical_N</td>\n",
       "      <td>eye_exam_N</td>\n",
       "      <td>backache_N</td>\n",
       "      <td>quad_injury_N</td>\n",
       "      <td>0.6367</td>\n",
       "      <td>0</td>\n",
       "      <td>MIU7M8JI0L</td>\n",
       "      <td>HAU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3286</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>cut_finger_N</td>\n",
       "      <td>ACL_tear_N</td>\n",
       "      <td>cold_sore_N</td>\n",
       "      <td>headache_N</td>\n",
       "      <td>cold_sore_N</td>\n",
       "      <td>backache_N</td>\n",
       "      <td>...</td>\n",
       "      <td>foot_pain_N</td>\n",
       "      <td>headache_N</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>hay_fever_N</td>\n",
       "      <td>cut_finger_N</td>\n",
       "      <td>cut_finger_N</td>\n",
       "      <td>0.2039</td>\n",
       "      <td>0</td>\n",
       "      <td>WFGDTDTDY5</td>\n",
       "      <td>UHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>418</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>hay_fever_N</td>\n",
       "      <td>eye_exam_N</td>\n",
       "      <td>myopia_N</td>\n",
       "      <td>quad_injury_N</td>\n",
       "      <td>ankle_sprain_N</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>C4T1HF7ISF</td>\n",
       "      <td>UHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1981</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>ACL_tear_N</td>\n",
       "      <td>cut_finger_N</td>\n",
       "      <td>cut_finger_N</td>\n",
       "      <td>hay_fever_N</td>\n",
       "      <td>backache_N</td>\n",
       "      <td>eye_exam_N</td>\n",
       "      <td>0.3799</td>\n",
       "      <td>0</td>\n",
       "      <td>AL3WPUN3O9</td>\n",
       "      <td>AUH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    299    298    297           296         295          294  \\\n",
       "0    126  <pad>  <pad>  <pad>         <pad>       <pad>        <pad>   \n",
       "1   1036  <pad>  <pad>  <pad>         <pad>       <pad>        <pad>   \n",
       "2   3286  <pad>  <pad>  <pad>  cut_finger_N  ACL_tear_N  cold_sore_N   \n",
       "3    418  <pad>  <pad>  <pad>         <pad>       <pad>        <pad>   \n",
       "4   1981  <pad>  <pad>  <pad>         <pad>       <pad>        <pad>   \n",
       "\n",
       "          293          292         291  ...               5               4  \\\n",
       "0       <pad>        <pad>       <pad>  ...     hay_fever_N  ingrown_nail_N   \n",
       "1       <pad>        <pad>       <pad>  ...      headache_N     cold_sore_N   \n",
       "2  headache_N  cold_sore_N  backache_N  ...     foot_pain_N      headache_N   \n",
       "3       <pad>        <pad>       <pad>  ...  ingrown_nail_N     hay_fever_N   \n",
       "4       <pad>        <pad>       <pad>  ...      ACL_tear_N    cut_finger_N   \n",
       "\n",
       "                   3                  2              1               0  \\\n",
       "0         headache_N  annual_physical_N  quad_injury_N        myopia_N   \n",
       "1  annual_physical_N         eye_exam_N     backache_N   quad_injury_N   \n",
       "2     ingrown_nail_N        hay_fever_N   cut_finger_N    cut_finger_N   \n",
       "3         eye_exam_N           myopia_N  quad_injury_N  ankle_sprain_N   \n",
       "4       cut_finger_N        hay_fever_N     backache_N      eye_exam_N   \n",
       "\n",
       "    proba label  patient_id seq_event  \n",
       "0  0.7710     0  0KK1UGRDLC       HUA  \n",
       "1  0.6367     0  MIU7M8JI0L       HAU  \n",
       "2  0.2039     0  WFGDTDTDY5       UHA  \n",
       "3  1.0000     1  C4T1HF7ISF       UHA  \n",
       "4  0.3799     0  AL3WPUN3O9       AUH  \n",
       "\n",
       "[5 rows x 305 columns]"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(TRAIN_FP)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "0    0.5\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
