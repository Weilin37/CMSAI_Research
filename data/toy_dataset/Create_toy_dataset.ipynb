{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic dataset generation\n",
    "Author: Lin Lee Cheong <br>\n",
    "Date: 12/12/ 2020 <br>\n",
    "\n",
    "Goal of this synthetic dataset is to create datasets to help understand how different relationships between tokens affect attention, SHAP and other interpretability factors.\n",
    "- length of events (30, 300, 900)\n",
    "- spacing between 2+ coupled events, i.e. order of sequence matters\n",
    "- amount of noise, i.e. performance vs interpretability\n",
    "- vocabulary space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install nb-black\n",
    "\n",
    "#! pip install botocore==1.12.201\n",
    "\n",
    "#! pip install shap\n",
    "#! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lab_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext lab_black\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext lab_black\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import string\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_NAMES_FP = \"./tokens.yaml\"\n",
    "\n",
    "SEQ_LEN = 900\n",
    "\n",
    "TRAIN_FP = \"data/{}/train.csv\".format(SEQ_LEN)\n",
    "VAL_FP = \"data/{}/val.csv\".format(SEQ_LEN)\n",
    "TEST_FP = \"data/{}/test.csv\".format(SEQ_LEN)\n",
    "\n",
    "UID_COLNAME = \"patient_id\"\n",
    "\n",
    "TRAIN_NROWS = 3000\n",
    "VAL_NROWS = 1000\n",
    "TEST_NROWS = 1000\n",
    "\n",
    "UID_LEN = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adverse_tokens: 4 tokens\n",
      "adverse_helper_tokens: 6 tokens\n",
      "adverse_unhelper_tokens: 5 tokens\n",
      "noise_tokens: 15 tokens\n"
     ]
    }
   ],
   "source": [
    "# Load tokens from yaml file path\n",
    "tokens = load_tokens(TOKEN_NAMES_FP)\n",
    "for key in tokens.keys():\n",
    "    print(f\"{key}: {len(tokens[key])} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get simple dataset:\n",
    "- positive set: (+++, 1 major + a helper), (++, 1 major), (+, 3 helper)\n",
    "- negative set: (---, 3 unhelper), (--, 1 helper + 2 unhelper), (-, 2 helper + 1 unhelper)\n",
    "\n",
    "\n",
    "**NOTES**<br>\n",
    "n_ppp_adverse = 2000 # 1 adverse event + 1 helper event <br>\n",
    "n_pp_adverse = 2000 # 1 adverse event <br>\n",
    "n_p_adverse = 2000 # 3 helper events <br><br>\n",
    "n_nnn_adverse = 2000 # 3 unhelper events <br>\n",
    "n_nn_adverse = 2000 # 1 helper + 2 unhelper <br>\n",
    "n_n_adverse = 2000 # 2 helper + 1 unhelper <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count_dict = {\n",
    "    \"n_ppp_adverse\": TRAIN_NROWS,\n",
    "    \"n_pp_adverse\": TRAIN_NROWS,\n",
    "    \"n_p_adverse\": TRAIN_NROWS,\n",
    "    \"n_nnn_adverse\": TRAIN_NROWS,\n",
    "    \"n_nn_adverse\": TRAIN_NROWS,\n",
    "    \"n_n_adverse\": TRAIN_NROWS,\n",
    "}\n",
    "\n",
    "val_count_dict = {\n",
    "    \"n_ppp_adverse\": VAL_NROWS,\n",
    "    \"n_pp_adverse\": VAL_NROWS,\n",
    "    \"n_p_adverse\": VAL_NROWS,\n",
    "    \"n_nnn_adverse\": VAL_NROWS,\n",
    "    \"n_nn_adverse\": VAL_NROWS,\n",
    "    \"n_n_adverse\": VAL_NROWS,\n",
    "}\n",
    "\n",
    "test_count_dict = {\n",
    "    \"n_ppp_adverse\": TEST_NROWS,\n",
    "    \"n_pp_adverse\": TEST_NROWS,\n",
    "    \"n_p_adverse\": TEST_NROWS,\n",
    "    \"n_nnn_adverse\": TEST_NROWS,\n",
    "    \"n_nn_adverse\": TEST_NROWS,\n",
    "    \"n_n_adverse\": TEST_NROWS,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: (18000, 903)\n",
      "ratio:\n",
      "0    0.502389\n",
      "1    0.497611\n",
      "Name: label, dtype: float64\n",
      "\n",
      "dataset: (6000, 903)\n",
      "ratio:\n",
      "1    0.502833\n",
      "0    0.497167\n",
      "Name: label, dtype: float64\n",
      "\n",
      "dataset: (6000, 903)\n",
      "ratio:\n",
      "1    0.502167\n",
      "0    0.497833\n",
      "Name: label, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_simple_data = get_simple_dataset(\n",
    "    seq_len=SEQ_LEN,\n",
    "    uid_len=UID_LEN,\n",
    "    uid_colname=UID_COLNAME,\n",
    "    count_dict=train_count_dict,\n",
    "    tokens=tokens,\n",
    ")\n",
    "\n",
    "val_simple_data = get_simple_dataset(\n",
    "    seq_len=SEQ_LEN,\n",
    "    uid_len=UID_LEN,\n",
    "    uid_colname=UID_COLNAME,\n",
    "    count_dict=val_count_dict,\n",
    "    tokens=tokens,\n",
    ")\n",
    "\n",
    "test_simple_data = get_simple_dataset(\n",
    "    seq_len=SEQ_LEN,\n",
    "    uid_len=UID_LEN,\n",
    "    uid_colname=UID_COLNAME,\n",
    "    count_dict=test_count_dict,\n",
    "    tokens=tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv(train_simple_data, TRAIN_FP)\n",
    "save_csv(val_simple_data, VAL_FP)\n",
    "save_csv(test_simple_data, TEST_FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 903)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>899</th>\n",
       "      <th>898</th>\n",
       "      <th>897</th>\n",
       "      <th>896</th>\n",
       "      <th>895</th>\n",
       "      <th>894</th>\n",
       "      <th>893</th>\n",
       "      <th>892</th>\n",
       "      <th>891</th>\n",
       "      <th>...</th>\n",
       "      <th>7</th>\n",
       "      <th>6</th>\n",
       "      <th>5</th>\n",
       "      <th>4</th>\n",
       "      <th>3</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>label</th>\n",
       "      <th>patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1464</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>peanut_allergy_N</td>\n",
       "      <td>foot_pain_N</td>\n",
       "      <td>backache_N</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>ankle_sprain_N</td>\n",
       "      <td>eye_exam_N</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>ACL_tear_N</td>\n",
       "      <td>0</td>\n",
       "      <td>XH6SLT2BCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2543</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>hay_fever_N</td>\n",
       "      <td>dental_exam_N</td>\n",
       "      <td>annual_physical_N</td>\n",
       "      <td>myopia_N</td>\n",
       "      <td>ankle_sprain_N</td>\n",
       "      <td>cold_sore_N</td>\n",
       "      <td>quad_injury_N</td>\n",
       "      <td>ACL_tear_N</td>\n",
       "      <td>0</td>\n",
       "      <td>6E4ZTLGOYU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>241</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>eye_exam_N</td>\n",
       "      <td>headache_N</td>\n",
       "      <td>annual_physical_N</td>\n",
       "      <td>headache_N</td>\n",
       "      <td>annual_physical_N</td>\n",
       "      <td>backache_N</td>\n",
       "      <td>ACL_tear_N</td>\n",
       "      <td>cut_finger_N</td>\n",
       "      <td>0</td>\n",
       "      <td>U3841J9X20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1983</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>headache_N</td>\n",
       "      <td>ankle_sprain_N</td>\n",
       "      <td>ankle_sprain_N</td>\n",
       "      <td>quad_injury_N</td>\n",
       "      <td>cold_sore_N</td>\n",
       "      <td>headache_N</td>\n",
       "      <td>foot_pain_N</td>\n",
       "      <td>cut_finger_N</td>\n",
       "      <td>1</td>\n",
       "      <td>C8253UIXKK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1231</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>cut_finger_N</td>\n",
       "      <td>ACL_tear_N</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>headache_N</td>\n",
       "      <td>quad_injury_N</td>\n",
       "      <td>cut_finger_N</td>\n",
       "      <td>cut_finger_N</td>\n",
       "      <td>peanut_allergy_N</td>\n",
       "      <td>1</td>\n",
       "      <td>7QKGFWNKNN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 903 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    899    898    897    896    895    894    893    892    891  ...  \\\n",
       "0   1464  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  ...   \n",
       "1   2543  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  ...   \n",
       "2    241  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  ...   \n",
       "3   1983  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  ...   \n",
       "4   1231  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  ...   \n",
       "\n",
       "                  7               6                  5               4  \\\n",
       "0  peanut_allergy_N     foot_pain_N         backache_N  ingrown_nail_N   \n",
       "1       hay_fever_N   dental_exam_N  annual_physical_N        myopia_N   \n",
       "2        eye_exam_N      headache_N  annual_physical_N      headache_N   \n",
       "3        headache_N  ankle_sprain_N     ankle_sprain_N   quad_injury_N   \n",
       "4      cut_finger_N      ACL_tear_N     ingrown_nail_N      headache_N   \n",
       "\n",
       "                   3             2               1                 0 label  \\\n",
       "0     ankle_sprain_N    eye_exam_N  ingrown_nail_N        ACL_tear_N     0   \n",
       "1     ankle_sprain_N   cold_sore_N   quad_injury_N        ACL_tear_N     0   \n",
       "2  annual_physical_N    backache_N      ACL_tear_N      cut_finger_N     0   \n",
       "3        cold_sore_N    headache_N     foot_pain_N      cut_finger_N     1   \n",
       "4      quad_injury_N  cut_finger_N    cut_finger_N  peanut_allergy_N     1   \n",
       "\n",
       "   patient_id  \n",
       "0  XH6SLT2BCA  \n",
       "1  6E4ZTLGOYU  \n",
       "2  U3841J9X20  \n",
       "3  C8253UIXKK  \n",
       "4  7QKGFWNKNN  \n",
       "\n",
       "[5 rows x 903 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(TRAIN_FP)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
