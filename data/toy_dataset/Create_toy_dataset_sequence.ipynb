{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic dataset generation -- Sequence based\n",
    "Author: Lin Lee Cheong <br>\n",
    "Date created: 12/12/ 2020 <br>\n",
    "Date updated: 1/31/2021 <br> <br>\n",
    "\n",
    "Goal of this synthetic dataset is to create datasets to help understand how different relationships between tokens affect attention, SHAP and other interpretability factors.\n",
    "- length of events (30, 300, 900)\n",
    "- spacing between 2+ coupled events, i.e. order of sequence matters\n",
    "- amount of noise, i.e. performance vs interpretability\n",
    "- vocabulary space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import string\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_NAMES_FP = \"./tokens.yaml\"\n",
    "\n",
    "SEQ_LEN = 300\n",
    "\n",
    "TRAIN_FP = \"data/seq/{}/seq_aaa_1/train.csv\".format(SEQ_LEN)\n",
    "VAL_FP = \"data/seq/{}/seq_aaa_1/val.csv\".format(SEQ_LEN)\n",
    "TEST_FP = \"data/seq/{}/seq_aaa_1/test.csv\".format(SEQ_LEN)\n",
    "\n",
    "UID_COLNAME = \"patient_id\"\n",
    "\n",
    "TRAIN_NROWS = 3000 # 18000\n",
    "VAL_NROWS = 1000 # 6000\n",
    "TEST_NROWS = 1000 # 6000\n",
    "\n",
    "UID_LEN = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adverse_tokens: 4 tokens\n",
      "adverse_helper_tokens: 6 tokens\n",
      "adverse_unhelper_tokens: 5 tokens\n",
      "noise_tokens: 15 tokens\n",
      "adverse_sequence_tokens: 3 tokens\n"
     ]
    }
   ],
   "source": [
    "# Load tokens from yaml file path\n",
    "tokens = load_tokens(TOKEN_NAMES_FP)\n",
    "for key in tokens.keys():\n",
    "    print(f\"{key}: {len(tokens[key])} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AMI_A', 'PH_A', 'ARR_A', 'CHF_A']\n"
     ]
    }
   ],
   "source": [
    "print(tokens['adverse_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apnea_H', 'furosemide_H', 'pneumonia_H', 'high_creatinine_H', 'tachycardia_H', 'resistent_hyp_H']\n"
     ]
    }
   ],
   "source": [
    "print(tokens['adverse_helper_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PCI_U', 'cardiac_rehab_U', 'normal_bmi_U', 'low_salt_diet_U', 'ACE_inhibitors_U']\n"
     ]
    }
   ],
   "source": [
    "print(tokens['adverse_unhelper_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AMI_A', 'CHF_A', 'ARR_A']\n"
     ]
    }
   ],
   "source": [
    "print(tokens['adverse_sequence_tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive label is driven by a sequence of tokens\n",
    "- positive set sequence:\n",
    "    - (AMI_A, CHF_A, ARR_A) --> 99%\n",
    "    - Other 1, 2, 3A sequence gives 0.55, 0.7, 0.75\n",
    "    - (1A) + 2 H --> 65 %\n",
    "- negative set:\n",
    "    - Ns (#and Us)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11220.0\n",
      "3780.0\n",
      "7440.0\n"
     ]
    }
   ],
   "source": [
    "x = 3000\n",
    "tot = x * 5\n",
    "pos_lab =  x * 0.99 + x * 0.6 + x * 0.7 + x * 0.75 + x * 0.7\n",
    "neg_lab = tot - pos_lab \n",
    "print(pos_lab)\n",
    "print(neg_lab) # number already negatively labelled\n",
    "print(pos_lab - neg_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1260.0\n",
      "2480.0\n"
     ]
    }
   ],
   "source": [
    "x = 1000\n",
    "tot = x * 5\n",
    "pos_lab =  x * 0.99 + x * 0.6 + x * 0.7 + x * 0.75 + x * 0.7\n",
    "neg_lab = tot - pos_lab \n",
    "print(neg_lab)\n",
    "print(pos_lab -  neg_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count_dict = {\n",
    "    \"n_aaa_seq_adverse\": TRAIN_NROWS,\n",
    "    \"n_aaa_adverse\": TRAIN_NROWS,\n",
    "    \"n_aa_adverse\": TRAIN_NROWS,\n",
    "    \"n_a_adverse\": TRAIN_NROWS,\n",
    "    \"n_ahh_adverse\": TRAIN_NROWS,\n",
    "    \"n_noise_adverse\": 7440,\n",
    "}\n",
    "\n",
    "val_count_dict = {\n",
    "    \"n_aaa_seq_adverse\": VAL_NROWS,\n",
    "    \"n_aaa_adverse\": VAL_NROWS,\n",
    "    \"n_aa_adverse\": VAL_NROWS,\n",
    "    \"n_a_adverse\": VAL_NROWS,\n",
    "    \"n_ahh_adverse\": VAL_NROWS,\n",
    "    \"n_noise_adverse\": 2480,\n",
    "}\n",
    "\n",
    "test_count_dict = {\n",
    "    \"n_aaa_seq_adverse\": TEST_NROWS,\n",
    "    \"n_aaa_adverse\": TEST_NROWS,\n",
    "    \"n_aa_adverse\": TEST_NROWS,\n",
    "    \"n_a_adverse\": TEST_NROWS,\n",
    "    \"n_ahh_adverse\": TEST_NROWS,\n",
    "    \"n_noise_adverse\": 2480,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_tok(seq_len, token_dict, token_key, n_pairs, min_idx=0):\n",
    "    \"\"\"Get random index and token from token_key of n_pairs.\"\"\"\n",
    "    return [\n",
    "        (\n",
    "            random.choices(range(min_idx, seq_len), k=1)[0],\n",
    "            random.choices(token_dict[token_key], k=1)[0],\n",
    "        )\n",
    "        for _ in range(n_pairs)\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_tok_ordered(seq_len, token_dict, token_key, min_idx=0):\n",
    "    \"\"\"Get random index and token from token_key of n_pairs.\"\"\"\n",
    "    \n",
    "    seq = token_dict[token_key]\n",
    "    \n",
    "    indexes = sorted([random.choices(range(min_idx, seq_len), k=1)[0] for _ in range(len(seq))])\n",
    "    return [(idx, tok) for idx, tok in zip(indexes, seq)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7, 'AMI_A'), (17, 'CHF_A'), (24, 'ARR_A')]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_idx_tok_ordered(30, tokens, 'adverse_sequence_tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_sequence_seq(\n",
    "    adverse, helper, unhelper, adverse_seq, seq_len, label, tokens, proba\n",
    "):\n",
    "    \"\"\"creates sequence + label (at the end of list) with specific orderings.\n",
    "       returns list of list\"\"\"\n",
    "\n",
    "    n_noise = np.max((\n",
    "        10,\n",
    "        random.choices(\n",
    "            range(adverse + helper + unhelper + adverse_seq, seq_len), k=1\n",
    "        )[0],\n",
    "    )) - (adverse + helper + unhelper + adverse_seq)\n",
    "\n",
    "    sel_adverse, sel_helper, sel_unhelper, sel_ad_seq = [], [], [], []\n",
    "\n",
    "    if adverse:\n",
    "        sel_adverse = get_idx_tok(n_noise, tokens, \"adverse_tokens\", adverse)\n",
    "\n",
    "    if helper:\n",
    "        sel_helper = get_idx_tok(n_noise, tokens, \"adverse_helper_tokens\", helper)\n",
    "\n",
    "    if unhelper:\n",
    "        sel_unhelper = get_idx_tok(n_noise, tokens, \"adverse_unhelper_tokens\", unhelper)\n",
    "    \n",
    "    if adverse_seq:\n",
    "        sel_ad_seq = get_idx_tok_ordered(n_noise, tokens, 'adverse_sequence_tokens')\n",
    "        \n",
    "    sel_noise = get_tokens(seq_len, tokens, \"noise_tokens\", n_noise)\n",
    "\n",
    "    for idx, event in sel_adverse + sel_helper + sel_unhelper + sel_ad_seq:\n",
    "        sel_noise.insert(idx, event)\n",
    "\n",
    "    sel_noise = [\"<pad>\"] * (seq_len - len(sel_noise)) + sel_noise\n",
    "\n",
    "    # label depending on proba\n",
    "    sim_lab = get_label(proba, target=label)\n",
    "\n",
    "    return sel_noise + [sim_lab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequences(\n",
    "    adverse, helper, unhelper, seq_len, label, uid_len, uid_colname, n_seq, tokens,\n",
    "    seq_type='event', adverse_seq=0, proba=1.0\n",
    "):\n",
    "    \"\"\"Get multiple sequences.\"\"\"\n",
    "    \n",
    "    if seq_type == 'event':\n",
    "        sequences = [\n",
    "            get_a_sequence(\n",
    "                adverse=adverse,\n",
    "                helper=helper,\n",
    "                unhelper=unhelper,\n",
    "                seq_len=seq_len,\n",
    "                label=label,\n",
    "                tokens=tokens,\n",
    "                proba=proba\n",
    "            )\n",
    "            + [get_uid(uid_len)]\n",
    "            for _ in range(n_seq)\n",
    "        ]\n",
    "        \n",
    "    if seq_type == 'seq':\n",
    "        sequences = [\n",
    "            get_a_sequence_seq(\n",
    "                adverse=adverse,\n",
    "                helper=helper,\n",
    "                unhelper=unhelper,\n",
    "                adverse_seq=adverse_seq,\n",
    "                seq_len=seq_len,\n",
    "                label=label,\n",
    "                tokens=tokens,\n",
    "                proba=proba\n",
    "            )\n",
    "            + [get_uid(uid_len)]\n",
    "            for _ in range(n_seq)\n",
    "        ]\n",
    "        print(f\"seq based events generated\")\n",
    "        \n",
    "    seq_df = pd.DataFrame(sequences)\n",
    "    seq_df.columns = [str(x) for x in range(seq_len-1, -1, -1)] + [\n",
    "        \"label\",\n",
    "        uid_colname,\n",
    "    ]\n",
    "\n",
    "    return seq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_dataset(seq_len, uid_len, uid_colname, count_dict, tokens):\n",
    "    \"\"\"Generate a simple toy dataset.\n",
    "    \n",
    "    Arg:\n",
    "    -----\n",
    "        seq_len (int) : length of the generated sequence\n",
    "        uid_len (int) : length of uid token\n",
    "        uid_colname (str) : name of uid column, usually patient_id\n",
    "        count_dict (dict) : dictionary of various sequence types.\n",
    "            6 different types are allowed:\n",
    "                n_ppp_adverse, n_pp_adverse, n_p_adverse\n",
    "                n_nnn_adverse, n_nn_adverse, n_n_adverse\n",
    "        tokens (dict) : dictionary of the various token types\n",
    "                \n",
    "    Returns:\n",
    "    --------\n",
    "        dataset (dataframe) : dataframe containing all the \n",
    "                              generated dataset, randomly mixed \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    cat_lst = []\n",
    "\n",
    "    if \"n_aaa_seq_adverse\" in count_dict:\n",
    "        aaa_seq = get_sequences(\n",
    "            adverse=0,\n",
    "            helper=0,\n",
    "            unhelper=0,\n",
    "            seq_len=seq_len,\n",
    "            label=1,\n",
    "            uid_len=uid_len,\n",
    "            uid_colname=uid_colname,\n",
    "            n_seq=count_dict[\"n_aaa_seq_adverse\"],\n",
    "            tokens=tokens,\n",
    "            seq_type='seq', \n",
    "            adverse_seq=3,\n",
    "            proba=0.99\n",
    "        )\n",
    "        aaa_seq['seq_event'] = 'aaa_seq'\n",
    "        cat_lst.append(aaa_seq)\n",
    "    \n",
    "    if \"n_aaa_adverse\" in count_dict:\n",
    "        aaa = get_sequences(\n",
    "            adverse=3,\n",
    "            helper=0,\n",
    "            unhelper=0,\n",
    "            seq_len=seq_len,\n",
    "            label=1,\n",
    "            uid_len=uid_len,\n",
    "            uid_colname=uid_colname,\n",
    "            n_seq=count_dict[\"n_aaa_adverse\"],\n",
    "            tokens=tokens,\n",
    "            seq_type='seq', \n",
    "            adverse_seq=0,\n",
    "            proba=0.75\n",
    "        )\n",
    "        aaa['seq_event'] = 'aaa'\n",
    "        \n",
    "        cat_lst.append(aaa)    \n",
    "\n",
    "    if \"n_aa_adverse\" in count_dict:\n",
    "        aa = get_sequences(\n",
    "            adverse=2,\n",
    "            helper=0,\n",
    "            unhelper=0,\n",
    "            seq_len=seq_len,\n",
    "            label=1,\n",
    "            uid_len=uid_len,\n",
    "            uid_colname=uid_colname,\n",
    "            n_seq=count_dict[\"n_aa_adverse\"],\n",
    "            tokens=tokens,\n",
    "            seq_type='seq', \n",
    "            adverse_seq=0,\n",
    "            proba=0.7\n",
    "        )\n",
    "        aa['seq_event'] = 'aa'\n",
    "        cat_lst.append(aa)\n",
    "        \n",
    "    if \"n_a_adverse\" in count_dict:\n",
    "        a = get_sequences(\n",
    "            adverse=1,\n",
    "            helper=0,\n",
    "            unhelper=0,\n",
    "            seq_len=seq_len,\n",
    "            label=1,\n",
    "            uid_len=uid_len,\n",
    "            uid_colname=uid_colname,\n",
    "            n_seq=count_dict[\"n_a_adverse\"],\n",
    "            tokens=tokens,\n",
    "            seq_type='seq', \n",
    "            adverse_seq=0,\n",
    "            proba=0.55\n",
    "        )\n",
    "        a['seq_event'] = 'a'\n",
    "        cat_lst.append(a)        \n",
    "\n",
    "    if \"n_ahh_adverse\" in count_dict:\n",
    "        ahh = get_sequences(\n",
    "            adverse=1,\n",
    "            helper=2,\n",
    "            unhelper=0,\n",
    "            seq_len=seq_len,\n",
    "            label=1,\n",
    "            uid_len=uid_len,\n",
    "            uid_colname=uid_colname,\n",
    "            n_seq=count_dict[\"n_ahh_adverse\"],\n",
    "            tokens=tokens,\n",
    "            seq_type='seq', \n",
    "            adverse_seq=0,\n",
    "            proba=0.65\n",
    "        )\n",
    "        ahh['seq_event'] = 'ahh'\n",
    "        cat_lst.append(ahh)  \n",
    "\n",
    "    if \"n_noise_adverse\" in count_dict:\n",
    "        noise = get_sequences(\n",
    "            adverse=0,\n",
    "            helper=0,\n",
    "            unhelper=0,\n",
    "            seq_len=seq_len,\n",
    "            label=0,\n",
    "            uid_len=uid_len,\n",
    "            uid_colname=uid_colname,\n",
    "            n_seq=count_dict[\"n_noise_adverse\"],\n",
    "            tokens=tokens,\n",
    "            seq_type='seq', \n",
    "            adverse_seq=0,\n",
    "            proba=0.95\n",
    "        )\n",
    "        noise['seq_event'] = 'noise'\n",
    "        cat_lst.append(noise)  \n",
    "        \n",
    "    # event-triggered ##\n",
    "    if \"n_ppp_adverse\" in count_dict:\n",
    "        ppp = get_sequences(\n",
    "            adverse=1,\n",
    "            helper=1,\n",
    "            unhelper=0,\n",
    "            seq_len=seq_len,\n",
    "            label=1,\n",
    "            uid_len=uid_len,\n",
    "            uid_colname=uid_colname,\n",
    "            n_seq=count_dict[\"n_ppp_adverse\"],\n",
    "            tokens=tokens\n",
    "        )\n",
    "        ppp['seq_event'] = 1\n",
    "        cat_lst.append(ppp)\n",
    "        \n",
    "    if \"n_pp_adverse\" in count_dict:  \n",
    "        pp = get_sequences(\n",
    "            adverse=1,\n",
    "            helper=0,\n",
    "            unhelper=0,\n",
    "            seq_len=seq_len,\n",
    "            label=1,\n",
    "            uid_len=uid_len,\n",
    "            uid_colname=uid_colname,\n",
    "            n_seq=count_dict[\"n_pp_adverse\"],\n",
    "            tokens=tokens,\n",
    "        )\n",
    "        pp['seq_event'] = 0\n",
    "        cat_lst.append(pp)\n",
    "        \n",
    "    if \"n_p_adverse\" in count_dict:\n",
    "        p = get_sequences(\n",
    "            adverse=0,\n",
    "            helper=3,\n",
    "            unhelper=0,\n",
    "            seq_len=seq_len,\n",
    "            label=1,\n",
    "            uid_len=uid_len,\n",
    "            uid_colname=uid_colname,\n",
    "            n_seq=count_dict[\"n_p_adverse\"],\n",
    "            tokens=tokens,\n",
    "        )\n",
    "        p['seq_event'] = 0\n",
    "        cat_lst.append(p)\n",
    "        \n",
    "    if \"n_nnn_adverse\" in count_dict:\n",
    "        nnn = get_sequences(\n",
    "            adverse=0,\n",
    "            helper=0,\n",
    "            unhelper=3,\n",
    "            seq_len=seq_len,\n",
    "            label=0,\n",
    "            uid_len=uid_len,\n",
    "            uid_colname=uid_colname,\n",
    "            n_seq=count_dict[\"n_nnn_adverse\"],\n",
    "            tokens=tokens,\n",
    "        )\n",
    "        nnn['seq_event'] = 0\n",
    "        cat_lst.append(nnn)\n",
    "    \n",
    "    if \"n_nn_adverse\" in count_dict:\n",
    "        nn = get_sequences(\n",
    "            adverse=0,\n",
    "            helper=1,\n",
    "            unhelper=2,\n",
    "            seq_len=seq_len,\n",
    "            label=0,\n",
    "            uid_len=uid_len,\n",
    "            uid_colname=uid_colname,\n",
    "            n_seq=count_dict[\"n_nn_adverse\"],\n",
    "            tokens=tokens,\n",
    "        )\n",
    "        nn['seq_event'] = 0\n",
    "        cat_lst.append(nn)\n",
    "        \n",
    "    if \"n_n_adverse\" in count_dict:\n",
    "        n = get_sequences(\n",
    "            adverse=0,\n",
    "            helper=2,\n",
    "            unhelper=1,\n",
    "            seq_len=seq_len,\n",
    "            label=0,\n",
    "            uid_len=uid_len,\n",
    "            uid_colname=uid_colname,\n",
    "            n_seq=count_dict[\"n_n_adverse\"],\n",
    "            tokens=tokens,\n",
    "        )\n",
    "        n['seq_event'] = 0\n",
    "        cat_lst.append(n)\n",
    "\n",
    "    dataset = pd.concat(cat_lst, axis=0)\n",
    "    dataset.reset_index(inplace=True)\n",
    "    indexes = [idx for idx in range(dataset.shape[0])]\n",
    "    random.shuffle(indexes)\n",
    "    dataset = dataset.iloc[indexes, :]\n",
    "    #dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    print(f\"dataset: {dataset.shape}\")\n",
    "    print(f\"ratio:\\n{dataset.label.value_counts(normalize=True)}\\n\")\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_simple_data = get_sequence_dataset(\n",
    "    seq_len=SEQ_LEN,\n",
    "    uid_len=UID_LEN,\n",
    "    uid_colname=UID_COLNAME,\n",
    "    count_dict=train_count_dict,\n",
    "    tokens=tokens,\n",
    ")\n",
    "\n",
    "val_simple_data = get_sequence_dataset(\n",
    "    seq_len=SEQ_LEN,\n",
    "    uid_len=UID_LEN,\n",
    "    uid_colname=UID_COLNAME,\n",
    "    count_dict=val_count_dict,\n",
    "    tokens=tokens,\n",
    ")\n",
    "\n",
    "test_simple_data = get_sequence_dataset(\n",
    "    seq_len=SEQ_LEN,\n",
    "    uid_len=UID_LEN,\n",
    "    uid_colname=UID_COLNAME,\n",
    "    count_dict=test_count_dict,\n",
    "    tokens=tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "noise      7440\n",
       "aaa_seq    3000\n",
       "aa         3000\n",
       "a          3000\n",
       "ahh        3000\n",
       "aaa        3000\n",
       "Name: seq_event, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_simple_data.seq_event.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv(train_simple_data, TRAIN_FP)\n",
    "save_csv(val_simple_data, VAL_FP)\n",
    "save_csv(test_simple_data, TEST_FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22440, 304)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>299</th>\n",
       "      <th>298</th>\n",
       "      <th>297</th>\n",
       "      <th>296</th>\n",
       "      <th>295</th>\n",
       "      <th>294</th>\n",
       "      <th>293</th>\n",
       "      <th>292</th>\n",
       "      <th>291</th>\n",
       "      <th>...</th>\n",
       "      <th>6</th>\n",
       "      <th>5</th>\n",
       "      <th>4</th>\n",
       "      <th>3</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>label</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>seq_event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>413</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>peanut_allergy_N</td>\n",
       "      <td>cold_sore_N</td>\n",
       "      <td>annual_physical_N</td>\n",
       "      <td>myopia_N</td>\n",
       "      <td>backache_N</td>\n",
       "      <td>dental_exam_N</td>\n",
       "      <td>myopia_N</td>\n",
       "      <td>1</td>\n",
       "      <td>QYGMG349QI</td>\n",
       "      <td>aaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>924</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>dental_exam_N</td>\n",
       "      <td>ankle_sprain_N</td>\n",
       "      <td>peanut_allergy_N</td>\n",
       "      <td>foot_pain_N</td>\n",
       "      <td>cold_sore_N</td>\n",
       "      <td>cold_sore_N</td>\n",
       "      <td>ankle_sprain_N</td>\n",
       "      <td>1</td>\n",
       "      <td>GEX6E0F70W</td>\n",
       "      <td>aaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2289</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>annual_physical_N</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>headache_N</td>\n",
       "      <td>annual_physical_N</td>\n",
       "      <td>annual_physical_N</td>\n",
       "      <td>headache_N</td>\n",
       "      <td>1</td>\n",
       "      <td>XDWKV6SBL2</td>\n",
       "      <td>ahh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>hay_fever_N</td>\n",
       "      <td>ACL_tear_N</td>\n",
       "      <td>dental_exam_N</td>\n",
       "      <td>eye_exam_N</td>\n",
       "      <td>peanut_allergy_N</td>\n",
       "      <td>annual_physical_N</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>0</td>\n",
       "      <td>YOSLNTMHVO</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1710</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>ankle_sprain_N</td>\n",
       "      <td>ACL_tear_N</td>\n",
       "      <td>headache_N</td>\n",
       "      <td>eye_exam_N</td>\n",
       "      <td>annual_physical_N</td>\n",
       "      <td>myopia_N</td>\n",
       "      <td>cut_finger_N</td>\n",
       "      <td>1</td>\n",
       "      <td>8GAD7ENZWG</td>\n",
       "      <td>aaa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    299    298    297    296    295    294    293    292    291  ...  \\\n",
       "0    413  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  ...   \n",
       "1    924  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  ...   \n",
       "2   2289  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  ...   \n",
       "3   1464  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  ...   \n",
       "4   1710  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  <pad>  ...   \n",
       "\n",
       "                  6                  5                  4            3  \\\n",
       "0  peanut_allergy_N        cold_sore_N  annual_physical_N     myopia_N   \n",
       "1     dental_exam_N     ankle_sprain_N   peanut_allergy_N  foot_pain_N   \n",
       "2    ingrown_nail_N  annual_physical_N     ingrown_nail_N   headache_N   \n",
       "3       hay_fever_N         ACL_tear_N      dental_exam_N   eye_exam_N   \n",
       "4    ankle_sprain_N         ACL_tear_N         headache_N   eye_exam_N   \n",
       "\n",
       "                   2                  1               0 label  patient_id  \\\n",
       "0         backache_N      dental_exam_N        myopia_N     1  QYGMG349QI   \n",
       "1        cold_sore_N        cold_sore_N  ankle_sprain_N     1  GEX6E0F70W   \n",
       "2  annual_physical_N  annual_physical_N      headache_N     1  XDWKV6SBL2   \n",
       "3   peanut_allergy_N  annual_physical_N  ingrown_nail_N     0  YOSLNTMHVO   \n",
       "4  annual_physical_N           myopia_N    cut_finger_N     1  8GAD7ENZWG   \n",
       "\n",
       "  seq_event  \n",
       "0       aaa  \n",
       "1       aaa  \n",
       "2       ahh  \n",
       "3         a  \n",
       "4       aaa  \n",
       "\n",
       "[5 rows x 304 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(TRAIN_FP)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    11257\n",
       "0    11183\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                   140\n",
       "299                   <pad>\n",
       "298                   <pad>\n",
       "297                   <pad>\n",
       "296                   <pad>\n",
       "                  ...      \n",
       "1               hay_fever_N\n",
       "0             dental_exam_N\n",
       "label                     0\n",
       "patient_id       ZZC2MUYUFQ\n",
       "seq_event               ahh\n",
       "Name: 20430, Length: 304, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "n = np.random.choice(df.shape[0])\n",
    "df.iloc[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = df[df.label == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index               6559\n",
       "299                <pad>\n",
       "298                <pad>\n",
       "297                <pad>\n",
       "296                <pad>\n",
       "                 ...    \n",
       "1               myopia_N\n",
       "0             backache_N\n",
       "label                  0\n",
       "patient_id    MN66YREIS2\n",
       "seq_event          noise\n",
       "Name: 84, Length: 304, dtype: object"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee.iloc[43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
