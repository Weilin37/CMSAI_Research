{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Multiple Dataset Generation\n",
    "Author: Lin Lee Cheong <br>\n",
    "Modified By: Tesfagabir Meharizghi <br>\n",
    "Date: 01/20/2021 <br>\n",
    "\n",
    "Goal of this synthetic dataset is to create datasets to help understand how different relationships between tokens affect attention, SHAP and other interpretability factors.\n",
    "- length of events (30, 300, 900)\n",
    "- spacing between 2+ coupled events, i.e. order of sequence matters\n",
    "- amount of noise, i.e. performance vs interpretability\n",
    "- vocabulary space\n",
    "\n",
    "It generates multiple datasets for experimentation purposes by changing `EXP_NUMBER` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install nb-black\n",
    "\n",
    "#! pip install botocore==1.12.201\n",
    "\n",
    "#! pip install shap\n",
    "#! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lab_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext lab_black\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext lab_black\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import string\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_NAMES_FP = \"./tokens.yaml\"\n",
    "\n",
    "SEQ_LEN = 30\n",
    "\n",
    "EXP_NUMBER = 10\n",
    "\n",
    "TRAIN_FP = f\"data/{SEQ_LEN}/{EXP_NUMBER:02}/train.csv\"\n",
    "VAL_FP = f\"data/{SEQ_LEN}/{EXP_NUMBER:02}/val.csv\"\n",
    "TEST_FP = f\"data/{SEQ_LEN}/{EXP_NUMBER:02}/test.csv\"\n",
    "\n",
    "UID_COLNAME = \"patient_id\"\n",
    "\n",
    "TRAIN_NROWS = 3000\n",
    "VAL_NROWS = 1000\n",
    "TEST_NROWS = 1000\n",
    "\n",
    "UID_LEN = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adverse_tokens: 4 tokens\n",
      "adverse_helper_tokens: 6 tokens\n",
      "adverse_unhelper_tokens: 5 tokens\n",
      "noise_tokens: 15 tokens\n"
     ]
    }
   ],
   "source": [
    "# Load tokens from yaml file path\n",
    "tokens = load_tokens(TOKEN_NAMES_FP)\n",
    "for key in tokens.keys():\n",
    "    print(f\"{key}: {len(tokens[key])} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get simple dataset:\n",
    "- positive set: (+++, 1 major + a helper), (++, 1 major), (+, 3 helper)\n",
    "- negative set: (---, 3 unhelper), (--, 1 helper + 2 unhelper), (-, 2 helper + 1 unhelper)\n",
    "\n",
    "\n",
    "**NOTES**<br>\n",
    "n_ppp_adverse = 2000 # 1 adverse event + 1 helper event <br>\n",
    "n_pp_adverse = 2000 # 1 adverse event <br>\n",
    "n_p_adverse = 2000 # 3 helper events <br><br>\n",
    "n_nnn_adverse = 2000 # 3 unhelper events <br>\n",
    "n_nn_adverse = 2000 # 1 helper + 2 unhelper <br>\n",
    "n_n_adverse = 2000 # 2 helper + 1 unhelper <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count_dict = {\n",
    "    \"n_ppp_adverse\": TRAIN_NROWS,\n",
    "    \"n_pp_adverse\": TRAIN_NROWS,\n",
    "    \"n_p_adverse\": TRAIN_NROWS,\n",
    "    \"n_nnn_adverse\": TRAIN_NROWS,\n",
    "    \"n_nn_adverse\": TRAIN_NROWS,\n",
    "    \"n_n_adverse\": TRAIN_NROWS,\n",
    "}\n",
    "\n",
    "val_count_dict = {\n",
    "    \"n_ppp_adverse\": VAL_NROWS,\n",
    "    \"n_pp_adverse\": VAL_NROWS,\n",
    "    \"n_p_adverse\": VAL_NROWS,\n",
    "    \"n_nnn_adverse\": VAL_NROWS,\n",
    "    \"n_nn_adverse\": VAL_NROWS,\n",
    "    \"n_n_adverse\": VAL_NROWS,\n",
    "}\n",
    "\n",
    "test_count_dict = {\n",
    "    \"n_ppp_adverse\": TEST_NROWS,\n",
    "    \"n_pp_adverse\": TEST_NROWS,\n",
    "    \"n_p_adverse\": TEST_NROWS,\n",
    "    \"n_nnn_adverse\": TEST_NROWS,\n",
    "    \"n_nn_adverse\": TEST_NROWS,\n",
    "    \"n_n_adverse\": TEST_NROWS,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: (18000, 33)\n",
      "ratio:\n",
      "1    0.500833\n",
      "0    0.499167\n",
      "Name: label, dtype: float64\n",
      "\n",
      "dataset: (6000, 33)\n",
      "ratio:\n",
      "0    0.503667\n",
      "1    0.496333\n",
      "Name: label, dtype: float64\n",
      "\n",
      "dataset: (6000, 33)\n",
      "ratio:\n",
      "1    0.503833\n",
      "0    0.496167\n",
      "Name: label, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_simple_data = get_simple_dataset(\n",
    "    seq_len=SEQ_LEN,\n",
    "    uid_len=UID_LEN,\n",
    "    uid_colname=UID_COLNAME,\n",
    "    count_dict=train_count_dict,\n",
    "    tokens=tokens,\n",
    ")\n",
    "\n",
    "val_simple_data = get_simple_dataset(\n",
    "    seq_len=SEQ_LEN,\n",
    "    uid_len=UID_LEN,\n",
    "    uid_colname=UID_COLNAME,\n",
    "    count_dict=val_count_dict,\n",
    "    tokens=tokens,\n",
    ")\n",
    "\n",
    "test_simple_data = get_simple_dataset(\n",
    "    seq_len=SEQ_LEN,\n",
    "    uid_len=UID_LEN,\n",
    "    uid_colname=UID_COLNAME,\n",
    "    count_dict=test_count_dict,\n",
    "    tokens=tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv(train_simple_data, TRAIN_FP)\n",
    "save_csv(val_simple_data, VAL_FP)\n",
    "save_csv(test_simple_data, TEST_FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 33)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>29</th>\n",
       "      <th>28</th>\n",
       "      <th>27</th>\n",
       "      <th>26</th>\n",
       "      <th>25</th>\n",
       "      <th>24</th>\n",
       "      <th>23</th>\n",
       "      <th>22</th>\n",
       "      <th>21</th>\n",
       "      <th>...</th>\n",
       "      <th>7</th>\n",
       "      <th>6</th>\n",
       "      <th>5</th>\n",
       "      <th>4</th>\n",
       "      <th>3</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>label</th>\n",
       "      <th>patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1068</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>peanut_allergy_N</td>\n",
       "      <td>cardiac_rehab_U</td>\n",
       "      <td>hay_fever_N</td>\n",
       "      <td>cold_sore_N</td>\n",
       "      <td>foot_pain_N</td>\n",
       "      <td>foot_pain_N</td>\n",
       "      <td>quad_injury_N</td>\n",
       "      <td>annual_physical_N</td>\n",
       "      <td>0</td>\n",
       "      <td>N5UE5PRL3K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1490</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>headache_N</td>\n",
       "      <td>hay_fever_N</td>\n",
       "      <td>headache_N</td>\n",
       "      <td>cold_sore_N</td>\n",
       "      <td>dental_exam_N</td>\n",
       "      <td>peanut_allergy_N</td>\n",
       "      <td>ankle_sprain_N</td>\n",
       "      <td>dental_exam_N</td>\n",
       "      <td>1</td>\n",
       "      <td>QZX2RVSPU3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1575</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>backache_N</td>\n",
       "      <td>annual_physical_N</td>\n",
       "      <td>cut_finger_N</td>\n",
       "      <td>backache_N</td>\n",
       "      <td>cut_finger_N</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>headache_N</td>\n",
       "      <td>...</td>\n",
       "      <td>peanut_allergy_N</td>\n",
       "      <td>eye_exam_N</td>\n",
       "      <td>eye_exam_N</td>\n",
       "      <td>dental_exam_N</td>\n",
       "      <td>ACE_inhibitors_U</td>\n",
       "      <td>headache_N</td>\n",
       "      <td>headache_N</td>\n",
       "      <td>dental_exam_N</td>\n",
       "      <td>1</td>\n",
       "      <td>QZDARC3OF1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1759</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>ACE_inhibitors_U</td>\n",
       "      <td>normal_bmi_U</td>\n",
       "      <td>ACE_inhibitors_U</td>\n",
       "      <td>cold_sore_N</td>\n",
       "      <td>cut_finger_N</td>\n",
       "      <td>foot_pain_N</td>\n",
       "      <td>ACL_tear_N</td>\n",
       "      <td>eye_exam_N</td>\n",
       "      <td>0</td>\n",
       "      <td>CCOYO5RILI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2184</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>tachycardia_H</td>\n",
       "      <td>backache_N</td>\n",
       "      <td>quad_injury_N</td>\n",
       "      <td>...</td>\n",
       "      <td>annual_physical_N</td>\n",
       "      <td>peanut_allergy_N</td>\n",
       "      <td>ankle_sprain_N</td>\n",
       "      <td>headache_N</td>\n",
       "      <td>ingrown_nail_N</td>\n",
       "      <td>ankle_sprain_N</td>\n",
       "      <td>backache_N</td>\n",
       "      <td>backache_N</td>\n",
       "      <td>1</td>\n",
       "      <td>ITA6KU5O0A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     29     28          27                 26            25  \\\n",
       "0   1068  <pad>  <pad>       <pad>              <pad>         <pad>   \n",
       "1   1490  <pad>  <pad>       <pad>              <pad>         <pad>   \n",
       "2   1575  <pad>  <pad>  backache_N  annual_physical_N  cut_finger_N   \n",
       "3   1759  <pad>  <pad>       <pad>              <pad>         <pad>   \n",
       "4   2184  <pad>  <pad>       <pad>              <pad>         <pad>   \n",
       "\n",
       "           24             23              22             21  ...  \\\n",
       "0       <pad>          <pad>           <pad>          <pad>  ...   \n",
       "1       <pad>          <pad>           <pad>          <pad>  ...   \n",
       "2  backache_N   cut_finger_N  ingrown_nail_N     headache_N  ...   \n",
       "3       <pad>          <pad>           <pad>          <pad>  ...   \n",
       "4       <pad>  tachycardia_H      backache_N  quad_injury_N  ...   \n",
       "\n",
       "                   7                 6                 5              4  \\\n",
       "0   peanut_allergy_N   cardiac_rehab_U       hay_fever_N    cold_sore_N   \n",
       "1         headache_N       hay_fever_N        headache_N    cold_sore_N   \n",
       "2   peanut_allergy_N        eye_exam_N        eye_exam_N  dental_exam_N   \n",
       "3   ACE_inhibitors_U      normal_bmi_U  ACE_inhibitors_U    cold_sore_N   \n",
       "4  annual_physical_N  peanut_allergy_N    ankle_sprain_N     headache_N   \n",
       "\n",
       "                  3                 2               1                  0  \\\n",
       "0       foot_pain_N       foot_pain_N   quad_injury_N  annual_physical_N   \n",
       "1     dental_exam_N  peanut_allergy_N  ankle_sprain_N      dental_exam_N   \n",
       "2  ACE_inhibitors_U        headache_N      headache_N      dental_exam_N   \n",
       "3      cut_finger_N       foot_pain_N      ACL_tear_N         eye_exam_N   \n",
       "4    ingrown_nail_N    ankle_sprain_N      backache_N         backache_N   \n",
       "\n",
       "  label  patient_id  \n",
       "0     0  N5UE5PRL3K  \n",
       "1     1  QZX2RVSPU3  \n",
       "2     1  QZDARC3OF1  \n",
       "3     0  CCOYO5RILI  \n",
       "4     1  ITA6KU5O0A  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(TRAIN_FP)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
